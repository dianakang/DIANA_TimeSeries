{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[딥러닝으로 걷는 시계열 예측] Ch4. 회귀 모델의 판별식.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMPFWLSnK2pbyrjKXFwA4YD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianakang/DIANA_TimeSeries/blob/master/%5B%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9C%BC%EB%A1%9C_%EA%B1%B7%EB%8A%94_%EC%8B%9C%EA%B3%84%EC%97%B4_%EC%98%88%EC%B8%A1%5D_Ch4_%ED%9A%8C%EA%B7%80_%EB%AA%A8%EB%8D%B8%EC%9D%98_%ED%8C%90%EB%B3%84%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPi5KIz1BmEb"
      },
      "source": [
        "# 목차\n",
        "\n",
        "*   4.1. 회귀 모델의 판별식\n",
        "*   4.2. 회귀 모델 코드 작성하기\n",
        "  *   4.2.1. Validation 추가\n",
        "  *   4.2.2. 데이터 분리\n",
        "      *   (1) 테스트 데이터로 예측하는 방법\n",
        "      *   (2) 새로운 데이터로 예측하는 방법\n",
        "  *   4.2.3. train_test_split\n",
        "*   4.3. 함수형 모델\n",
        "  *   4.3.1. 1:1 모델\n",
        "  *   4.3.2. 다:다 모델\n",
        "  *   4.3.3. 다:1 모델\n",
        "  *   4.3.4. 1:다 모델\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdg_bI7LBr2H"
      },
      "source": [
        "# 4. 회귀 모델의 판별식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NaNl01OBttq"
      },
      "source": [
        "## 4.1. 회귀 모델의 판별식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Liu8ZYCQ53"
      },
      "source": [
        "**RMSE(평균 제곱근 오차, Root Mean Squared Error)는 회귀 분석에서 모델을 평가할 때 가장 많이 쓰는 지표 중 하나**이다.\n",
        "\n",
        "대부분의 모든 파이썬과 딥러닝, 머신러닝은 API나 프레임워크, 함수가 거의 만들어져 있다.\n",
        "\n",
        "하지만 아쉽게도 RMSE는 아직 준비가 안되어 있는 듯 하다. 그래서 간단하게 함수를 만들어 사용한다.\n",
        "\n",
        "MSE에 루트를 씌운 것이 RMSE이다. 즉, RMSE는 원래 데이터에서 평균을 뺀 값을 제곱하여 모두 더한 뒤 전체 개수로 나눈 값에 루트를 씌운 것이다. \n",
        "\n",
        "**RMSE가 낮을수록 정밀도가 높다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY6S4IX_DGOs",
        "outputId": "920880fc-9d3f-4810-aa0b-80518c94de9c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np \n",
        "\n",
        "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "x_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n",
        "y_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=1, activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=300, batch_size=1, validation_data=(x_test, y_test))\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=1)\n",
        "\n",
        "print('loss : ', loss)\n",
        "y_predict = model.predict(x_test)\n",
        "print('결과물 : \\n', y_predict)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 5)                 10        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 18        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 21.2227 - mse: 21.2227 - val_loss: 8010.7642 - val_mse: 8010.7642\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.8609 - mse: 27.8609 - val_loss: 7617.9468 - val_mse: 7617.9468\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.5738 - mse: 21.5738 - val_loss: 7247.8174 - val_mse: 7247.8174\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 17.0099 - mse: 17.0099 - val_loss: 6878.0508 - val_mse: 6878.0508\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.7070 - mse: 21.7070 - val_loss: 6488.0791 - val_mse: 6488.0791\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.0271 - mse: 16.0271 - val_loss: 6093.4053 - val_mse: 6093.4053\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.0067 - mse: 21.0067 - val_loss: 5673.0361 - val_mse: 5673.0361\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.6238 - mse: 17.6238 - val_loss: 5295.2139 - val_mse: 5295.2139\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.3913 - mse: 14.3913 - val_loss: 4890.4292 - val_mse: 4890.4292\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2394 - mse: 8.2394 - val_loss: 4540.0171 - val_mse: 4540.0171\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.0608 - mse: 10.0608 - val_loss: 4167.8154 - val_mse: 4167.8154\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7700 - mse: 7.7700 - val_loss: 3808.2336 - val_mse: 3808.2336\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.7686 - mse: 12.7686 - val_loss: 3413.8628 - val_mse: 3413.8628\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.0441 - mse: 10.0441 - val_loss: 3075.1887 - val_mse: 3075.1887\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2108 - mse: 7.2108 - val_loss: 2747.1382 - val_mse: 2747.1382\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4992 - mse: 5.4992 - val_loss: 2459.9075 - val_mse: 2459.9075\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6899 - mse: 6.6899 - val_loss: 2159.1689 - val_mse: 2159.1689\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1020 - mse: 4.1020 - val_loss: 1925.9739 - val_mse: 1925.9739\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1855 - mse: 5.1855 - val_loss: 1687.2617 - val_mse: 1687.2617\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4228 - mse: 4.4228 - val_loss: 1467.9548 - val_mse: 1467.9548\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6742 - mse: 2.6742 - val_loss: 1280.8557 - val_mse: 1280.8557\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4632 - mse: 1.4632 - val_loss: 1123.5964 - val_mse: 1123.5964\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4015 - mse: 1.4015 - val_loss: 981.1444 - val_mse: 981.1444\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5376 - mse: 1.5376 - val_loss: 840.2661 - val_mse: 840.2661\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8456 - mse: 0.8456 - val_loss: 735.5598 - val_mse: 735.5598\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7047 - mse: 0.7047 - val_loss: 638.8156 - val_mse: 638.8156\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6674 - mse: 0.6674 - val_loss: 558.6375 - val_mse: 558.6375\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7711 - mse: 0.7711 - val_loss: 492.4716 - val_mse: 492.4716\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2972 - mse: 0.2972 - val_loss: 438.4957 - val_mse: 438.4957\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2772 - mse: 0.2772 - val_loss: 396.8790 - val_mse: 396.8790\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 359.6151 - val_mse: 359.6151\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2748 - mse: 0.2748 - val_loss: 331.5741 - val_mse: 331.5741\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 305.9271 - val_mse: 305.9271\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 282.2868 - val_mse: 282.2868\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2949 - mse: 0.2949 - val_loss: 258.3795 - val_mse: 258.3795\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3169 - mse: 0.3169 - val_loss: 243.9443 - val_mse: 243.9443\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 237.5124 - val_mse: 237.5124\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2894 - mse: 0.2894 - val_loss: 225.3139 - val_mse: 225.3139\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1987 - mse: 0.1987 - val_loss: 216.2616 - val_mse: 216.2616\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 210.6733 - val_mse: 210.6733\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1776 - mse: 0.1776 - val_loss: 206.4208 - val_mse: 206.4208\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 199.9486 - val_mse: 199.9486\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1646 - mse: 0.1646 - val_loss: 193.9872 - val_mse: 193.9872\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1808 - mse: 0.1808 - val_loss: 192.9175 - val_mse: 192.9175\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1495 - mse: 0.1495 - val_loss: 188.6204 - val_mse: 188.6204\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1145 - mse: 0.1145 - val_loss: 189.0495 - val_mse: 189.0495\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 185.8656 - val_mse: 185.8656\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 184.5754 - val_mse: 184.5754\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1917 - mse: 0.1917 - val_loss: 181.4479 - val_mse: 181.4479\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 180.0084 - val_mse: 180.0084\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 173.5687 - val_mse: 173.5687\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1654 - mse: 0.1654 - val_loss: 172.5985 - val_mse: 172.5985\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1763 - mse: 0.1763 - val_loss: 172.1245 - val_mse: 172.1245\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1694 - mse: 0.1694 - val_loss: 168.2949 - val_mse: 168.2949\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1683 - mse: 0.1683 - val_loss: 163.8823 - val_mse: 163.8823\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 161.8195 - val_mse: 161.8195\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2070 - mse: 0.2070 - val_loss: 163.3648 - val_mse: 163.3648\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2078 - mse: 0.2078 - val_loss: 159.9935 - val_mse: 159.9935\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1965 - mse: 0.1965 - val_loss: 158.9246 - val_mse: 158.9246\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1741 - mse: 0.1741 - val_loss: 160.8378 - val_mse: 160.8378\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1851 - mse: 0.1851 - val_loss: 156.3694 - val_mse: 156.3694\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 153.5500 - val_mse: 153.5500\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2085 - mse: 0.2085 - val_loss: 149.5510 - val_mse: 149.5510\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1579 - mse: 0.1579 - val_loss: 149.3099 - val_mse: 149.3099\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1507 - mse: 0.1507 - val_loss: 148.6491 - val_mse: 148.6491\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 143.9340 - val_mse: 143.9340\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 140.2470 - val_mse: 140.2470\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1317 - mse: 0.1317 - val_loss: 137.9959 - val_mse: 137.9959\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1495 - mse: 0.1495 - val_loss: 138.1459 - val_mse: 138.1459\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 138.1450 - val_mse: 138.1450\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 133.4872 - val_mse: 133.4872\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 131.8909 - val_mse: 131.8909\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 131.3664 - val_mse: 131.3664\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1724 - mse: 0.1724 - val_loss: 129.6559 - val_mse: 129.6559\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 127.3078 - val_mse: 127.3078\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 122.5009 - val_mse: 122.5009\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1698 - mse: 0.1698 - val_loss: 122.3595 - val_mse: 122.3595\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 120.3996 - val_mse: 120.3996\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 120.1291 - val_mse: 120.1291\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2050 - mse: 0.2050 - val_loss: 120.5862 - val_mse: 120.5862\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 116.6380 - val_mse: 116.6380\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 116.0388 - val_mse: 116.0388\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 113.1328 - val_mse: 113.1328\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 113.2747 - val_mse: 113.2747\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 107.6674 - val_mse: 107.6674\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1484 - mse: 0.1484 - val_loss: 106.3019 - val_mse: 106.3019\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 104.2629 - val_mse: 104.2629\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 105.5793 - val_mse: 105.5793\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 99.4465 - val_mse: 99.4465\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 96.4369 - val_mse: 96.4369\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 97.6240 - val_mse: 97.6240\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 95.7485 - val_mse: 95.7485\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 93.9262 - val_mse: 93.9262\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 93.6967 - val_mse: 93.6967\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 90.1380 - val_mse: 90.1380\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 89.8919 - val_mse: 89.8919\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 87.5667 - val_mse: 87.5667\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 86.3989 - val_mse: 86.3989\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 85.1895 - val_mse: 85.1895\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 83.1777 - val_mse: 83.1777\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0601 - mse: 0.0601 - val_loss: 82.0553 - val_mse: 82.0553\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0788 - mse: 0.0788 - val_loss: 81.4241 - val_mse: 81.4241\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 77.8293 - val_mse: 77.8293\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 77.7610 - val_mse: 77.7610\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 76.5472 - val_mse: 76.5472\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 74.1312 - val_mse: 74.1312\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 73.5829 - val_mse: 73.5829\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 72.5770 - val_mse: 72.5770\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 68.9290 - val_mse: 68.9290\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0787 - mse: 0.0787 - val_loss: 69.3107 - val_mse: 69.3107\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 65.1911 - val_mse: 65.1911\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 63.5379 - val_mse: 63.5379\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0765 - mse: 0.0765 - val_loss: 63.3914 - val_mse: 63.3914\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 65.0696 - val_mse: 65.0696\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 62.3505 - val_mse: 62.3505\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0773 - mse: 0.0773 - val_loss: 62.7028 - val_mse: 62.7028\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 58.2771 - val_mse: 58.2771\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 57.9669 - val_mse: 57.9669\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 56.8740 - val_mse: 56.8740\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 54.9743 - val_mse: 54.9743\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 53.6068 - val_mse: 53.6068\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 52.8049 - val_mse: 52.8049\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 50.9873 - val_mse: 50.9873\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 50.7921 - val_mse: 50.7921\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 52.4609 - val_mse: 52.4609\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 50.0524 - val_mse: 50.0524\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 46.8651 - val_mse: 46.8651\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 44.9173 - val_mse: 44.9173\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 45.3185 - val_mse: 45.3185\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 43.2702 - val_mse: 43.2702\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 44.7680 - val_mse: 44.7680\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 42.8343 - val_mse: 42.8343\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 42.4822 - val_mse: 42.4822\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 39.9978 - val_mse: 39.9978\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 40.4622 - val_mse: 40.4622\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 37.1800 - val_mse: 37.1800\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 36.4843 - val_mse: 36.4843\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 35.5084 - val_mse: 35.5084\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 34.7455 - val_mse: 34.7455\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 34.3171 - val_mse: 34.3171\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 35.9776 - val_mse: 35.9776\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 34.0418 - val_mse: 34.0418\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 32.7435 - val_mse: 32.7435\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 31.0613 - val_mse: 31.0613\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 29.5179 - val_mse: 29.5179\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 29.7885 - val_mse: 29.7885\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 28.6499 - val_mse: 28.6499\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 28.4452 - val_mse: 28.4452\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 27.4170 - val_mse: 27.4170\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 26.1643 - val_mse: 26.1643\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 25.7822 - val_mse: 25.7822\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 25.0814 - val_mse: 25.0814\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 23.5021 - val_mse: 23.5021\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 23.5853 - val_mse: 23.5853\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 23.7623 - val_mse: 23.7623\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 23.3487 - val_mse: 23.3487\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 22.0787 - val_mse: 22.0787\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 20.5255 - val_mse: 20.5255\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 20.2234 - val_mse: 20.2234\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 20.0176 - val_mse: 20.0176\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 20.4959 - val_mse: 20.4959\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 19.9867 - val_mse: 19.9867\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 18.7635 - val_mse: 18.7635\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 18.2347 - val_mse: 18.2347\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 17.2338 - val_mse: 17.2338\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 16.9559 - val_mse: 16.9559\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 15.4795 - val_mse: 15.4795\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 15.4015 - val_mse: 15.4015\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 16.2174 - val_mse: 16.2174\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 15.5499 - val_mse: 15.5499\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 13.8417 - val_mse: 13.8417\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 13.6011 - val_mse: 13.6011\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 14.0256 - val_mse: 14.0256\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 13.1319 - val_mse: 13.1319\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 12.5919 - val_mse: 12.5919\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 12.0324 - val_mse: 12.0324\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 11.5583 - val_mse: 11.5583\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 11.6397 - val_mse: 11.6397\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 11.2839 - val_mse: 11.2839\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 11.0652 - val_mse: 11.0652\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 11.1325 - val_mse: 11.1325\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 10.0090 - val_mse: 10.0090\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 9.4633 - val_mse: 9.4633\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 8.9335 - val_mse: 8.9335\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 9.1574 - val_mse: 9.1574\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 9.2029 - val_mse: 9.2029\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 8.9831 - val_mse: 8.9831\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 8.2539 - val_mse: 8.2539\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 7.6428 - val_mse: 7.6428\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 7.3612 - val_mse: 7.3612\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 7.1671 - val_mse: 7.1671\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 7.1841 - val_mse: 7.1841\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 6.8752 - val_mse: 6.8752\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 6.5227 - val_mse: 6.5227\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 6.9722 - val_mse: 6.9722\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 6.3264 - val_mse: 6.3264\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 5.5977 - val_mse: 5.5977\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 5.4774 - val_mse: 5.4774\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 5.6238 - val_mse: 5.6238\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 5.2102 - val_mse: 5.2102\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 5.3129 - val_mse: 5.3129\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 4.7581 - val_mse: 4.7581\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 4.5626 - val_mse: 4.5626\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 4.4862 - val_mse: 4.4862\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.4599 - val_mse: 4.4599\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 4.2451 - val_mse: 4.2451\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 4.3022 - val_mse: 4.3022\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 3.9425 - val_mse: 3.9425\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 3.8045 - val_mse: 3.8045\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 3.4618 - val_mse: 3.4618\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 3.2318 - val_mse: 3.2318\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 3.3694 - val_mse: 3.3694\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 3.2384 - val_mse: 3.2384\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 2.9895 - val_mse: 2.9895\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.9139 - val_mse: 2.9139\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.6223 - val_mse: 2.6223\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.6587 - val_mse: 2.6587\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.6248 - val_mse: 2.6248\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.4401 - val_mse: 2.4401\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.4109 - val_mse: 2.4109\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 2.1864 - val_mse: 2.1864\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.1367 - val_mse: 2.1367\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.1256 - val_mse: 2.1256\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.0424 - val_mse: 2.0424\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.9210 - val_mse: 1.9210\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.7403 - val_mse: 1.7403\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.6912 - val_mse: 1.6912\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.5721 - val_mse: 1.5721\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.5599 - val_mse: 1.5599\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.4478 - val_mse: 1.4478\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.9026e-04 - mse: 9.9026e-04 - val_loss: 1.5307 - val_mse: 1.5307\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.3604 - val_mse: 1.3604\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.2661 - val_mse: 1.2661\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.6019e-04 - mse: 9.6019e-04 - val_loss: 1.2080 - val_mse: 1.2080\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.1552 - val_mse: 1.1552\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.1173 - val_mse: 1.1173\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.1158 - val_mse: 1.1158\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6483e-04 - mse: 7.6483e-04 - val_loss: 0.9412 - val_mse: 0.9412\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.9050 - val_mse: 0.9050\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.6524e-04 - mse: 9.6524e-04 - val_loss: 0.8744 - val_mse: 0.8744\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3926e-04 - mse: 8.3926e-04 - val_loss: 0.8512 - val_mse: 0.8512\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.0464e-04 - mse: 8.0464e-04 - val_loss: 0.8536 - val_mse: 0.8536\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0791e-04 - mse: 6.0791e-04 - val_loss: 0.7951 - val_mse: 0.7951\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4604e-04 - mse: 6.4604e-04 - val_loss: 0.7005 - val_mse: 0.7005\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4206e-04 - mse: 7.4206e-04 - val_loss: 0.6909 - val_mse: 0.6909\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.6426 - val_mse: 0.6426\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1833e-04 - mse: 7.1833e-04 - val_loss: 0.6411 - val_mse: 0.6411\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.2253e-04 - mse: 7.2253e-04 - val_loss: 0.6301 - val_mse: 0.6301\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0242e-04 - mse: 6.0242e-04 - val_loss: 0.5629 - val_mse: 0.5629\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4283e-04 - mse: 6.4283e-04 - val_loss: 0.5557 - val_mse: 0.5557\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5398e-04 - mse: 4.5398e-04 - val_loss: 0.5205 - val_mse: 0.5205\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9713e-04 - mse: 5.9713e-04 - val_loss: 0.4625 - val_mse: 0.4625\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1887e-04 - mse: 6.1887e-04 - val_loss: 0.4550 - val_mse: 0.4550\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9720e-04 - mse: 5.9720e-04 - val_loss: 0.4392 - val_mse: 0.4392\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1730e-04 - mse: 6.1730e-04 - val_loss: 0.4281 - val_mse: 0.4281\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9218e-04 - mse: 5.9218e-04 - val_loss: 0.4142 - val_mse: 0.4142\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7612e-04 - mse: 3.7612e-04 - val_loss: 0.3564 - val_mse: 0.3564\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4444e-04 - mse: 2.4444e-04 - val_loss: 0.3510 - val_mse: 0.3510\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9802e-04 - mse: 2.9802e-04 - val_loss: 0.3144 - val_mse: 0.3144\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0917e-04 - mse: 3.0917e-04 - val_loss: 0.3255 - val_mse: 0.3255\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1406e-04 - mse: 4.1406e-04 - val_loss: 0.3062 - val_mse: 0.3062\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9392e-04 - mse: 1.9392e-04 - val_loss: 0.2782 - val_mse: 0.2782\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0620e-04 - mse: 4.0620e-04 - val_loss: 0.2705 - val_mse: 0.2705\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1895e-04 - mse: 3.1895e-04 - val_loss: 0.2594 - val_mse: 0.2594\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6575e-04 - mse: 3.6575e-04 - val_loss: 0.2438 - val_mse: 0.2438\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7347e-04 - mse: 2.7347e-04 - val_loss: 0.2198 - val_mse: 0.2198\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9050e-04 - mse: 2.9050e-04 - val_loss: 0.2178 - val_mse: 0.2178\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4630e-04 - mse: 1.4630e-04 - val_loss: 0.1964 - val_mse: 0.1964\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3434e-04 - mse: 1.3434e-04 - val_loss: 0.1824 - val_mse: 0.1824\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9002e-04 - mse: 1.9002e-04 - val_loss: 0.1801 - val_mse: 0.1801\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3355e-04 - mse: 2.3355e-04 - val_loss: 0.1807 - val_mse: 0.1807\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1243e-04 - mse: 2.1243e-04 - val_loss: 0.1597 - val_mse: 0.1597\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4106e-04 - mse: 1.4106e-04 - val_loss: 0.1560 - val_mse: 0.1560\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1199e-04 - mse: 1.1199e-04 - val_loss: 0.1382 - val_mse: 0.1382\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5872e-04 - mse: 1.5872e-04 - val_loss: 0.1344 - val_mse: 0.1344\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1723e-05 - mse: 7.1723e-05 - val_loss: 0.1200 - val_mse: 0.1200\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1089e-05 - mse: 7.1089e-05 - val_loss: 0.1129 - val_mse: 0.1129\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0148e-04 - mse: 1.0148e-04 - val_loss: 0.1140 - val_mse: 0.1140\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5228e-05 - mse: 8.5228e-05 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6254e-05 - mse: 7.6254e-05 - val_loss: 0.1073 - val_mse: 0.1073\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1416e-04 - mse: 1.1416e-04 - val_loss: 0.0941 - val_mse: 0.0941\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4947e-05 - mse: 6.4947e-05 - val_loss: 0.0832 - val_mse: 0.0832\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9066e-05 - mse: 4.9066e-05 - val_loss: 0.0769 - val_mse: 0.0769\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7256e-05 - mse: 5.7256e-05 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7840e-05 - mse: 7.7840e-05 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7531e-05 - mse: 6.7531e-05 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0621e-04 - mse: 1.0621e-04 - val_loss: 0.0600 - val_mse: 0.0600\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3478e-05 - mse: 5.3478e-05 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6953e-05 - mse: 5.6953e-05 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1586e-05 - mse: 4.1586e-05 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.2443e-05 - mse: 8.2443e-05 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5630e-05 - mse: 4.5630e-05 - val_loss: 0.0504 - val_mse: 0.0504\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2442e-05 - mse: 3.2442e-05 - val_loss: 0.0392 - val_mse: 0.0392\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1486e-05 - mse: 3.1486e-05 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2362e-05 - mse: 3.2362e-05 - val_loss: 0.0399 - val_mse: 0.0399\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8077e-05 - mse: 2.8077e-05 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8792e-05 - mse: 2.8792e-05 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8819e-05 - mse: 3.8819e-05 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6493e-05 - mse: 2.6493e-05 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0276\n",
            "loss :  0.02761554718017578\n",
            "결과물 : \n",
            " [[100.84148 ]\n",
            " [101.83979 ]\n",
            " [102.838104]\n",
            " [103.836426]\n",
            " [104.83474 ]\n",
            " [105.83305 ]\n",
            " [106.83137 ]\n",
            " [107.82968 ]\n",
            " [108.827995]\n",
            " [109.82631 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrg8SaSNDlgr",
        "outputId": "684f42ef-7b75-4d32-8940-505254fea782"
      },
      "source": [
        "# RMSE 구하기 \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "\n",
        "print('RMSE : ', RMSE(y_test ,y_predict))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :  0.16617615553804171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69qoZGmvEd3v"
      },
      "source": [
        "이어서 RMSE와 함께 회귀 분석에서 가장 많이 쓰는 지표인 R2를 구해보자.\n",
        "\n",
        "R2는 여러 가지로 불린다. R2, R2 Score, R제곱, 설명력, 결정계수 등이 있지만 보통 R2 또는 결정계수로 많이 불린다. \n",
        "\n",
        "RMSE와 반대로 높을수록 좋은 지표이며, 0-1 사이의 수치가 출력된다. \n",
        "\n",
        "만약 0,73의 값이 나온다면, 내가 만든 모델식이 R2로 계산했을 떄 73%의 설명력을 가진다고 해석할 수 있다.\n",
        "\n",
        "R2는 사이킷런에서 함수 형태로 제공해주기 때문에 사이킷런을 import해서 그대로 사용하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs6PFeJyDwaL",
        "outputId": "3f2aa9ad-29d6-416b-e9ac-ba5d99aefdd3"
      },
      "source": [
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 :  0.9966527861006784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHGKE0jgFsoH"
      },
      "source": [
        "## 4.2. 회귀 모델 코드 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ary17hIgF1HH"
      },
      "source": [
        "### 4.2.1. Validation 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL9BzAs2F5Au"
      },
      "source": [
        "앞에서 모델을 훈련시킬 때(fit) 검증값을 test로 하였다. 그러나 훈련셋에 검증값이 들어가고 그 검증값으로 다시 테스트를 한다는 것은 평가에 검증값이 반영되는 문제가 있다. \n",
        "\n",
        "따라서 **훈련셋, 테스트셋, 검증셋은 엄밀히 분리가 되는 것이 좋은 데이터의 형태이다.**\n",
        "\n",
        "**일반적으로 Train 데이터의 일부를 잘라서 Validation 데이터로 사용하는 것이 좋다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEx7SXvFKg8",
        "outputId": "3f22c4f1-be64-4f33-c3df-cbefe1625430"
      },
      "source": [
        "# 1. 데이터 준비\n",
        "import numpy as np\n",
        "x_train = np.array([1,2,3,3,4,5,6,7,8,9,10])\n",
        "y_train = np.array([1,2,3,3,4,5,6,7,8,9,10])\n",
        "\n",
        "x_test = np.array([11,12,13,14,15,16,17,18,19,20])\n",
        "y_test = np.array([11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "x_val = np.array([101,102,103,104,105])\n",
        "y_val = np.array([101,102,103,104,105])\n",
        "\n",
        "\n",
        "# 2. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 3. 모델 훈련\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "# 4. 평가예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('mse : ', mse)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 25.2323 - mse: 25.2323 - val_loss: 12458.6465 - val_mse: 12458.6465\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 51.6139 - mse: 51.6139 - val_loss: 11569.2480 - val_mse: 11569.2480\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.4380 - mse: 27.4380 - val_loss: 10832.1621 - val_mse: 10832.1621\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 38.3012 - mse: 38.3012 - val_loss: 10039.5391 - val_mse: 10039.5391\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 23.8661 - mse: 23.8661 - val_loss: 9342.2812 - val_mse: 9342.2812\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 30.6957 - mse: 30.6957 - val_loss: 8543.5137 - val_mse: 8543.5137\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.2914 - mse: 21.2914 - val_loss: 7798.6982 - val_mse: 7798.6982\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.4165 - mse: 22.4165 - val_loss: 7007.5850 - val_mse: 7007.5850\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.3107 - mse: 19.3107 - val_loss: 6224.4307 - val_mse: 6224.4307\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1510 - mse: 10.1510 - val_loss: 5441.2588 - val_mse: 5441.2588\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.2969 - mse: 14.2969 - val_loss: 4635.4375 - val_mse: 4635.4375\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6157 - mse: 7.6157 - val_loss: 3874.4585 - val_mse: 3874.4585\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.0992 - mse: 7.0992 - val_loss: 3149.0979 - val_mse: 3149.0979\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9191 - mse: 4.9191 - val_loss: 2553.7024 - val_mse: 2553.7024\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5776 - mse: 5.5776 - val_loss: 1969.2917 - val_mse: 1969.2917\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7103 - mse: 2.7103 - val_loss: 1555.1860 - val_mse: 1555.1860\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.6908 - mse: 1.6908 - val_loss: 1216.3328 - val_mse: 1216.3328\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.9352 - mse: 0.9352 - val_loss: 982.5724 - val_mse: 982.5724\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7362 - mse: 1.7362 - val_loss: 750.0674 - val_mse: 750.0674\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5509 - mse: 0.5509 - val_loss: 626.2430 - val_mse: 626.2430\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5636 - mse: 0.5636 - val_loss: 525.9326 - val_mse: 525.9326\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5220 - mse: 0.5220 - val_loss: 454.0519 - val_mse: 454.0519\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4120 - mse: 0.4120 - val_loss: 404.7726 - val_mse: 404.7726\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3077 - mse: 0.3077 - val_loss: 383.3039 - val_mse: 383.3039\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5688 - mse: 0.5688 - val_loss: 363.8477 - val_mse: 363.8477\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 354.7167 - val_mse: 354.7167\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4906 - mse: 0.4906 - val_loss: 353.9641 - val_mse: 353.9641\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2588 - mse: 0.2588 - val_loss: 350.1271 - val_mse: 350.1271\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3261 - mse: 0.3261 - val_loss: 331.6143 - val_mse: 331.6143\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2942 - mse: 0.2942 - val_loss: 318.7062 - val_mse: 318.7062\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2482 - mse: 0.2482 - val_loss: 314.8569 - val_mse: 314.8569\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4212 - mse: 0.4212 - val_loss: 320.1034 - val_mse: 320.1034\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 313.2812 - val_mse: 313.2812\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3083 - mse: 0.3083 - val_loss: 302.1240 - val_mse: 302.1240\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3560 - mse: 0.3560 - val_loss: 291.0043 - val_mse: 291.0043\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3377 - mse: 0.3377 - val_loss: 291.4348 - val_mse: 291.4348\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3031 - mse: 0.3031 - val_loss: 286.3483 - val_mse: 286.3483\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2894 - mse: 0.2894 - val_loss: 276.0494 - val_mse: 276.0494\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3924 - mse: 0.3924 - val_loss: 261.3023 - val_mse: 261.3023\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2922 - mse: 0.2922 - val_loss: 261.0937 - val_mse: 261.0937\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3663 - mse: 0.3663 - val_loss: 261.3852 - val_mse: 261.3852\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2022 - mse: 0.2022 - val_loss: 248.4641 - val_mse: 248.4641\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2022 - mse: 0.2022 - val_loss: 235.0352 - val_mse: 235.0352\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1501 - mse: 0.1501 - val_loss: 236.8331 - val_mse: 236.8331\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1698 - mse: 0.1698 - val_loss: 241.7886 - val_mse: 241.7886\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2794 - mse: 0.2794 - val_loss: 232.7137 - val_mse: 232.7137\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2641 - mse: 0.2641 - val_loss: 227.7420 - val_mse: 227.7420\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2758 - mse: 0.2758 - val_loss: 222.9742 - val_mse: 222.9742\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2465 - mse: 0.2465 - val_loss: 215.0241 - val_mse: 215.0241\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2084 - mse: 0.2084 - val_loss: 210.3606 - val_mse: 210.3606\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2391 - mse: 0.2391 - val_loss: 189.2327 - val_mse: 189.2327\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1316 - mse: 0.1316 - val_loss: 185.0264 - val_mse: 185.0264\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1904 - mse: 0.1904 - val_loss: 177.0695 - val_mse: 177.0695\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1409 - mse: 0.1409 - val_loss: 186.7267 - val_mse: 186.7267\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2487 - mse: 0.2487 - val_loss: 178.2729 - val_mse: 178.2729\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1957 - mse: 0.1957 - val_loss: 179.2697 - val_mse: 179.2697\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1534 - mse: 0.1534 - val_loss: 175.1008 - val_mse: 175.1008\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1743 - mse: 0.1743 - val_loss: 168.0469 - val_mse: 168.0469\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1086 - mse: 0.1086 - val_loss: 151.9251 - val_mse: 151.9251\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1515 - mse: 0.1515 - val_loss: 148.7817 - val_mse: 148.7817\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 143.9572 - val_mse: 143.9572\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 140.0741 - val_mse: 140.0741\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 134.6066 - val_mse: 134.6066\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 138.5801 - val_mse: 138.5801\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1518 - mse: 0.1518 - val_loss: 133.0794 - val_mse: 133.0794\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 126.9017 - val_mse: 126.9017\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1572 - mse: 0.1572 - val_loss: 120.7579 - val_mse: 120.7579\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 115.3430 - val_mse: 115.3430\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1391 - mse: 0.1391 - val_loss: 118.2307 - val_mse: 118.2307\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1510 - mse: 0.1510 - val_loss: 111.2221 - val_mse: 111.2221\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1653 - mse: 0.1653 - val_loss: 104.1688 - val_mse: 104.1688\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 104.6171 - val_mse: 104.6171\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 101.4652 - val_mse: 101.4652\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 98.5620 - val_mse: 98.5620\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 90.5401 - val_mse: 90.5401\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0722 - mse: 0.0722 - val_loss: 84.3909 - val_mse: 84.3909\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 86.5922 - val_mse: 86.5922\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1155 - mse: 0.1155 - val_loss: 85.1096 - val_mse: 85.1096\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 79.3342 - val_mse: 79.3342\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 76.0923 - val_mse: 76.0923\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 69.4214 - val_mse: 69.4214\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 69.5357 - val_mse: 69.5357\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 71.3864 - val_mse: 71.3864\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 67.6939 - val_mse: 67.6939\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 61.5139 - val_mse: 61.5139\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 60.5470 - val_mse: 60.5470\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 60.4347 - val_mse: 60.4347\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 54.9793 - val_mse: 54.9793\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 53.8639 - val_mse: 53.8639\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 49.9315 - val_mse: 49.9315\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 51.2366 - val_mse: 51.2366\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 48.8510 - val_mse: 48.8510\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 43.3619 - val_mse: 43.3619\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 40.3097 - val_mse: 40.3097\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 40.5311 - val_mse: 40.5311\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 40.7250 - val_mse: 40.7250\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 36.6493 - val_mse: 36.6493\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 35.7945 - val_mse: 35.7945\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 32.2845 - val_mse: 32.2845\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 33.7169 - val_mse: 33.7169\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 31.3099 - val_mse: 31.3099\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 30.2120 - val_mse: 30.2120\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 27.7565 - val_mse: 27.7565\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 28.1619 - val_mse: 28.1619\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 24.5412 - val_mse: 24.5412\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 22.7662 - val_mse: 22.7662\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 23.7283 - val_mse: 23.7283\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 22.4651 - val_mse: 22.4651\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 20.5570 - val_mse: 20.5570\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 18.5499 - val_mse: 18.5499\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 18.4494 - val_mse: 18.4494\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 18.7211 - val_mse: 18.7211\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 17.1797 - val_mse: 17.1797\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 15.5058 - val_mse: 15.5058\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 15.2859 - val_mse: 15.2859\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 14.8574 - val_mse: 14.8574\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 13.8874 - val_mse: 13.8874\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 12.1113 - val_mse: 12.1113\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 13.2207 - val_mse: 13.2207\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 11.5421 - val_mse: 11.5421\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 11.3474 - val_mse: 11.3474\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 9.7240 - val_mse: 9.7240\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 9.5588 - val_mse: 9.5588\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 9.0589 - val_mse: 9.0589\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 9.1109 - val_mse: 9.1109\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 8.0424 - val_mse: 8.0424\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 7.6309 - val_mse: 7.6309\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 6.8602 - val_mse: 6.8602\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 6.4367 - val_mse: 6.4367\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 6.1737 - val_mse: 6.1737\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 6.4855 - val_mse: 6.4855\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 5.5738 - val_mse: 5.5738\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 5.0801 - val_mse: 5.0801\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 4.8323 - val_mse: 4.8323\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 4.8461 - val_mse: 4.8461\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 4.5656 - val_mse: 4.5656\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 4.1338 - val_mse: 4.1338\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 3.4578 - val_mse: 3.4578\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 3.5015 - val_mse: 3.5015\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.1981 - val_mse: 3.1981\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 3.2329 - val_mse: 3.2329\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.9237 - val_mse: 2.9237\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.6549 - val_mse: 2.6549\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.6036 - val_mse: 2.6036\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.4255 - val_mse: 2.4255\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.0438 - val_mse: 2.0438\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.9559 - val_mse: 1.9559\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.0100 - val_mse: 2.0100\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.8678 - val_mse: 1.8678\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4847 - val_mse: 1.4847\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.5230 - val_mse: 1.5230\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.5716 - val_mse: 1.5716\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.2006 - val_mse: 1.2006\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.2257 - val_mse: 1.2257\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.9744 - val_mse: 0.9744\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.0561 - val_mse: 1.0561\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0033e-04 - mse: 8.0033e-04 - val_loss: 0.8850 - val_mse: 0.8850\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2299e-04 - mse: 8.2299e-04 - val_loss: 0.9889 - val_mse: 0.9889\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.7920 - val_mse: 0.7920\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.2999e-04 - mse: 9.2999e-04 - val_loss: 0.7120 - val_mse: 0.7120\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.8364e-04 - mse: 9.8364e-04 - val_loss: 0.7009 - val_mse: 0.7009\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.6777e-04 - mse: 7.6777e-04 - val_loss: 0.6096 - val_mse: 0.6096\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2327e-04 - mse: 7.2327e-04 - val_loss: 0.5576 - val_mse: 0.5576\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0387e-04 - mse: 6.0387e-04 - val_loss: 0.5904 - val_mse: 0.5904\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.2929e-04 - mse: 6.2929e-04 - val_loss: 0.5058 - val_mse: 0.5058\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2497e-04 - mse: 5.2497e-04 - val_loss: 0.4293 - val_mse: 0.4293\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1043e-04 - mse: 6.1043e-04 - val_loss: 0.4031 - val_mse: 0.4031\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6377e-04 - mse: 5.6377e-04 - val_loss: 0.3958 - val_mse: 0.3958\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4360e-04 - mse: 5.4360e-04 - val_loss: 0.3555 - val_mse: 0.3555\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2537e-04 - mse: 3.2537e-04 - val_loss: 0.3277 - val_mse: 0.3277\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0454e-04 - mse: 3.0454e-04 - val_loss: 0.3122 - val_mse: 0.3122\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3662e-04 - mse: 3.3662e-04 - val_loss: 0.2857 - val_mse: 0.2857\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.3649e-04 - mse: 3.3649e-04 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6407e-04 - mse: 2.6407e-04 - val_loss: 0.2281 - val_mse: 0.2281\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4615e-04 - mse: 3.4615e-04 - val_loss: 0.2034 - val_mse: 0.2034\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2254e-04 - mse: 1.2254e-04 - val_loss: 0.2050 - val_mse: 0.2050\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3671e-04 - mse: 2.3671e-04 - val_loss: 0.2078 - val_mse: 0.2078\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4535e-04 - mse: 1.4535e-04 - val_loss: 0.1342 - val_mse: 0.1342\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4774e-04 - mse: 1.4774e-04 - val_loss: 0.1365 - val_mse: 0.1365\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5879e-04 - mse: 1.5879e-04 - val_loss: 0.1477 - val_mse: 0.1477\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2216e-04 - mse: 1.2216e-04 - val_loss: 0.1434 - val_mse: 0.1434\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6041e-04 - mse: 1.6041e-04 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.1458e-04 - mse: 1.1458e-04 - val_loss: 0.0983 - val_mse: 0.0983\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7611e-05 - mse: 8.7611e-05 - val_loss: 0.0789 - val_mse: 0.0789\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2075e-04 - mse: 1.2075e-04 - val_loss: 0.0891 - val_mse: 0.0891\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1924e-04 - mse: 1.1924e-04 - val_loss: 0.0721 - val_mse: 0.0721\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0224e-04 - mse: 1.0224e-04 - val_loss: 0.0791 - val_mse: 0.0791\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9578e-05 - mse: 8.9578e-05 - val_loss: 0.0698 - val_mse: 0.0698\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9683e-05 - mse: 6.9683e-05 - val_loss: 0.0511 - val_mse: 0.0511\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8277e-05 - mse: 8.8277e-05 - val_loss: 0.0494 - val_mse: 0.0494\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2218e-05 - mse: 5.2218e-05 - val_loss: 0.0454 - val_mse: 0.0454\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4284e-05 - mse: 4.4284e-05 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8741e-05 - mse: 3.8741e-05 - val_loss: 0.0456 - val_mse: 0.0456\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9882e-05 - mse: 4.9882e-05 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7108e-05 - mse: 3.7108e-05 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5762e-05 - mse: 3.5762e-05 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4527e-05 - mse: 2.4527e-05 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7684e-05 - mse: 3.7684e-05 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4205e-05 - mse: 2.4205e-05 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1070e-05 - mse: 2.1070e-05 - val_loss: 0.0194 - val_mse: 0.0194\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6489e-05 - mse: 2.6489e-05 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7916e-05 - mse: 1.7916e-05 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4303e-05 - mse: 2.4303e-05 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5940e-05 - mse: 1.5940e-05 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.0288e-05 - mse: 1.0288e-05 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0693e-05 - mse: 1.0693e-05 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.6612e-06 - mse: 8.6612e-06 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7658e-06 - mse: 7.7658e-06 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1414e-06 - mse: 7.1414e-06 - val_loss: 0.0064 - val_mse: 0.0064\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.3545e-06 - mse: 9.3545e-06 - val_loss: 0.0067 - val_mse: 0.0067\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7676e-06 - mse: 5.7676e-06 - val_loss: 0.0062 - val_mse: 0.0062\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8859e-06 - mse: 6.8859e-06 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8372e-06 - mse: 7.8372e-06 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7753e-06 - mse: 3.7753e-06 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4256e-06 - mse: 5.4256e-06 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0920e-06 - mse: 3.0920e-06 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6548e-06 - mse: 4.6548e-06 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4437e-06 - mse: 2.4437e-06 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1834e-06 - mse: 2.1834e-06 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5175e-06 - mse: 1.5175e-06 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0746e-06 - mse: 2.0746e-06 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1376e-06 - mse: 2.1376e-06 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4688e-06 - mse: 1.4688e-06 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7346e-06 - mse: 1.7346e-06 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1962e-06 - mse: 1.1962e-06 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3127e-06 - mse: 1.3127e-06 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0137e-07 - mse: 9.0137e-07 - val_loss: 8.6342e-04 - val_mse: 8.6342e-04\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4352e-06 - mse: 1.4352e-06 - val_loss: 8.7340e-04 - val_mse: 8.7340e-04\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6664e-07 - mse: 8.6664e-07 - val_loss: 6.5276e-04 - val_mse: 6.5276e-04\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5735e-07 - mse: 9.5735e-07 - val_loss: 5.5079e-04 - val_mse: 5.5079e-04\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8720e-07 - mse: 4.8720e-07 - val_loss: 5.3954e-04 - val_mse: 5.3954e-04\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9482e-07 - mse: 4.9482e-07 - val_loss: 4.3901e-04 - val_mse: 4.3901e-04\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8755e-07 - mse: 7.8755e-07 - val_loss: 4.1281e-04 - val_mse: 4.1281e-04\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3883e-07 - mse: 4.3883e-07 - val_loss: 3.6469e-04 - val_mse: 3.6469e-04\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9390e-07 - mse: 3.9390e-07 - val_loss: 2.4582e-04 - val_mse: 2.4582e-04\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4499e-07 - mse: 2.4499e-07 - val_loss: 2.9098e-04 - val_mse: 2.9098e-04\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5943e-07 - mse: 3.5943e-07 - val_loss: 2.3177e-04 - val_mse: 2.3177e-04\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2901e-07 - mse: 2.2901e-07 - val_loss: 1.9896e-04 - val_mse: 1.9896e-04\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3328e-07 - mse: 1.3328e-07 - val_loss: 1.8157e-04 - val_mse: 1.8157e-04\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3969e-07 - mse: 2.3969e-07 - val_loss: 1.6985e-04 - val_mse: 1.6985e-04\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1260e-07 - mse: 1.1260e-07 - val_loss: 1.5511e-04 - val_mse: 1.5511e-04\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3660e-07 - mse: 1.3660e-07 - val_loss: 1.2506e-04 - val_mse: 1.2506e-04\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.2527e-07 - mse: 1.2527e-07 - val_loss: 7.7050e-05 - val_mse: 7.7050e-05\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2964e-07 - mse: 1.2964e-07 - val_loss: 9.6224e-05 - val_mse: 9.6224e-05\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2208e-07 - mse: 1.2208e-07 - val_loss: 9.3078e-05 - val_mse: 9.3078e-05\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2128e-08 - mse: 8.2128e-08 - val_loss: 5.1861e-05 - val_mse: 5.1861e-05\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0192e-07 - mse: 1.0192e-07 - val_loss: 5.5893e-05 - val_mse: 5.5893e-05\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8423e-08 - mse: 7.8423e-08 - val_loss: 6.2850e-05 - val_mse: 6.2850e-05\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7878e-08 - mse: 5.7878e-08 - val_loss: 4.3261e-05 - val_mse: 4.3261e-05\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4852e-08 - mse: 6.4852e-08 - val_loss: 3.3805e-05 - val_mse: 3.3805e-05\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2377e-08 - mse: 3.2377e-08 - val_loss: 3.8161e-05 - val_mse: 3.8161e-05\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9031e-08 - mse: 3.9031e-08 - val_loss: 2.6826e-05 - val_mse: 2.6826e-05\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6869e-08 - mse: 3.6869e-08 - val_loss: 2.9598e-05 - val_mse: 2.9598e-05\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0896e-08 - mse: 3.0896e-08 - val_loss: 1.7141e-05 - val_mse: 1.7141e-05\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9175e-08 - mse: 2.9175e-08 - val_loss: 1.8559e-05 - val_mse: 1.8559e-05\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6194e-08 - mse: 1.6194e-08 - val_loss: 1.3808e-05 - val_mse: 1.3808e-05\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2207e-08 - mse: 2.2207e-08 - val_loss: 1.4648e-05 - val_mse: 1.4648e-05\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6345e-08 - mse: 1.6345e-08 - val_loss: 1.1979e-05 - val_mse: 1.1979e-05\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6493e-09 - mse: 8.6493e-09 - val_loss: 9.6820e-06 - val_mse: 9.6820e-06\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5081e-09 - mse: 9.5081e-09 - val_loss: 6.8335e-06 - val_mse: 6.8335e-06\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1862e-09 - mse: 6.1862e-09 - val_loss: 7.3619e-06 - val_mse: 7.3619e-06\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9093e-09 - mse: 7.9093e-09 - val_loss: 6.3863e-06 - val_mse: 6.3863e-06\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9290e-09 - mse: 4.9290e-09 - val_loss: 4.9099e-06 - val_mse: 4.9099e-06\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7853e-09 - mse: 4.7853e-09 - val_loss: 5.0871e-06 - val_mse: 5.0871e-06\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7777e-09 - mse: 4.7777e-09 - val_loss: 3.6095e-06 - val_mse: 3.6095e-06\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0049e-09 - mse: 4.0049e-09 - val_loss: 2.5579e-06 - val_mse: 2.5579e-06\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9850e-09 - mse: 3.9850e-09 - val_loss: 2.8850e-06 - val_mse: 2.8850e-06\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0475e-09 - mse: 3.0475e-09 - val_loss: 2.6963e-06 - val_mse: 2.6963e-06\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1432e-09 - mse: 3.1432e-09 - val_loss: 1.6161e-06 - val_mse: 1.6161e-06\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8454e-09 - mse: 1.8454e-09 - val_loss: 1.7424e-06 - val_mse: 1.7424e-06\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0454e-09 - mse: 1.0454e-09 - val_loss: 1.7065e-06 - val_mse: 1.7065e-06\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2789e-09 - mse: 2.2789e-09 - val_loss: 1.3844e-06 - val_mse: 1.3844e-06\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0245e-09 - mse: 1.0245e-09 - val_loss: 9.6594e-07 - val_mse: 9.6594e-07\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0469e-10 - mse: 7.0469e-10 - val_loss: 9.3320e-07 - val_mse: 9.3320e-07\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3917e-10 - mse: 5.3917e-10 - val_loss: 8.8930e-07 - val_mse: 8.8930e-07\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6960e-10 - mse: 7.6960e-10 - val_loss: 6.8918e-07 - val_mse: 6.8918e-07\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5538e-10 - mse: 9.5538e-10 - val_loss: 5.5685e-07 - val_mse: 5.5685e-07\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9117e-10 - mse: 5.9117e-10 - val_loss: 5.3204e-07 - val_mse: 5.3204e-07\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1352e-10 - mse: 7.1352e-10 - val_loss: 4.6535e-07 - val_mse: 4.6535e-07\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8101e-10 - mse: 3.8101e-10 - val_loss: 4.0710e-07 - val_mse: 4.0710e-07\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5294e-10 - mse: 3.5294e-10 - val_loss: 2.4604e-07 - val_mse: 2.4604e-07\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8014e-10 - mse: 2.8014e-10 - val_loss: 2.4752e-07 - val_mse: 2.4752e-07\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0036e-10 - mse: 2.0036e-10 - val_loss: 2.4152e-07 - val_mse: 2.4152e-07\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2813e-10 - mse: 1.2813e-10 - val_loss: 2.2819e-07 - val_mse: 2.2819e-07\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5393e-10 - mse: 2.5393e-10 - val_loss: 1.9053e-07 - val_mse: 1.9053e-07\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8296e-10 - mse: 1.8296e-10 - val_loss: 1.6355e-07 - val_mse: 1.6355e-07\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6051e-10 - mse: 1.6051e-10 - val_loss: 1.4096e-07 - val_mse: 1.4096e-07\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6312e-10 - mse: 1.6312e-10 - val_loss: 1.3642e-07 - val_mse: 1.3642e-07\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0289e-10 - mse: 1.0289e-10 - val_loss: 1.2860e-07 - val_mse: 1.2860e-07\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3474e-10 - mse: 1.3474e-10 - val_loss: 1.0079e-07 - val_mse: 1.0079e-07\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1876e-11 - mse: 9.1876e-11 - val_loss: 9.9803e-08 - val_mse: 9.9803e-08\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5968e-11 - mse: 7.5968e-11 - val_loss: 8.7661e-08 - val_mse: 8.7661e-08\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0647e-11 - mse: 7.0647e-11 - val_loss: 7.7137e-08 - val_mse: 7.7137e-08\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6523e-11 - mse: 6.6523e-11 - val_loss: 6.9721e-08 - val_mse: 6.9721e-08\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2525e-11 - mse: 7.2525e-11 - val_loss: 5.9628e-08 - val_mse: 5.9628e-08\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3479e-11 - mse: 5.3479e-11 - val_loss: 5.7428e-08 - val_mse: 5.7428e-08\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9262e-11 - mse: 3.9262e-11 - val_loss: 5.6694e-08 - val_mse: 5.6694e-08\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2586e-11 - mse: 4.2586e-11 - val_loss: 5.1700e-08 - val_mse: 5.1700e-08\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8788e-11 - mse: 3.8788e-11 - val_loss: 4.7626e-08 - val_mse: 4.7626e-08\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2439e-11 - mse: 3.2439e-11 - val_loss: 3.9989e-08 - val_mse: 3.9989e-08\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7042e-11 - mse: 3.7042e-11 - val_loss: 3.5239e-08 - val_mse: 3.5239e-08\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5959e-11 - mse: 2.5959e-11 - val_loss: 3.4098e-08 - val_mse: 3.4098e-08\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6651e-11 - mse: 4.6651e-11 - val_loss: 3.0291e-08 - val_mse: 3.0291e-08\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6914e-11 - mse: 1.6914e-11 - val_loss: 2.9220e-08 - val_mse: 2.9220e-08\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5297e-11 - mse: 2.5297e-11 - val_loss: 2.5693e-08 - val_mse: 2.5693e-08\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9162e-11 - mse: 1.9162e-11 - val_loss: 2.4715e-08 - val_mse: 2.4715e-08\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9964e-11 - mse: 2.9964e-11 - val_loss: 2.2829e-08 - val_mse: 2.2829e-08\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2207e-11 - mse: 2.2207e-11 - val_loss: 2.2375e-08 - val_mse: 2.2375e-08\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9786e-11 - mse: 1.9786e-11 - val_loss: 2.0582e-08 - val_mse: 2.0582e-08\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5302e-11 - mse: 1.5302e-11 - val_loss: 1.9721e-08 - val_mse: 1.9721e-08\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1621e-11 - mse: 2.1621e-11 - val_loss: 1.7660e-08 - val_mse: 1.7660e-08\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7770e-12 - mse: 9.7770e-12 - val_loss: 1.6845e-08 - val_mse: 1.6845e-08\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1096e-12 - mse: 9.1096e-12 - val_loss: 1.6845e-08 - val_mse: 1.6845e-08\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6834e-12 - mse: 8.6834e-12 - val_loss: 1.5670e-08 - val_mse: 1.5670e-08\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0899e-11 - mse: 1.0899e-11 - val_loss: 1.4924e-08 - val_mse: 1.4924e-08\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3381e-12 - mse: 9.3381e-12 - val_loss: 1.4540e-08 - val_mse: 1.4540e-08\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8546e-12 - mse: 9.8546e-12 - val_loss: 1.3097e-08 - val_mse: 1.3097e-08\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6276e-11 - mse: 1.6276e-11 - val_loss: 1.2084e-08 - val_mse: 1.2084e-08\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1647e-11 - mse: 1.1647e-11 - val_loss: 1.1746e-08 - val_mse: 1.1746e-08\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9593e-12 - mse: 8.9593e-12 - val_loss: 1.0780e-08 - val_mse: 1.0780e-08\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1005e-11 - mse: 1.1005e-11 - val_loss: 1.0151e-08 - val_mse: 1.0151e-08\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0662e-11 - mse: 1.0662e-11 - val_loss: 9.5693e-09 - val_mse: 9.5693e-09\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9755e-12 - mse: 9.9755e-12 - val_loss: 8.9640e-09 - val_mse: 8.9640e-09\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5362e-12 - mse: 8.5362e-12 - val_loss: 8.9640e-09 - val_mse: 8.9640e-09\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9131e-12 - mse: 8.9131e-12 - val_loss: 7.8464e-09 - val_mse: 7.8464e-09\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8900e-12 - mse: 7.8900e-12 - val_loss: 7.0664e-09 - val_mse: 7.0664e-09\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3834e-12 - mse: 7.3834e-12 - val_loss: 7.0664e-09 - val_mse: 7.0664e-09\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1984e-12 - mse: 5.1984e-12 - val_loss: 7.0664e-09 - val_mse: 7.0664e-09\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3162e-12 - mse: 4.3162e-12 - val_loss: 7.0664e-09 - val_mse: 7.0664e-09\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8663e-12 - mse: 4.8663e-12 - val_loss: 6.8219e-09 - val_mse: 6.8219e-09\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5782e-12 - mse: 4.5782e-12 - val_loss: 6.5542e-09 - val_mse: 6.5542e-09\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1469e-12 - mse: 5.1469e-12 - val_loss: 6.3097e-09 - val_mse: 6.3097e-09\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4335e-12 - mse: 4.4335e-12 - val_loss: 6.0652e-09 - val_mse: 6.0652e-09\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2297e-12 - mse: 5.2297e-12 - val_loss: 5.8440e-09 - val_mse: 5.8440e-09\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5906e-12 - mse: 3.5906e-12 - val_loss: 5.5996e-09 - val_mse: 5.5996e-09\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6654e-12 - mse: 4.6654e-12 - val_loss: 5.5996e-09 - val_mse: 5.5996e-09\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0650e-12 - mse: 5.0650e-12 - val_loss: 4.9360e-09 - val_mse: 4.9360e-09\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9895e-12 - mse: 2.9895e-12 - val_loss: 4.9360e-09 - val_mse: 4.9360e-09\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7200e-12 - mse: 3.7200e-12 - val_loss: 4.9360e-09 - val_mse: 4.9360e-09\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0092e-12 - mse: 4.0092e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9613e-12 - mse: 3.9613e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1659e-12 - mse: 3.1659e-12 - val_loss: 4.5402e-09 - val_mse: 4.5402e-09\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2860e-12 - mse: 4.2860e-12 - val_loss: 4.1211e-09 - val_mse: 4.1211e-09\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2889e-12 - mse: 2.2889e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5370e-12 - mse: 2.5370e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7065e-12 - mse: 2.7065e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5091e-12 - mse: 3.5091e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6812e-12 - mse: 1.6812e-12 - val_loss: 4.7381e-09 - val_mse: 4.7381e-09\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6829e-12 - mse: 2.6829e-12 - val_loss: 4.1211e-09 - val_mse: 4.1211e-09\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7642e-12 - mse: 1.7642e-12 - val_loss: 3.9232e-09 - val_mse: 3.9232e-09\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8781e-12 - mse: 2.8781e-12 - val_loss: 3.9232e-09 - val_mse: 3.9232e-09\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8125e-12 - mse: 2.8125e-12 - val_loss: 3.9232e-09 - val_mse: 3.9232e-09\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.7895e-12 - mse: 1.7895e-12 - val_loss: 3.7253e-09 - val_mse: 3.7253e-09\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.8147e-12 - mse: 1.8147e-12 - val_loss: 3.7253e-09 - val_mse: 3.7253e-09\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0564e-12 - mse: 1.0564e-12 - val_loss: 3.5507e-09 - val_mse: 3.5507e-09\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3014e-12 - mse: 1.3014e-12 - val_loss: 3.5507e-09 - val_mse: 3.5507e-09\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4498e-12 - mse: 1.4498e-12 - val_loss: 3.5507e-09 - val_mse: 3.5507e-09\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6992e-12 - mse: 2.6992e-12 - val_loss: 3.3760e-09 - val_mse: 3.3760e-09\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7598e-12 - mse: 1.7598e-12 - val_loss: 3.2014e-09 - val_mse: 3.2014e-09\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7411e-12 - mse: 2.7411e-12 - val_loss: 3.2014e-09 - val_mse: 3.2014e-09\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5519e-12 - mse: 1.5519e-12 - val_loss: 3.0501e-09 - val_mse: 3.0501e-09\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9866e-12 - mse: 2.9866e-12 - val_loss: 2.8755e-09 - val_mse: 2.8755e-09\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3196e-12 - mse: 2.3196e-12 - val_loss: 2.8755e-09 - val_mse: 2.8755e-09\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6812e-12 - mse: 3.6812e-12 - val_loss: 2.8755e-09 - val_mse: 2.8755e-09\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0428e-12 - mse: 3.0428e-12 - val_loss: 2.7241e-09 - val_mse: 2.7241e-09\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2981e-12 - mse: 1.2981e-12 - val_loss: 2.7241e-09 - val_mse: 2.7241e-09\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7247e-12 - mse: 1.7247e-12 - val_loss: 2.7241e-09 - val_mse: 2.7241e-09\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6089e-12 - mse: 1.6089e-12 - val_loss: 2.2468e-09 - val_mse: 2.2468e-09\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8891e-12 - mse: 1.8891e-12 - val_loss: 2.2468e-09 - val_mse: 2.2468e-09\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9028e-12 - mse: 1.9028e-12 - val_loss: 2.2468e-09 - val_mse: 2.2468e-09\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8195e-12 - mse: 1.8195e-12 - val_loss: 1.9674e-09 - val_mse: 1.9674e-09\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1486e-12 - mse: 1.1486e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5283e-12 - mse: 1.5283e-12 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1778e-12 - mse: 2.1778e-12 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1904e-12 - mse: 2.1904e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3026e-12 - mse: 1.3026e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1175e-12 - mse: 2.1175e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8109e-12 - mse: 1.8109e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0906e-12 - mse: 1.0906e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8640e-13 - mse: 8.8640e-13 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4837e-12 - mse: 1.4837e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0068e-12 - mse: 1.0068e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7009e-12 - mse: 2.7009e-12 - val_loss: 1.3504e-09 - val_mse: 1.3504e-09\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9682e-13 - mse: 9.9682e-13 - val_loss: 1.3504e-09 - val_mse: 1.3504e-09\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1230e-12 - mse: 1.1230e-12 - val_loss: 1.3504e-09 - val_mse: 1.3504e-09\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1858e-12 - mse: 1.1858e-12 - val_loss: 1.3504e-09 - val_mse: 1.3504e-09\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6864e-13 - mse: 9.6864e-13 - val_loss: 1.3504e-09 - val_mse: 1.3504e-09\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2974e-13 - mse: 8.2974e-13 - val_loss: 1.2456e-09 - val_mse: 1.2456e-09\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5034e-13 - mse: 6.5034e-13 - val_loss: 1.2456e-09 - val_mse: 1.2456e-09\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1437e-13 - mse: 6.1437e-13 - val_loss: 1.1409e-09 - val_mse: 1.1409e-09\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4424e-13 - mse: 6.4424e-13 - val_loss: 1.1409e-09 - val_mse: 1.1409e-09\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1948e-13 - mse: 8.1948e-13 - val_loss: 1.0361e-09 - val_mse: 1.0361e-09\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6829e-13 - mse: 6.6829e-13 - val_loss: 1.0361e-09 - val_mse: 1.0361e-09\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2436e-13 - mse: 9.2436e-13 - val_loss: 1.0361e-09 - val_mse: 1.0361e-09\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3179e-13 - mse: 7.3179e-13 - val_loss: 1.0361e-09 - val_mse: 1.0361e-09\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5986e-13 - mse: 8.5986e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0577e-12 - mse: 1.0577e-12 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6013e-13 - mse: 9.6013e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9108e-13 - mse: 6.9108e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4130e-13 - mse: 6.4130e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6315e-13 - mse: 4.6315e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0178e-13 - mse: 4.0178e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1627e-13 - mse: 6.1627e-13 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8425e-13 - mse: 7.8425e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0085e-12 - mse: 1.0085e-12 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8728e-13 - mse: 2.8728e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1948e-13 - mse: 4.1948e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2019e-13 - mse: 2.2019e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1604e-13 - mse: 2.1604e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7127e-13 - mse: 2.7127e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9563e-13 - mse: 2.9563e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4812e-13 - mse: 1.4812e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8045e-13 - mse: 1.8045e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9677e-13 - mse: 2.9677e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3224e-13 - mse: 1.3224e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2764e-13 - mse: 3.2764e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9292e-13 - mse: 2.9292e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.1140e-13 - mse: 3.1140e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6719e-13 - mse: 2.6719e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1908e-13 - mse: 1.1908e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5027e-13 - mse: 1.5027e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9134e-13 - mse: 2.9134e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8724e-13 - mse: 1.8724e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5073e-13 - mse: 1.5073e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2144e-13 - mse: 3.2144e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0078e-13 - mse: 1.0078e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2659e-13 - mse: 2.2659e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2982e-13 - mse: 3.2982e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2702e-13 - mse: 1.2702e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6588e-13 - mse: 1.6588e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1884e-13 - mse: 1.1884e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0889e-13 - mse: 3.0889e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3662e-13 - mse: 1.3662e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8673e-13 - mse: 1.8673e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2442e-13 - mse: 2.2442e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6783e-13 - mse: 1.6783e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9725e-13 - mse: 2.9725e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1976e-13 - mse: 2.1976e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.3654e-13 - mse: 3.3654e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0393e-13 - mse: 2.0393e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6724e-13 - mse: 3.6724e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5500e-13 - mse: 1.5500e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1653e-13 - mse: 1.1653e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9366e-13 - mse: 2.9366e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6945e-13 - mse: 1.6945e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7579e-13 - mse: 3.7579e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0967e-13 - mse: 2.0967e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1926e-13 - mse: 2.1926e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3222e-13 - mse: 2.3222e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6403e-14 - mse: 9.6403e-14 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5386e-13 - mse: 1.5386e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9641e-13 - mse: 2.9641e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5333e-13 - mse: 3.5333e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0094e-13 - mse: 3.0094e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3203e-13 - mse: 2.3203e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4987e-13 - mse: 1.4987e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7242e-13 - mse: 1.7242e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5256e-14 - mse: 9.5256e-14 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0401e-13 - mse: 1.0401e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2972e-13 - mse: 2.2972e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9131e-13 - mse: 1.9131e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8658e-13 - mse: 1.8658e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8319e-13 - mse: 1.8319e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1526e-13 - mse: 1.1526e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0516e-13 - mse: 3.0516e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4733e-13 - mse: 3.4733e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4926e-13 - mse: 2.4926e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0843e-13 - mse: 1.0843e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6049e-13 - mse: 1.6049e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2543e-13 - mse: 1.2543e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9842e-13 - mse: 1.9842e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4625e-13 - mse: 1.4625e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3548e-14 - mse: 9.3548e-14 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8327e-13 - mse: 1.8327e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4179e-13 - mse: 2.4179e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8798e-13 - mse: 1.8798e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5436e-13 - mse: 2.5436e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9755e-13 - mse: 1.9755e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1182e-13 - mse: 3.1182e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5706e-13 - mse: 1.5706e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.6282e-13 - mse: 1.6282e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0043e-13 - mse: 2.0043e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.4483e-13 - mse: 1.4483e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.4687e-13 - mse: 1.4687e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0126e-13 - mse: 1.0126e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.1658e-13 - mse: 2.1658e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9657e-13 - mse: 2.9657e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1426e-13 - mse: 1.1426e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0281e-13 - mse: 2.0281e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0504e-13 - mse: 2.0504e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2807e-13 - mse: 2.2807e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0573e-13 - mse: 2.0573e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4637e-13 - mse: 3.4637e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1281e-13 - mse: 2.1281e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0025e-13 - mse: 1.0025e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7289e-13 - mse: 2.7289e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1578e-13 - mse: 1.1578e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2743e-14 - mse: 6.2743e-14 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1964e-13 - mse: 2.1964e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4919e-13 - mse: 1.4919e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3660e-12 - mse: 5.3660e-12\n",
            "mse :  [5.36601882719645e-12, 5.36601882719645e-12]\n",
            "[[10.999999]\n",
            " [11.999997]\n",
            " [12.999998]\n",
            " [13.999998]\n",
            " [14.999999]\n",
            " [15.999998]\n",
            " [16.999996]\n",
            " [17.999996]\n",
            " [18.999998]\n",
            " [19.999996]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNe4aFJkHanO"
      },
      "source": [
        "1에서 10까지의 데이터를 훈련시킬 때 101에서 105의 데이터를 검증용 데이터로 사용한다. 이후 11에서 20까지의 데이터로 테스트한다.\n",
        "\n",
        "mse는 5.36601882719645e-12로 아주 낮은 수치가 나왔고, predict도 거의 정확하게 나왔다. \n",
        "\n",
        "이제 여기에 RMSE와 R2를 추가해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCx4GdkOHXkh",
        "outputId": "682b5f99-5776-4c20-cfc4-56baf42dd8ed"
      },
      "source": [
        "# RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "  return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :  2.6117446780451113e-06\n",
            "R2 :  0.9999999999991732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd1pxhFQIgs_"
      },
      "source": [
        "-> RMSE는 낮을수록, R2는 1에 가까울수록 정확한 예측치가 된다. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D41ZWabjIzjP"
      },
      "source": [
        "### 4.2.2 데이터 분리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U0xLmTLN1IV"
      },
      "source": [
        "#### (1) 테스트 데이터로 예측하는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6l-YHDyI4qI"
      },
      "source": [
        "이번에는 데이터를 일일이 쓰지 않고, 1부터 100까지의 정수형 데이터셋을 잘라서 사용해보겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soOu3GXXIbdM"
      },
      "source": [
        "# 1. 데이터 준비\n",
        "x = np.array(range(1,101))\n",
        "y = np.array(range(1,101))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6F9zlGsJUYE"
      },
      "source": [
        "데이터셋이 준비되었으니 이제 이것을 6:2:2의 비율(Train:Val:Test)로 나눠보겠다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFy_0qDIJKuO"
      },
      "source": [
        "# 2. Train:Val:Test로 나누기\n",
        "x_train = x[:60]\n",
        "x_val = x[60:80]\n",
        "x_test = x[80:]\n",
        "\n",
        "y_train = y[:60]\n",
        "y_val = y[60:80]\n",
        "y_test = y[80:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vZZGYrhJz7U",
        "outputId": "96eb9ccd-83a8-4e2d-f2f9-d1de4fc15efd"
      },
      "source": [
        "# 3. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 4. 모델 훈련\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "# 5. 평가예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('mse : ', mse)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)\n",
        "\n",
        "# 6. RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "  return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# 7. R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 1627.5283 - mse: 1627.5283 - val_loss: 5772.1870 - val_mse: 5772.1870\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1381.8638 - mse: 1381.8638 - val_loss: 4661.1470 - val_mse: 4661.1470\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1071.1294 - mse: 1071.1294 - val_loss: 3206.3130 - val_mse: 3206.3130\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 699.7870 - mse: 699.7870 - val_loss: 1691.9359 - val_mse: 1691.9359\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 284.3376 - mse: 284.3376 - val_loss: 456.1407 - val_mse: 456.1407\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 58.2506 - mse: 58.2506 - val_loss: 51.9423 - val_mse: 51.9423\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2156 - mse: 5.2156 - val_loss: 4.2126 - val_mse: 4.2126\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8562 - mse: 0.8562 - val_loss: 2.3800 - val_mse: 2.3800\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8509 - mse: 0.8509 - val_loss: 2.0162 - val_mse: 2.0162\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7950 - mse: 0.7950 - val_loss: 2.0457 - val_mse: 2.0457\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8232 - mse: 0.8232 - val_loss: 1.9937 - val_mse: 1.9937\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9238 - mse: 0.9238 - val_loss: 1.7125 - val_mse: 1.7125\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8510 - mse: 0.8510 - val_loss: 1.7046 - val_mse: 1.7046\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6538 - mse: 0.6538 - val_loss: 2.3174 - val_mse: 2.3174\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8905 - mse: 0.8905 - val_loss: 1.4937 - val_mse: 1.4937\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5412 - mse: 0.5412 - val_loss: 1.4391 - val_mse: 1.4391\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7887 - mse: 0.7887 - val_loss: 1.2678 - val_mse: 1.2678\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7979 - mse: 0.7979 - val_loss: 2.0073 - val_mse: 2.0073\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6920 - mse: 0.6920 - val_loss: 1.8071 - val_mse: 1.8071\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6022 - mse: 0.6022 - val_loss: 1.5449 - val_mse: 1.5449\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7564 - mse: 0.7564 - val_loss: 1.5724 - val_mse: 1.5724\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6337 - mse: 0.6337 - val_loss: 1.2629 - val_mse: 1.2629\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4958 - mse: 0.4958 - val_loss: 1.0791 - val_mse: 1.0791\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4877 - mse: 0.4877 - val_loss: 1.4669 - val_mse: 1.4669\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5450 - mse: 0.5450 - val_loss: 1.0442 - val_mse: 1.0442\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4524 - mse: 0.4524 - val_loss: 0.9712 - val_mse: 0.9712\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4898 - mse: 0.4898 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3332 - mse: 0.3332 - val_loss: 1.3339 - val_mse: 1.3339\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3670 - mse: 0.3670 - val_loss: 0.7040 - val_mse: 0.7040\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5117 - mse: 0.5117 - val_loss: 0.9990 - val_mse: 0.9990\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 1.2130 - val_mse: 1.2130\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3475 - mse: 0.3475 - val_loss: 1.2162 - val_mse: 1.2162\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.9958 - val_mse: 0.9958\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3060 - mse: 0.3060 - val_loss: 0.5518 - val_mse: 0.5518\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3088 - mse: 0.3088 - val_loss: 0.5266 - val_mse: 0.5266\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3250 - mse: 0.3250 - val_loss: 0.7696 - val_mse: 0.7696\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2225 - mse: 0.2225 - val_loss: 0.8863 - val_mse: 0.8863\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2483 - mse: 0.2483 - val_loss: 0.5090 - val_mse: 0.5090\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.3979 - val_mse: 0.3979\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.5412 - val_mse: 0.5412\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1961 - mse: 0.1961 - val_loss: 0.5127 - val_mse: 0.5127\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1936 - mse: 0.1936 - val_loss: 0.5947 - val_mse: 0.5947\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1627 - mse: 0.1627 - val_loss: 0.4088 - val_mse: 0.4088\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1674 - mse: 0.1674 - val_loss: 0.4446 - val_mse: 0.4446\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1522 - mse: 0.1522 - val_loss: 0.3738 - val_mse: 0.3738\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.3556 - val_mse: 0.3556\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 0.1757 - val_mse: 0.1757\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 0.1411 - val_mse: 0.1411\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.2853 - val_mse: 0.2853\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 0.1166 - val_mse: 0.1166\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.1814 - val_mse: 0.1814\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.1907 - val_mse: 0.1907\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.1372 - val_mse: 0.1372\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.1557 - val_mse: 0.1557\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0648 - val_mse: 0.0648\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.1292 - val_mse: 0.1292\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0958 - val_mse: 0.0958\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0701 - val_mse: 0.0701\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0486 - val_mse: 0.0486\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.9760e-04 - mse: 6.9760e-04 - val_loss: 8.0004e-04 - val_mse: 8.0004e-04\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0146e-04 - mse: 6.0146e-04 - val_loss: 9.1611e-04 - val_mse: 9.1611e-04\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4059e-04 - mse: 5.4059e-04 - val_loss: 5.2970e-04 - val_mse: 5.2970e-04\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.6220e-04 - mse: 3.6220e-04 - val_loss: 4.9076e-04 - val_mse: 4.9076e-04\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5686e-04 - mse: 2.5686e-04 - val_loss: 5.6185e-04 - val_mse: 5.6185e-04\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1063e-04 - mse: 2.1063e-04 - val_loss: 2.8255e-04 - val_mse: 2.8255e-04\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4983e-04 - mse: 1.4983e-04 - val_loss: 3.4781e-06 - val_mse: 3.4781e-06\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2026e-04 - mse: 1.2026e-04 - val_loss: 2.3501e-04 - val_mse: 2.3501e-04\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.6225e-05 - mse: 8.6225e-05 - val_loss: 1.3451e-04 - val_mse: 1.3451e-04\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3336e-05 - mse: 4.3336e-05 - val_loss: 2.9338e-04 - val_mse: 2.9338e-04\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4946e-05 - mse: 5.4946e-05 - val_loss: 6.3812e-05 - val_mse: 6.3812e-05\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0423e-05 - mse: 2.0423e-05 - val_loss: 9.7289e-05 - val_mse: 9.7289e-05\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3186e-05 - mse: 1.3186e-05 - val_loss: 6.7563e-05 - val_mse: 6.7563e-05\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3802e-05 - mse: 1.3802e-05 - val_loss: 2.2109e-05 - val_mse: 2.2109e-05\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0154e-05 - mse: 1.0154e-05 - val_loss: 1.8951e-05 - val_mse: 1.8951e-05\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.6868e-06 - mse: 5.6868e-06 - val_loss: 1.0432e-05 - val_mse: 1.0432e-05\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7541e-06 - mse: 3.7541e-06 - val_loss: 3.8812e-06 - val_mse: 3.8812e-06\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0965e-06 - mse: 2.0965e-06 - val_loss: 9.8762e-06 - val_mse: 9.8762e-06\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6898e-06 - mse: 1.6898e-06 - val_loss: 8.3149e-06 - val_mse: 8.3149e-06\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3768e-06 - mse: 1.3768e-06 - val_loss: 7.4130e-07 - val_mse: 7.4130e-07\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2600e-07 - mse: 5.2600e-07 - val_loss: 9.9498e-07 - val_mse: 9.9498e-07\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1496e-07 - mse: 4.1496e-07 - val_loss: 1.0266e-06 - val_mse: 1.0266e-06\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2605e-07 - mse: 2.2605e-07 - val_loss: 1.1332e-08 - val_mse: 1.1332e-08\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7249e-07 - mse: 1.7249e-07 - val_loss: 1.1906e-07 - val_mse: 1.1906e-07\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4513e-08 - mse: 6.4513e-08 - val_loss: 2.0992e-07 - val_mse: 2.0992e-07\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3572e-08 - mse: 3.3572e-08 - val_loss: 2.4113e-09 - val_mse: 2.4113e-09\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5650e-08 - mse: 3.5650e-08 - val_loss: 3.4916e-08 - val_mse: 3.4916e-08\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4459e-08 - mse: 1.4459e-08 - val_loss: 4.1036e-10 - val_mse: 4.1036e-10\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.9840e-09 - mse: 6.9840e-09 - val_loss: 4.1327e-10 - val_mse: 4.1327e-10\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4564e-09 - mse: 3.4564e-09 - val_loss: 6.6291e-09 - val_mse: 6.6291e-09\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9351e-09 - mse: 1.9351e-09 - val_loss: 9.8080e-10 - val_mse: 9.8080e-10\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6573e-10 - mse: 7.6573e-10 - val_loss: 7.5452e-10 - val_mse: 7.5452e-10\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.8435e-10 - mse: 6.8435e-10 - val_loss: 5.4424e-10 - val_mse: 5.4424e-10\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7679e-10 - mse: 2.7679e-10 - val_loss: 1.0346e-09 - val_mse: 1.0346e-09\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4323e-10 - mse: 1.4323e-10 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8704e-11 - mse: 4.8704e-11 - val_loss: 1.7535e-10 - val_mse: 1.7535e-10\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7090e-11 - mse: 3.7090e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9141e-11 - mse: 1.9141e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.2047e-12 - mse: 8.2047e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0561e-12 - mse: 9.0561e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1795e-11 - mse: 1.1795e-11 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.3917e-12 - mse: 7.3917e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5551e-12 - mse: 4.5551e-12 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.2159e-12 - mse: 9.2159e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7759e-12 - mse: 4.7759e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.6599e-12 - mse: 5.6599e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2357e-12 - mse: 7.2357e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4001e-12 - mse: 5.4001e-12 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3058e-12 - mse: 8.3058e-12 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0131e-12 - mse: 9.0131e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8219e-12 - mse: 7.8219e-12 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.9355e-12 - mse: 8.9355e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0365e-11 - mse: 1.0365e-11 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2445e-12 - mse: 7.2445e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0113e-12 - mse: 8.0113e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1066e-12 - mse: 6.1066e-12 - val_loss: 5.6025e-11 - val_mse: 5.6025e-11\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0532e-12 - mse: 9.0532e-12 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3855e-12 - mse: 6.3855e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6171e-12 - mse: 7.6171e-12 - val_loss: 1.0259e-10 - val_mse: 1.0259e-10\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6737e-11 - mse: 1.6737e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.9736e-12 - mse: 5.9736e-12 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5301e-12 - mse: 8.5301e-12 - val_loss: 6.8394e-11 - val_mse: 6.8394e-11\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1373e-12 - mse: 6.1373e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6349e-12 - mse: 7.6349e-12 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2367e-11 - mse: 1.2367e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0798e-11 - mse: 3.0798e-11 - val_loss: 6.3301e-11 - val_mse: 6.3301e-11\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8625e-11 - mse: 1.8625e-11 - val_loss: 6.8394e-11 - val_mse: 6.8394e-11\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9810e-11 - mse: 5.9810e-11 - val_loss: 1.0477e-10 - val_mse: 1.0477e-10\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9689e-11 - mse: 1.9689e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 9.6770e-11 - val_mse: 9.6770e-11\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4129e-11 - mse: 1.4129e-11 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0765e-12 - mse: 8.0765e-12 - val_loss: 1.1642e-11 - val_mse: 1.1642e-11\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5553e-12 - mse: 5.5553e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5768e-12 - mse: 9.5768e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0477e-11 - mse: 1.0477e-11 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6346e-11 - mse: 1.6346e-11 - val_loss: 8.8039e-11 - val_mse: 8.8039e-11\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2331e-10 - mse: 3.2331e-10 - val_loss: 1.9354e-10 - val_mse: 1.9354e-10\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6104e-08 - mse: 1.6104e-08 - val_loss: 9.4857e-09 - val_mse: 9.4857e-09\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4026e-07 - mse: 7.4026e-07 - val_loss: 6.7773e-06 - val_mse: 6.7773e-06\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0994e-06 - mse: 7.0994e-06 - val_loss: 5.7305e-06 - val_mse: 5.7305e-06\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2578e-05 - mse: 4.2578e-05 - val_loss: 6.2240e-06 - val_mse: 6.2240e-06\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7213e-05 - mse: 7.7213e-05 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.4175 - val_mse: 0.4175\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.2028 - val_mse: 0.2028\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 6.3193e-04 - val_mse: 6.3193e-04\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8909e-05 - mse: 7.8909e-05 - val_loss: 1.9706e-06 - val_mse: 1.9706e-06\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7882e-05 - mse: 4.7882e-05 - val_loss: 1.1220e-05 - val_mse: 1.1220e-05\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.9583e-06 - mse: 7.9583e-06 - val_loss: 9.4239e-07 - val_mse: 9.4239e-07\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4765e-07 - mse: 5.4765e-07 - val_loss: 1.1386e-06 - val_mse: 1.1386e-06\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.3626e-06 - mse: 7.3626e-06 - val_loss: 1.0045e-07 - val_mse: 1.0045e-07\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3196e-05 - mse: 1.3196e-05 - val_loss: 2.2753e-06 - val_mse: 2.2753e-06\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8635e-07 - mse: 1.8635e-07 - val_loss: 6.0984e-08 - val_mse: 6.0984e-08\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7734e-08 - mse: 2.7734e-08 - val_loss: 2.2873e-08 - val_mse: 2.2873e-08\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.5541e-10 - mse: 7.5541e-10 - val_loss: 4.2928e-10 - val_mse: 4.2928e-10\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1604e-11 - mse: 6.1604e-11 - val_loss: 1.0550e-10 - val_mse: 1.0550e-10\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3359e-10 - mse: 1.3359e-10 - val_loss: 5.1445e-08 - val_mse: 5.1445e-08\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3726e-09 - mse: 4.3726e-09 - val_loss: 2.0518e-09 - val_mse: 2.0518e-09\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5603e-09 - mse: 3.5603e-09 - val_loss: 1.1714e-10 - val_mse: 1.1714e-10\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3283e-09 - mse: 1.3283e-09 - val_loss: 1.4195e-09 - val_mse: 1.4195e-09\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.7080e-10 - mse: 4.7080e-10 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6661e-11 - mse: 1.6661e-11 - val_loss: 1.2151e-10 - val_mse: 1.2151e-10\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4119e-11 - mse: 3.4119e-11 - val_loss: 1.3606e-10 - val_mse: 1.3606e-10\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0504e-11 - mse: 1.0504e-11 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3440e-11 - mse: 2.3440e-11 - val_loss: 1.6225e-10 - val_mse: 1.6225e-10\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5732e-10 - mse: 1.5732e-10 - val_loss: 2.0642e-09 - val_mse: 2.0642e-09\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0741e-10 - mse: 3.0741e-10 - val_loss: 2.5757e-10 - val_mse: 2.5757e-10\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6824e-11 - mse: 1.6824e-11 - val_loss: 8.6584e-11 - val_mse: 8.6584e-11\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0057e-11 - mse: 2.0057e-11 - val_loss: 1.5803e-09 - val_mse: 1.5803e-09\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.9646e-10 - mse: 5.9646e-10 - val_loss: 2.6483e-07 - val_mse: 2.6483e-07\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4135e-06 - mse: 6.4135e-06 - val_loss: 3.7420e-04 - val_mse: 3.7420e-04\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7497e-04 - mse: 6.7497e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 9.3881e-06 - val_mse: 9.3881e-06\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.1670 - val_mse: 0.1670\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 1.4198e-05 - val_mse: 1.4198e-05\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0171 - val_mse: 0.0171\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0454 - val_mse: 0.0454\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 4.4847e-04 - val_mse: 4.4847e-04\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1174e-04 - mse: 2.1174e-04 - val_loss: 1.0667e-06 - val_mse: 1.0667e-06\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6559e-07 - mse: 2.6559e-07 - val_loss: 9.0756e-08 - val_mse: 9.0756e-08\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0418e-08 - mse: 1.0418e-08 - val_loss: 9.6203e-09 - val_mse: 9.6203e-09\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0978e-09 - mse: 1.0978e-09 - val_loss: 1.9281e-10 - val_mse: 1.9281e-10\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6895e-11 - mse: 1.6895e-11 - val_loss: 5.5297e-11 - val_mse: 5.5297e-11\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2373e-12 - mse: 5.2373e-12 - val_loss: 6.6939e-11 - val_mse: 6.6939e-11\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.9269e-12 - mse: 7.9269e-12 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1948e-11 - mse: 1.1948e-11 - val_loss: 3.0850e-10 - val_mse: 3.0850e-10\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5299e-11 - mse: 5.5299e-11 - val_loss: 6.7303e-10 - val_mse: 6.7303e-10\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5633e-10 - mse: 1.5633e-10 - val_loss: 3.1483e-09 - val_mse: 3.1483e-09\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8933e-10 - mse: 1.8933e-10 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6827e-12 - mse: 6.6827e-12 - val_loss: 6.4756e-11 - val_mse: 6.4756e-11\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0640e-12 - mse: 7.0640e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0824e-11 - mse: 2.0824e-11 - val_loss: 1.8699e-10 - val_mse: 1.8699e-10\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7441e-11 - mse: 2.7441e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2194e-12 - mse: 4.2194e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1677e-10 - mse: 1.1677e-10 - val_loss: 5.8935e-10 - val_mse: 5.8935e-10\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9995e-11 - mse: 3.9995e-11 - val_loss: 6.8394e-11 - val_mse: 6.8394e-11\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9399e-10 - mse: 1.9399e-10 - val_loss: 3.6832e-08 - val_mse: 3.6832e-08\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.2847e-08 - mse: 9.2847e-08 - val_loss: 2.0428e-06 - val_mse: 2.0428e-06\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.7774e-07 - mse: 8.7774e-07 - val_loss: 3.5178e-06 - val_mse: 3.5178e-06\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0507e-06 - mse: 2.0507e-06 - val_loss: 2.0133e-08 - val_mse: 2.0133e-08\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.0899e-08 - mse: 6.0899e-08 - val_loss: 8.7166e-10 - val_mse: 8.7166e-10\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5077e-07 - mse: 1.5077e-07 - val_loss: 8.5870e-07 - val_mse: 8.5870e-07\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3293e-07 - mse: 3.3293e-07 - val_loss: 2.3092e-06 - val_mse: 2.3092e-06\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4008e-06 - mse: 1.4008e-06 - val_loss: 8.9780e-05 - val_mse: 8.9780e-05\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4266e-05 - mse: 3.4266e-05 - val_loss: 2.5912e-07 - val_mse: 2.5912e-07\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4468e-04 - mse: 1.4468e-04 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.1240 - val_mse: 0.1240\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0784 - val_mse: 0.0784\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0825 - mse: 0.0825 - val_loss: 2.1237 - val_mse: 2.1237\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4940 - mse: 0.4940 - val_loss: 0.6001 - val_mse: 0.6001\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 9.9914e-04 - val_mse: 9.9914e-04\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1032e-04 - mse: 2.1032e-04 - val_loss: 7.6999e-04 - val_mse: 7.6999e-04\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0209e-05 - mse: 4.0209e-05 - val_loss: 1.3649e-04 - val_mse: 1.3649e-04\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7499e-05 - mse: 1.7499e-05 - val_loss: 4.8497e-05 - val_mse: 4.8497e-05\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5664e-06 - mse: 3.5664e-06 - val_loss: 1.8419e-06 - val_mse: 1.8419e-06\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2109e-07 - mse: 7.2109e-07 - val_loss: 2.9575e-07 - val_mse: 2.9575e-07\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5090e-07 - mse: 3.5090e-07 - val_loss: 2.8484e-07 - val_mse: 2.8484e-07\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3992e-07 - mse: 1.3992e-07 - val_loss: 1.6879e-08 - val_mse: 1.6879e-08\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1570e-08 - mse: 1.1570e-08 - val_loss: 8.4692e-09 - val_mse: 8.4692e-09\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0966e-09 - mse: 5.0966e-09 - val_loss: 4.8771e-09 - val_mse: 4.8771e-09\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7020e-10 - mse: 7.7020e-10 - val_loss: 7.0577e-11 - val_mse: 7.0577e-11\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0409e-10 - mse: 2.0409e-10 - val_loss: 1.0477e-10 - val_mse: 1.0477e-10\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2367e-11 - mse: 4.2367e-11 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2154e-12 - mse: 6.2154e-12 - val_loss: 5.8935e-11 - val_mse: 5.8935e-11\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0957e-12 - mse: 6.0957e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8136e-12 - mse: 7.8136e-12 - val_loss: 5.8935e-11 - val_mse: 5.8935e-11\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7110e-11 - mse: 1.7110e-11 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.6376e-12 - mse: 3.6376e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.8754e-12 - mse: 3.8754e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0013e-12 - mse: 5.0013e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2659e-12 - mse: 3.2659e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1704e-12 - mse: 4.1704e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5451e-12 - mse: 2.5451e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.4733e-12 - mse: 4.4733e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1824e-12 - mse: 4.1824e-12 - val_loss: 1.1642e-11 - val_mse: 1.1642e-11\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0210e-12 - mse: 5.0210e-12 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.1080e-12 - mse: 9.1080e-12 - val_loss: 5.5297e-11 - val_mse: 5.5297e-11\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1229e-11 - mse: 2.1229e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9266e-11 - mse: 2.9266e-11 - val_loss: 8.2218e-11 - val_mse: 8.2218e-11\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8363e-11 - mse: 1.8363e-11 - val_loss: 1.2369e-11 - val_mse: 1.2369e-11\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1491e-12 - mse: 6.1491e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0256e-12 - mse: 6.0256e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1106e-12 - mse: 3.1106e-12 - val_loss: 5.8208e-11 - val_mse: 5.8208e-11\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6670e-11 - mse: 1.6670e-11 - val_loss: 8.0763e-11 - val_mse: 8.0763e-11\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0750e-11 - mse: 1.0750e-11 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8095e-12 - mse: 4.8095e-12 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1960e-11 - mse: 2.1960e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8685e-12 - mse: 7.8685e-12 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0181e-11 - mse: 1.0181e-11 - val_loss: 3.7107e-10 - val_mse: 3.7107e-10\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9266e-11 - mse: 5.9266e-11 - val_loss: 1.7244e-10 - val_mse: 1.7244e-10\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2108e-11 - mse: 5.2108e-11 - val_loss: 8.4881e-09 - val_mse: 8.4881e-09\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1802e-10 - mse: 6.1802e-10 - val_loss: 5.9837e-09 - val_mse: 5.9837e-09\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9457e-09 - mse: 2.9457e-09 - val_loss: 1.7608e-10 - val_mse: 1.7608e-10\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2150e-11 - mse: 2.2150e-11 - val_loss: 1.0405e-10 - val_mse: 1.0405e-10\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0065e-11 - mse: 1.0065e-11 - val_loss: 4.8749e-11 - val_mse: 4.8749e-11\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1631e-11 - mse: 1.1631e-11 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8350e-11 - mse: 1.8350e-11 - val_loss: 5.9663e-11 - val_mse: 5.9663e-11\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7912e-11 - mse: 2.7912e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7256e-09 - mse: 1.7256e-09 - val_loss: 6.9796e-08 - val_mse: 6.9796e-08\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.6841e-08 - mse: 6.6841e-08 - val_loss: 7.6252e-10 - val_mse: 7.6252e-10\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8117e-09 - mse: 3.8117e-09 - val_loss: 1.8124e-09 - val_mse: 1.8124e-09\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8295e-08 - mse: 5.8295e-08 - val_loss: 4.0405e-05 - val_mse: 4.0405e-05\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8022e-05 - mse: 1.8022e-05 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0364e-04 - mse: 1.0364e-04 - val_loss: 1.5742e-04 - val_mse: 1.5742e-04\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0398 - val_mse: 0.0398\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.2182 - val_mse: 0.2182\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 5.9930e-04 - val_mse: 5.9930e-04\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1687e-04 - mse: 2.1687e-04 - val_loss: 3.7373e-05 - val_mse: 3.7373e-05\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4844e-06 - mse: 6.4844e-06 - val_loss: 8.6490e-06 - val_mse: 8.6490e-06\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1220e-07 - mse: 2.1220e-07 - val_loss: 9.0360e-08 - val_mse: 9.0360e-08\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5275e-09 - mse: 9.5275e-09 - val_loss: 1.9772e-08 - val_mse: 1.9772e-08\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0051e-08 - mse: 1.0051e-08 - val_loss: 2.8376e-10 - val_mse: 2.8376e-10\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1878e-09 - mse: 6.1878e-09 - val_loss: 1.5505e-09 - val_mse: 1.5505e-09\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3264e-09 - mse: 1.3264e-09 - val_loss: 1.6429e-09 - val_mse: 1.6429e-09\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8611e-09 - mse: 3.8611e-09 - val_loss: 5.1140e-08 - val_mse: 5.1140e-08\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.9754e-08 - mse: 8.9754e-08 - val_loss: 5.4071e-08 - val_mse: 5.4071e-08\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3084e-07 - mse: 3.3084e-07 - val_loss: 1.7963e-06 - val_mse: 1.7963e-06\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7231e-07 - mse: 5.7231e-07 - val_loss: 1.8894e-07 - val_mse: 1.8894e-07\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2044e-08 - mse: 2.2044e-08 - val_loss: 3.4779e-10 - val_mse: 3.4779e-10\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2769e-08 - mse: 3.2769e-08 - val_loss: 1.8252e-08 - val_mse: 1.8252e-08\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2693e-08 - mse: 1.2693e-08 - val_loss: 8.3483e-08 - val_mse: 8.3483e-08\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3655e-09 - mse: 7.3655e-09 - val_loss: 6.1918e-09 - val_mse: 6.1918e-09\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.4740e-09 - mse: 4.4740e-09 - val_loss: 2.8269e-08 - val_mse: 2.8269e-08\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1472e-09 - mse: 3.1472e-09 - val_loss: 1.7317e-10 - val_mse: 1.7317e-10\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.7861e-11 - mse: 9.7861e-11 - val_loss: 5.5443e-10 - val_mse: 5.5443e-10\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4937e-09 - mse: 3.4937e-09 - val_loss: 1.0077e-08 - val_mse: 1.0077e-08\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.6657e-08 - mse: 7.6657e-08 - val_loss: 3.0621e-06 - val_mse: 3.0621e-06\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0013e-07 - mse: 3.0013e-07 - val_loss: 9.2762e-06 - val_mse: 9.2762e-06\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8925e-06 - mse: 3.8925e-06 - val_loss: 1.2137e-05 - val_mse: 1.2137e-05\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5463e-05 - mse: 1.5463e-05 - val_loss: 2.7769e-04 - val_mse: 2.7769e-04\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.1141 - val_mse: 0.1141\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 4.5549e-04 - val_mse: 4.5549e-04\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8846e-04 - mse: 1.8846e-04 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.1891e-06 - val_mse: 2.1891e-06\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.6702e-04 - mse: 3.6702e-04 - val_loss: 0.0059 - val_mse: 0.0059\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.5670e-04 - val_mse: 9.5670e-04\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.6872e-04 - mse: 5.6872e-04 - val_loss: 0.0869 - val_mse: 0.0869\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 1.3390e-04 - val_mse: 1.3390e-04\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4887e-05 - mse: 2.4887e-05 - val_loss: 7.8529e-04 - val_mse: 7.8529e-04\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3527e-05 - mse: 4.3527e-05 - val_loss: 2.8086e-05 - val_mse: 2.8086e-05\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8398e-05 - mse: 1.8398e-05 - val_loss: 1.4205e-07 - val_mse: 1.4205e-07\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2227e-07 - mse: 1.2227e-07 - val_loss: 4.8583e-06 - val_mse: 4.8583e-06\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2519e-06 - mse: 2.2519e-06 - val_loss: 3.3882e-06 - val_mse: 3.3882e-06\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5904e-06 - mse: 1.5904e-06 - val_loss: 1.3613e-08 - val_mse: 1.3613e-08\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1469e-08 - mse: 1.1469e-08 - val_loss: 1.3049e-08 - val_mse: 1.3049e-08\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5828e-05 - mse: 1.5828e-05 - val_loss: 1.4054e-04 - val_mse: 1.4054e-04\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3821e-04 - mse: 3.3821e-04 - val_loss: 4.0989e-06 - val_mse: 4.0989e-06\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0114e-05 - mse: 5.0114e-05 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0807 - val_mse: 0.0807\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0168 - val_mse: 0.0168\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 3.4950e-04 - val_mse: 3.4950e-04\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2728e-05 - mse: 6.2728e-05 - val_loss: 2.4213e-05 - val_mse: 2.4213e-05\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1516e-06 - mse: 5.1516e-06 - val_loss: 6.9015e-07 - val_mse: 6.9015e-07\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6878e-06 - mse: 9.6878e-06 - val_loss: 1.3583e-04 - val_mse: 1.3583e-04\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.0426e-06 - mse: 6.0426e-06 - val_loss: 8.2068e-07 - val_mse: 8.2068e-07\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5200e-06 - mse: 1.5200e-06 - val_loss: 2.4151e-05 - val_mse: 2.4151e-05\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2506e-06 - mse: 1.2506e-06 - val_loss: 2.4032e-05 - val_mse: 2.4032e-05\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7490e-06 - mse: 1.7490e-06 - val_loss: 1.6312e-06 - val_mse: 1.6312e-06\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4840e-06 - mse: 1.4840e-06 - val_loss: 8.8168e-07 - val_mse: 8.8168e-07\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1571e-07 - mse: 2.1571e-07 - val_loss: 1.5180e-06 - val_mse: 1.5180e-06\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3321e-07 - mse: 1.3321e-07 - val_loss: 1.4112e-07 - val_mse: 1.4112e-07\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.6914e-08 - mse: 7.6914e-08 - val_loss: 3.5894e-08 - val_mse: 3.5894e-08\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4536e-09 - mse: 1.4536e-09 - val_loss: 3.1650e-10 - val_mse: 3.1650e-10\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3432e-11 - mse: 1.3432e-11 - val_loss: 1.9645e-10 - val_mse: 1.9645e-10\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3590e-10 - mse: 1.3590e-10 - val_loss: 3.7886e-09 - val_mse: 3.7886e-09\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6891e-09 - mse: 7.6891e-09 - val_loss: 5.1628e-08 - val_mse: 5.1628e-08\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8426e-09 - mse: 3.8426e-09 - val_loss: 9.6734e-09 - val_mse: 9.6734e-09\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1646e-09 - mse: 1.1646e-09 - val_loss: 3.1039e-09 - val_mse: 3.1039e-09\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8943e-09 - mse: 2.8943e-09 - val_loss: 2.3429e-10 - val_mse: 2.3429e-10\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5081e-10 - mse: 8.5081e-10 - val_loss: 6.8168e-09 - val_mse: 6.8168e-09\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5714e-07 - mse: 1.5714e-07 - val_loss: 7.2324e-08 - val_mse: 7.2324e-08\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7622e-08 - mse: 7.7622e-08 - val_loss: 2.1660e-07 - val_mse: 2.1660e-07\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1001e-08 - mse: 3.1001e-08 - val_loss: 3.9693e-08 - val_mse: 3.9693e-08\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3545e-08 - mse: 3.3545e-08 - val_loss: 1.1043e-07 - val_mse: 1.1043e-07\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.1893e-07 - mse: 4.1893e-07 - val_loss: 1.2292e-08 - val_mse: 1.2292e-08\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1162e-09 - mse: 4.1162e-09 - val_loss: 8.8278e-08 - val_mse: 8.8278e-08\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0894e-07 - mse: 9.0894e-07 - val_loss: 3.5291e-05 - val_mse: 3.5291e-05\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1382e-05 - mse: 6.1382e-05 - val_loss: 3.7076e-04 - val_mse: 3.7076e-04\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.2621e-04 - val_mse: 2.2621e-04\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.2320 - val_mse: 0.2320\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 1.8027e-04 - val_mse: 1.8027e-04\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.0323e-04 - mse: 9.0323e-04 - val_loss: 2.5165e-04 - val_mse: 2.5165e-04\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8617e-05 - mse: 7.8617e-05 - val_loss: 2.9213e-05 - val_mse: 2.9213e-05\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.6855e-06 - mse: 5.6855e-06 - val_loss: 4.8994e-06 - val_mse: 4.8994e-06\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1513e-06 - mse: 1.1513e-06 - val_loss: 1.2978e-06 - val_mse: 1.2978e-06\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0006e-07 - mse: 2.0006e-07 - val_loss: 2.1297e-09 - val_mse: 2.1297e-09\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2532e-07 - mse: 1.2532e-07 - val_loss: 6.9626e-07 - val_mse: 6.9626e-07\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3453e-07 - mse: 7.3453e-07 - val_loss: 6.1102e-06 - val_mse: 6.1102e-06\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8181e-06 - mse: 3.8181e-06 - val_loss: 1.2981e-05 - val_mse: 1.2981e-05\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.9326e-06 - mse: 5.9326e-06 - val_loss: 1.7331e-05 - val_mse: 1.7331e-05\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7190e-07 - mse: 6.7190e-07 - val_loss: 2.0724e-07 - val_mse: 2.0724e-07\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.8901e-08 - mse: 8.8901e-08 - val_loss: 7.2705e-08 - val_mse: 7.2705e-08\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0247e-09 - mse: 4.0247e-09 - val_loss: 4.0236e-10 - val_mse: 4.0236e-10\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0482e-10 - mse: 2.0482e-10 - val_loss: 6.1489e-09 - val_mse: 6.1489e-09\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0111e-09 - mse: 2.0111e-09 - val_loss: 2.1464e-09 - val_mse: 2.1464e-09\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1162e-10 - mse: 3.1162e-10 - val_loss: 3.0341e-10 - val_mse: 3.0341e-10\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3314e-11 - mse: 6.3314e-11 - val_loss: 3.3833e-10 - val_mse: 3.3833e-10\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4956e-11 - mse: 3.4956e-11 - val_loss: 8.0763e-11 - val_mse: 8.0763e-11\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3469e-10 - mse: 2.3469e-10 - val_loss: 5.7335e-10 - val_mse: 5.7335e-10\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3499e-11 - mse: 6.3499e-11 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.3681e-12 - mse: 7.3681e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3746e-11 - mse: 6.3746e-11 - val_loss: 1.7550e-09 - val_mse: 1.7550e-09\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2173e-09 - mse: 3.2173e-09 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8761e-11 - mse: 2.8761e-11 - val_loss: 8.7311e-11 - val_mse: 8.7311e-11\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3550e-09 - mse: 2.3550e-09 - val_loss: 1.3013e-08 - val_mse: 1.3013e-08\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0039e-09 - mse: 1.0039e-09 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2941e-08 - mse: 1.2941e-08 - val_loss: 3.6271e-05 - val_mse: 3.6271e-05\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2988e-05 - mse: 2.2988e-05 - val_loss: 3.6067e-06 - val_mse: 3.6067e-06\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.6904e-04 - mse: 9.6904e-04 - val_loss: 0.1982 - val_mse: 0.1982\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5143e-04 - mse: 8.5143e-04 - val_loss: 1.3164e-07 - val_mse: 1.3164e-07\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1422e-06 - mse: 4.1422e-06 - val_loss: 4.6346e-04 - val_mse: 4.6346e-04\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.2530e-04 - mse: 8.2530e-04 - val_loss: 5.7080e-09 - val_mse: 5.7080e-09\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.6228e-07 - mse: 5.6228e-07 - val_loss: 8.8732e-07 - val_mse: 8.8732e-07\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6392e-05 - mse: 2.6392e-05 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6008e-04 - mse: 7.6008e-04 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.6792e-04 - mse: 5.6792e-04 - val_loss: 4.8708e-05 - val_mse: 4.8708e-05\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2225e-05 - mse: 2.2225e-05 - val_loss: 6.0633e-06 - val_mse: 6.0633e-06\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5869e-07 - mse: 2.5869e-07 - val_loss: 3.0024e-07 - val_mse: 3.0024e-07\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1667e-08 - mse: 4.1667e-08 - val_loss: 7.4979e-09 - val_mse: 7.4979e-09\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9384e-09 - mse: 2.9384e-09 - val_loss: 1.4616e-07 - val_mse: 1.4616e-07\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5039e-08 - mse: 1.5039e-08 - val_loss: 3.5197e-08 - val_mse: 3.5197e-08\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.1770e-09 - mse: 4.1770e-09 - val_loss: 3.4488e-10 - val_mse: 3.4488e-10\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0186e-10 - mse: 1.0186e-10 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8187e-12 - mse: 2.8187e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1413e-12 - mse: 7.1413e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2051e-11 - mse: 1.2051e-11 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0638e-11 - mse: 1.0638e-11 - val_loss: 4.7221e-10 - val_mse: 4.7221e-10\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8911e-11 - mse: 9.8911e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.8065e-11 - mse: 8.8065e-11 - val_loss: 2.9817e-09 - val_mse: 2.9817e-09\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4079e-10 - mse: 1.4079e-10 - val_loss: 7.0577e-11 - val_mse: 7.0577e-11\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2252e-11 - mse: 1.2252e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2290e-12 - mse: 6.2290e-12 - val_loss: 2.7809e-09 - val_mse: 2.7809e-09\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0913e-09 - mse: 3.0913e-09 - val_loss: 2.6346e-09 - val_mse: 2.6346e-09\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6419e-07 - mse: 1.6419e-07 - val_loss: 4.1868e-05 - val_mse: 4.1868e-05\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8214e-06 - mse: 5.8214e-06 - val_loss: 2.9807e-05 - val_mse: 2.9807e-05\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0072 - val_mse: 0.0072\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.6121e-04 - mse: 4.6121e-04 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8788e-04 - mse: 1.8788e-04 - val_loss: 3.3365e-04 - val_mse: 3.3365e-04\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4938e-05 - mse: 8.4938e-05 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4875e-04 - mse: 2.4875e-04 - val_loss: 2.0256e-06 - val_mse: 2.0256e-06\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1443e-05 - mse: 3.1443e-05 - val_loss: 5.9454e-04 - val_mse: 5.9454e-04\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3528e-04 - mse: 4.3528e-04 - val_loss: 5.2772e-04 - val_mse: 5.2772e-04\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3606e-05 - mse: 3.3606e-05 - val_loss: 7.9997e-06 - val_mse: 7.9997e-06\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.3934e-07 - mse: 9.3934e-07 - val_loss: 1.9463e-07 - val_mse: 1.9463e-07\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0472e-07 - mse: 8.0472e-07 - val_loss: 6.0192e-07 - val_mse: 6.0192e-07\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0012e-07 - mse: 3.0012e-07 - val_loss: 1.0614e-07 - val_mse: 1.0614e-07\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.8693e-08 - mse: 3.8693e-08 - val_loss: 9.4134e-07 - val_mse: 9.4134e-07\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9318e-07 - mse: 1.9318e-07 - val_loss: 5.9834e-07 - val_mse: 5.9834e-07\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4682e-07 - mse: 1.4682e-07 - val_loss: 8.4551e-08 - val_mse: 8.4551e-08\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0307e-08 - mse: 1.0307e-08 - val_loss: 9.6719e-09 - val_mse: 9.6719e-09\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7132e-09 - mse: 3.7132e-09 - val_loss: 1.9791e-10 - val_mse: 1.9791e-10\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.6014e-10 - mse: 8.6014e-10 - val_loss: 3.4066e-09 - val_mse: 3.4066e-09\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.3244e-09 - mse: 5.3244e-09 - val_loss: 2.9753e-07 - val_mse: 2.9753e-07\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.0335e-07 - mse: 3.0335e-07 - val_loss: 2.8949e-06 - val_mse: 2.8949e-06\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5711e-05 - mse: 4.5711e-05 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.3304 - val_mse: 0.3304\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 1.3793 - val_mse: 1.3793\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5592e-04 - mse: 2.5592e-04 - val_loss: 8.7264e-06 - val_mse: 8.7264e-06\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7122e-07 - mse: 5.7122e-07 - val_loss: 6.1488e-07 - val_mse: 6.1488e-07\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3939e-07 - mse: 4.3939e-07 - val_loss: 1.0281e-07 - val_mse: 1.0281e-07\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.8601e-07 - mse: 6.8601e-07 - val_loss: 4.5008e-07 - val_mse: 4.5008e-07\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9257e-08 - mse: 4.9257e-08 - val_loss: 1.0053e-08 - val_mse: 1.0053e-08\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7243e-09 - mse: 1.7243e-09 - val_loss: 1.7972e-10 - val_mse: 1.7972e-10\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0500e-11 - mse: 1.0500e-11 - val_loss: 1.3242e-10 - val_mse: 1.3242e-10\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9854e-11 - mse: 3.9854e-11 - val_loss: 1.1569e-10 - val_mse: 1.1569e-10\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.7995e-12 - mse: 9.7995e-12 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.0789e-12 - mse: 9.0789e-12 - val_loss: 6.4756e-11 - val_mse: 6.4756e-11\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.1256e-12 - mse: 9.1256e-12 - val_loss: 1.2951e-10 - val_mse: 1.2951e-10\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.9850e-11 - mse: 8.9850e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.8613e-12 - mse: 7.8613e-12 - val_loss: 4.7658e-10 - val_mse: 4.7658e-10\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4839e-11 - mse: 1.4839e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8096e-12 - mse: 9.8096e-12 - val_loss: 2.0809e-10 - val_mse: 2.0809e-10\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.5664e-12 - mse: 7.5664e-12 - val_loss: 2.4302e-10 - val_mse: 2.4302e-10\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1168e-11 - mse: 1.1168e-11 - val_loss: 2.1100e-10 - val_mse: 2.1100e-10\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9601e-11 - mse: 2.9601e-11 - val_loss: 4.3874e-10 - val_mse: 4.3874e-10\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5988e-10 - mse: 1.5988e-10 - val_loss: 1.1205e-10 - val_mse: 1.1205e-10\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3608e-10 - mse: 3.3608e-10 - val_loss: 7.7125e-11 - val_mse: 7.7125e-11\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.9308e-10 - mse: 3.9308e-10 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7761e-11 - mse: 1.7761e-11 - val_loss: 9.9681e-11 - val_mse: 9.9681e-11\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.0215e-11 - mse: 9.0215e-11 - val_loss: 3.5607e-08 - val_mse: 3.5607e-08\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1972e-08 - mse: 1.1972e-08 - val_loss: 1.8866e-07 - val_mse: 1.8866e-07\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1315e-07 - mse: 1.1315e-07 - val_loss: 7.5921e-08 - val_mse: 7.5921e-08\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4939e-08 - mse: 2.4939e-08 - val_loss: 2.1858e-07 - val_mse: 2.1858e-07\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9534e-07 - mse: 1.9534e-07 - val_loss: 1.7448e-09 - val_mse: 1.7448e-09\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2784e-06 - mse: 3.2784e-06 - val_loss: 3.1721e-05 - val_mse: 3.1721e-05\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0501e-05 - mse: 1.0501e-05 - val_loss: 1.2585e-07 - val_mse: 1.2585e-07\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4450e-08 - mse: 6.4450e-08 - val_loss: 4.3491e-08 - val_mse: 4.3491e-08\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4935e-07 - mse: 1.4935e-07 - val_loss: 1.2422e-07 - val_mse: 1.2422e-07\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2157e-05 - mse: 4.2157e-05 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.3984 - val_mse: 0.3984\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 4.4161e-07 - val_mse: 4.4161e-07\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.6071e-05 - mse: 3.6071e-05 - val_loss: 3.3304e-06 - val_mse: 3.3304e-06\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3984e-07 - mse: 2.3984e-07 - val_loss: 8.2866e-09 - val_mse: 8.2866e-09\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2608e-09 - mse: 1.2608e-09 - val_loss: 2.9977e-10 - val_mse: 2.9977e-10\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4753e-11 - mse: 3.4753e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3027e-10 - mse: 4.3027e-10 - val_loss: 6.9574e-08 - val_mse: 6.9574e-08\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1506e-08 - mse: 2.1506e-08 - val_loss: 2.3785e-09 - val_mse: 2.3785e-09\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1672e-10 - mse: 3.1672e-10 - val_loss: 1.9420e-09 - val_mse: 1.9420e-09\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.0524e-10 - mse: 3.0524e-10 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1541e-10 - mse: 7.1541e-10 - val_loss: 3.6402e-09 - val_mse: 3.6402e-09\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.2893e-09 - mse: 6.2893e-09\n",
            "mse :  [6.289337939335837e-09, 6.289337939335837e-09]\n",
            "[[ 81.00008 ]\n",
            " [ 82.00007 ]\n",
            " [ 83.00008 ]\n",
            " [ 84.00008 ]\n",
            " [ 85.00008 ]\n",
            " [ 86.00008 ]\n",
            " [ 87.00008 ]\n",
            " [ 88.00008 ]\n",
            " [ 89.00008 ]\n",
            " [ 90.00008 ]\n",
            " [ 91.000084]\n",
            " [ 92.00007 ]\n",
            " [ 93.000084]\n",
            " [ 94.00007 ]\n",
            " [ 95.000084]\n",
            " [ 96.00007 ]\n",
            " [ 97.000084]\n",
            " [ 98.000084]\n",
            " [ 99.00009 ]\n",
            " [100.0001  ]]\n",
            "RMSE :  7.89559401427933e-05\n",
            "R2 :  0.9999999998125101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkb_335mKpMH"
      },
      "source": [
        "-> mse, RMSE 모두 아주 낮은 수치가 나왔고 R2 역시 0.999...로 1에 근접하는 아주 좋은 평가가 나왔다. \n",
        "\n",
        "  예측값도 81에서 100에 근접한 값으로 입력한 값(x_test)과 거의 근사치로 출력되었다. \n",
        "\n",
        "  하지만 이 모델에도 약간의 문제가 있는데, 그것은 바로 x_test 값으로 predict를 한 것이다. \n",
        "\n",
        "  가급적 **test한 값보다는 새로운 데이터로 예측하는 것이 좋기 때문에**, x_predict를 새로 입력하여 예측해보도록 하겠다. \n",
        "\n",
        "  x_predict는 x의 범위 바깥쪽의 새로운 데이터로 하겠다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_ZFICDcN7ub"
      },
      "source": [
        "#### (2) 새로운 데이터로 예측하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd16uonJKY1w",
        "outputId": "50236710-9ce7-4a0e-f0d7-55fd5ef41abd"
      },
      "source": [
        "# 1. 데이터 준비\n",
        "x = np.array(range(1,101))\n",
        "y = np.array(range(1,101))\n",
        "\n",
        "\n",
        "# 2. 6:2:2비율로 Train:Val:Test로 나누기\n",
        "x_train = x[:60]\n",
        "x_val = x[60:80]\n",
        "x_test = x[80:]\n",
        "\n",
        "y_train = y[:60]\n",
        "y_val = y[60:80]\n",
        "y_test = y[80:]\n",
        "\n",
        "x_predict = np.array(range(101,111))   ## 추가\n",
        "\n",
        "\n",
        "# 3. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 4. 모델 훈련\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "# 5. 평가예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('mse : ', mse)\n",
        "\n",
        "y_predict = model.predict(x_predict)   ## x_test > x_predict로 수정\n",
        "print(y_predict)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 602.9449 - mse: 602.9449 - val_loss: 736.3043 - val_mse: 736.3043\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 141.0249 - mse: 141.0249 - val_loss: 42.5977 - val_mse: 42.5977\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3076 - mse: 3.3076 - val_loss: 0.4176 - val_mse: 0.4176\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.3340 - val_mse: 0.3340\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.1170 - val_loss: 0.3841 - val_mse: 0.3841\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 0.2749 - val_mse: 0.2749\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.3579 - val_mse: 0.3579\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.2021 - val_mse: 0.2021\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 0.1794 - val_mse: 0.1794\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 0.2893 - val_mse: 0.2893\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.2313 - val_mse: 0.2313\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.3050 - val_mse: 0.3050\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0791 - mse: 0.0791 - val_loss: 0.1345 - val_mse: 0.1345\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.2102 - val_mse: 0.2102\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.0828 - val_mse: 0.0828\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.0906 - val_mse: 0.0906\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639 - val_loss: 0.1489 - val_mse: 0.1489\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.1196 - val_mse: 0.1196\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.1112 - val_mse: 0.1112\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0426 - val_mse: 0.0426\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0931 - val_mse: 0.0931\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.1595 - val_mse: 0.1595\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0787 - val_mse: 0.0787\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0589 - val_mse: 0.0589\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0782 - val_mse: 0.0782\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0485 - val_mse: 0.0485\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6296e-04 - mse: 9.6296e-04 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6600e-04 - mse: 6.6600e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7889e-04 - mse: 5.7889e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0861e-04 - mse: 4.0861e-04 - val_loss: 3.9746e-04 - val_mse: 3.9746e-04\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1052e-04 - mse: 3.1052e-04 - val_loss: 4.1513e-04 - val_mse: 4.1513e-04\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8774e-04 - mse: 2.8774e-04 - val_loss: 5.4640e-04 - val_mse: 5.4640e-04\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9555e-04 - mse: 1.9555e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1116e-04 - mse: 2.1116e-04 - val_loss: 4.9812e-04 - val_mse: 4.9812e-04\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0641e-04 - mse: 1.0641e-04 - val_loss: 4.9953e-04 - val_mse: 4.9953e-04\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.4790e-05 - mse: 9.4790e-05 - val_loss: 1.8430e-04 - val_mse: 1.8430e-04\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4302e-05 - mse: 6.4302e-05 - val_loss: 4.9707e-04 - val_mse: 4.9707e-04\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3438e-05 - mse: 4.3438e-05 - val_loss: 4.0970e-05 - val_mse: 4.0970e-05\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8239e-05 - mse: 2.8239e-05 - val_loss: 1.3675e-04 - val_mse: 1.3675e-04\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5873e-05 - mse: 2.5873e-05 - val_loss: 3.0456e-05 - val_mse: 3.0456e-05\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5561e-05 - mse: 1.5561e-05 - val_loss: 4.6567e-05 - val_mse: 4.6567e-05\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2217e-05 - mse: 1.2217e-05 - val_loss: 5.9453e-06 - val_mse: 5.9453e-06\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1454e-06 - mse: 7.1454e-06 - val_loss: 8.2209e-07 - val_mse: 8.2209e-07\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4336e-06 - mse: 6.4336e-06 - val_loss: 4.1491e-06 - val_mse: 4.1491e-06\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3134e-06 - mse: 3.3134e-06 - val_loss: 6.1894e-06 - val_mse: 6.1894e-06\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0963e-06 - mse: 2.0963e-06 - val_loss: 1.3559e-05 - val_mse: 1.3559e-05\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5743e-06 - mse: 1.5743e-06 - val_loss: 7.1505e-07 - val_mse: 7.1505e-07\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.1093e-07 - mse: 9.1093e-07 - val_loss: 2.2234e-07 - val_mse: 2.2234e-07\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4703e-07 - mse: 5.4703e-07 - val_loss: 3.0223e-06 - val_mse: 3.0223e-06\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3786e-07 - mse: 4.3786e-07 - val_loss: 7.1302e-07 - val_mse: 7.1302e-07\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3515e-07 - mse: 2.3515e-07 - val_loss: 6.3633e-07 - val_mse: 6.3633e-07\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4408e-07 - mse: 1.4408e-07 - val_loss: 4.9044e-07 - val_mse: 4.9044e-07\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2665e-07 - mse: 1.2665e-07 - val_loss: 2.0982e-08 - val_mse: 2.0982e-08\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3396e-08 - mse: 3.3396e-08 - val_loss: 2.5085e-08 - val_mse: 2.5085e-08\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4343e-08 - mse: 3.4343e-08 - val_loss: 6.1291e-08 - val_mse: 6.1291e-08\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6181e-08 - mse: 1.6181e-08 - val_loss: 2.9684e-08 - val_mse: 2.9684e-08\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9732e-09 - mse: 5.9732e-09 - val_loss: 4.5533e-08 - val_mse: 4.5533e-08\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9839e-09 - mse: 5.9839e-09 - val_loss: 7.9606e-09 - val_mse: 7.9606e-09\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2119e-09 - mse: 2.2119e-09 - val_loss: 1.4988e-10 - val_mse: 1.4988e-10\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4230e-09 - mse: 1.4230e-09 - val_loss: 1.7426e-09 - val_mse: 1.7426e-09\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1358e-10 - mse: 7.1358e-10 - val_loss: 1.2245e-09 - val_mse: 1.2245e-09\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5442e-10 - mse: 2.5442e-10 - val_loss: 2.8158e-10 - val_mse: 2.8158e-10\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0826e-10 - mse: 1.0826e-10 - val_loss: 2.1391e-10 - val_mse: 2.1391e-10\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2097e-11 - mse: 6.2097e-11 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7466e-11 - mse: 3.7466e-11 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7005e-11 - mse: 1.7005e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8318e-11 - mse: 1.8318e-11 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0087e-12 - mse: 8.0087e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.9549e-12 - mse: 9.9549e-12 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5513e-12 - mse: 8.5513e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5982e-11 - mse: 1.5982e-11 - val_loss: 9.0949e-11 - val_mse: 9.0949e-11\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1423e-12 - mse: 7.1423e-12 - val_loss: 8.8039e-11 - val_mse: 8.8039e-11\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2959e-12 - mse: 3.2959e-12 - val_loss: 5.6025e-11 - val_mse: 5.6025e-11\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4381e-12 - mse: 7.4381e-12 - val_loss: 7.0577e-11 - val_mse: 7.0577e-11\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7679e-12 - mse: 7.7679e-12 - val_loss: 5.6025e-11 - val_mse: 5.6025e-11\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3677e-12 - mse: 4.3677e-12 - val_loss: 4.5111e-11 - val_mse: 4.5111e-11\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4469e-12 - mse: 7.4469e-12 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.6342e-12 - mse: 5.6342e-12 - val_loss: 5.9663e-11 - val_mse: 5.9663e-11\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5526e-12 - mse: 3.5526e-12 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.8848e-12 - mse: 6.8848e-12 - val_loss: 6.5484e-11 - val_mse: 6.5484e-11\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9619e-12 - mse: 4.9619e-12 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.7752e-12 - mse: 8.7752e-12 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9054e-12 - mse: 3.9054e-12 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1785e-12 - mse: 5.1785e-12 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1219e-12 - mse: 3.1219e-12 - val_loss: 1.0623e-10 - val_mse: 1.0623e-10\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4386e-11 - mse: 2.4386e-11 - val_loss: 8.8039e-11 - val_mse: 8.8039e-11\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2162e-12 - mse: 4.2162e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1642e-11 - mse: 1.1642e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7906e-12 - mse: 7.7906e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0405e-11 - mse: 2.0405e-11 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.7073e-12 - mse: 8.7073e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3376e-12 - mse: 4.3376e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4415e-11 - mse: 1.4415e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.7947e-12 - mse: 5.7947e-12 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4545e-11 - mse: 1.4545e-11 - val_loss: 5.1659e-11 - val_mse: 5.1659e-11\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.1008e-12 - mse: 8.1008e-12 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9905e-12 - mse: 5.9905e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0833e-11 - mse: 3.0833e-11 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2931e-11 - mse: 1.2931e-11 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3386e-11 - mse: 1.3386e-11 - val_loss: 1.2296e-10 - val_mse: 1.2296e-10\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1320e-11 - mse: 2.1320e-11 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1280e-11 - mse: 1.1280e-11 - val_loss: 7.5670e-11 - val_mse: 7.5670e-11\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5807e-12 - mse: 4.5807e-12 - val_loss: 1.0332e-10 - val_mse: 1.0332e-10\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.7075e-12 - mse: 8.7075e-12 - val_loss: 5.6025e-11 - val_mse: 5.6025e-11\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3323e-11 - mse: 1.3323e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9869e-12 - mse: 3.9869e-12 - val_loss: 4.1182e-10 - val_mse: 4.1182e-10\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.9858e-10 - mse: 6.9858e-10 - val_loss: 2.5248e-10 - val_mse: 2.5248e-10\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6516e-11 - mse: 1.6516e-11 - val_loss: 5.4570e-11 - val_mse: 5.4570e-11\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0778e-12 - mse: 7.0778e-12 - val_loss: 1.1132e-10 - val_mse: 1.1132e-10\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7057e-12 - mse: 4.7057e-12 - val_loss: 1.1350e-10 - val_mse: 1.1350e-10\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.7927e-12 - mse: 9.7927e-12 - val_loss: 1.6371e-10 - val_mse: 1.6371e-10\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3646e-11 - mse: 3.3646e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1036e-11 - mse: 1.1036e-11 - val_loss: 1.2806e-10 - val_mse: 1.2806e-10\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7816e-12 - mse: 4.7816e-12 - val_loss: 6.2500e-10 - val_mse: 6.2500e-10\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3249e-11 - mse: 4.3249e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4286e-11 - mse: 3.4286e-11 - val_loss: 1.0652e-09 - val_mse: 1.0652e-09\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0168e-09 - mse: 1.0168e-09 - val_loss: 5.2557e-08 - val_mse: 5.2557e-08\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2329e-06 - mse: 4.2329e-06 - val_loss: 2.5421e-04 - val_mse: 2.5421e-04\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 3.1981 - val_mse: 3.1981\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3159 - mse: 0.3159 - val_loss: 0.1433 - val_mse: 0.1433\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 0.1260 - val_mse: 0.1260\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.1525 - val_mse: 0.1525\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 2.8869e-04 - val_mse: 2.8869e-04\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3218e-05 - mse: 5.3218e-05 - val_loss: 9.3951e-07 - val_mse: 9.3951e-07\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1906e-06 - mse: 1.1906e-06 - val_loss: 3.3244e-09 - val_mse: 3.3244e-09\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1900e-07 - mse: 1.1900e-07 - val_loss: 2.2815e-07 - val_mse: 2.2815e-07\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0132e-08 - mse: 4.0132e-08 - val_loss: 4.5111e-11 - val_mse: 4.5111e-11\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1053e-09 - mse: 3.1053e-09 - val_loss: 2.1391e-10 - val_mse: 2.1391e-10\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6335e-11 - mse: 9.6335e-11 - val_loss: 3.2887e-10 - val_mse: 3.2887e-10\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1851e-11 - mse: 2.1851e-11 - val_loss: 1.7608e-10 - val_mse: 1.7608e-10\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5874e-11 - mse: 1.5874e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7808e-12 - mse: 2.7808e-12 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.8538e-12 - mse: 8.8538e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5087e-12 - mse: 5.5087e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6619e-11 - mse: 1.6619e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2694e-12 - mse: 4.2694e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0588e-11 - mse: 3.0588e-11 - val_loss: 3.6962e-10 - val_mse: 3.6962e-10\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9194e-11 - mse: 3.9194e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.8576e-12 - mse: 6.8576e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7730e-12 - mse: 2.7730e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0046e-12 - mse: 4.0046e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7468e-12 - mse: 6.7468e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0013e-11 - mse: 1.0013e-11 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1888e-11 - mse: 1.1888e-11 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9555e-11 - mse: 1.9555e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.7989e-12 - mse: 6.7989e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6245e-12 - mse: 2.6245e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.4823e-12 - mse: 4.4823e-12 - val_loss: 5.7480e-11 - val_mse: 5.7480e-11\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4772e-11 - mse: 1.4772e-11 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8112e-11 - mse: 5.8112e-11 - val_loss: 7.0577e-11 - val_mse: 7.0577e-11\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6218e-11 - mse: 1.6218e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.9013e-12 - mse: 8.9013e-12 - val_loss: 6.7666e-11 - val_mse: 6.7666e-11\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7879e-12 - mse: 7.7879e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5487e-11 - mse: 2.5487e-11 - val_loss: 2.3196e-09 - val_mse: 2.3196e-09\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7076e-10 - mse: 1.7076e-10 - val_loss: 9.9681e-11 - val_mse: 9.9681e-11\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9040e-11 - mse: 2.9040e-11 - val_loss: 3.2982e-09 - val_mse: 3.2982e-09\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2799e-10 - mse: 7.2799e-10 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9406e-10 - mse: 1.9406e-10 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5165e-11 - mse: 1.5165e-11 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8403e-09 - mse: 1.8403e-09 - val_loss: 2.2191e-07 - val_mse: 2.2191e-07\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3652e-06 - mse: 1.3652e-06 - val_loss: 1.1043e-04 - val_mse: 1.1043e-04\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8081e-05 - mse: 7.8081e-05 - val_loss: 6.9667e-04 - val_mse: 6.9667e-04\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1610e-04 - mse: 1.1610e-04 - val_loss: 2.9012e-04 - val_mse: 2.9012e-04\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 9.5679e-04 - val_mse: 9.5679e-04\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.5297 - val_mse: 0.5297\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5601e-04 - mse: 4.5601e-04 - val_loss: 2.9968e-07 - val_mse: 2.9968e-07\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1036e-04 - mse: 1.1036e-04 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1353e-04 - mse: 5.1353e-04 - val_loss: 6.1145e-07 - val_mse: 6.1145e-07\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8020e-05 - mse: 2.8020e-05 - val_loss: 8.4775e-06 - val_mse: 8.4775e-06\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4026e-06 - mse: 7.4026e-06 - val_loss: 8.5049e-08 - val_mse: 8.5049e-08\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.4486e-07 - mse: 6.4486e-07 - val_loss: 5.0081e-07 - val_mse: 5.0081e-07\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2389e-07 - mse: 2.2389e-07 - val_loss: 1.1097e-05 - val_mse: 1.1097e-05\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4329e-06 - mse: 1.4329e-06 - val_loss: 1.0435e-07 - val_mse: 1.0435e-07\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.5015e-07 - mse: 7.5015e-07 - val_loss: 2.0786e-06 - val_mse: 2.0786e-06\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0844e-07 - mse: 1.0844e-07 - val_loss: 6.8072e-08 - val_mse: 6.8072e-08\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9465e-09 - mse: 2.9465e-09 - val_loss: 1.0426e-09 - val_mse: 1.0426e-09\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4928e-10 - mse: 1.4928e-10 - val_loss: 1.1787e-10 - val_mse: 1.1787e-10\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8433e-11 - mse: 4.8433e-11 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4266e-11 - mse: 1.4266e-11 - val_loss: 2.4811e-10 - val_mse: 2.4811e-10\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0738e-11 - mse: 7.0738e-11 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3296e-09 - mse: 2.3296e-09 - val_loss: 7.7875e-09 - val_mse: 7.7875e-09\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4671e-06 - mse: 3.4671e-06 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.6761e-04 - mse: 4.6761e-04 - val_loss: 7.6328e-04 - val_mse: 7.6328e-04\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.3175e-05 - val_mse: 6.3175e-05\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2250e-05 - mse: 2.2250e-05 - val_loss: 5.1693e-05 - val_mse: 5.1693e-05\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0079e-05 - mse: 4.0079e-05 - val_loss: 2.3196e-07 - val_mse: 2.3196e-07\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1162e-07 - mse: 2.1162e-07 - val_loss: 1.7986e-09 - val_mse: 1.7986e-09\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.6297e-07 - mse: 4.6297e-07 - val_loss: 6.0890e-08 - val_mse: 6.0890e-08\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2817e-08 - mse: 4.2817e-08 - val_loss: 4.2775e-09 - val_mse: 4.2775e-09\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5462e-09 - mse: 9.5462e-09 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.6977e-12 - mse: 3.6977e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0762e-10 - mse: 1.0762e-10 - val_loss: 8.1491e-11 - val_mse: 8.1491e-11\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7574e-11 - mse: 1.7574e-11 - val_loss: 5.4279e-10 - val_mse: 5.4279e-10\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7418e-10 - mse: 1.7418e-10 - val_loss: 2.2410e-10 - val_mse: 2.2410e-10\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6623e-11 - mse: 1.6623e-11 - val_loss: 1.9936e-10 - val_mse: 1.9936e-10\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4246e-11 - mse: 1.4246e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.2321e-12 - mse: 8.2321e-12 - val_loss: 3.7107e-10 - val_mse: 3.7107e-10\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2326e-10 - mse: 1.2326e-10 - val_loss: 1.2296e-10 - val_mse: 1.2296e-10\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1755e-09 - mse: 2.1755e-09 - val_loss: 1.1850e-08 - val_mse: 1.1850e-08\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8706e-09 - mse: 2.8706e-09 - val_loss: 7.4651e-10 - val_mse: 7.4651e-10\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7577e-10 - mse: 2.7577e-10 - val_loss: 9.8035e-08 - val_mse: 9.8035e-08\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0104e-09 - mse: 9.0104e-09 - val_loss: 4.1409e-08 - val_mse: 4.1409e-08\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5068e-07 - mse: 3.5068e-07 - val_loss: 4.3798e-05 - val_mse: 4.3798e-05\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.4389e-05 - mse: 9.4389e-05 - val_loss: 7.8960e-04 - val_mse: 7.8960e-04\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.5390 - val_mse: 0.5390\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3024 - mse: 0.3024 - val_loss: 0.5911 - val_mse: 0.5911\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0633 - val_mse: 0.0633\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.7356e-06 - val_mse: 2.7356e-06\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3691e-05 - mse: 1.3691e-05 - val_loss: 8.1008e-07 - val_mse: 8.1008e-07\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8896e-06 - mse: 2.8896e-06 - val_loss: 1.1120e-06 - val_mse: 1.1120e-06\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0781e-07 - mse: 1.0781e-07 - val_loss: 6.6318e-08 - val_mse: 6.6318e-08\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9735e-08 - mse: 4.9735e-08 - val_loss: 4.5318e-08 - val_mse: 4.5318e-08\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5715e-09 - mse: 9.5715e-09 - val_loss: 2.2440e-08 - val_mse: 2.2440e-08\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0292e-09 - mse: 2.0292e-09 - val_loss: 4.6421e-10 - val_mse: 4.6421e-10\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2817e-10 - mse: 2.2817e-10 - val_loss: 1.1205e-10 - val_mse: 1.1205e-10\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8464e-12 - mse: 9.8464e-12 - val_loss: 1.0914e-11 - val_mse: 1.0914e-11\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4371e-11 - mse: 1.4371e-11 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7737e-12 - mse: 7.7737e-12 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0309e-11 - mse: 2.0309e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5271e-12 - mse: 3.5271e-12 - val_loss: 1.2005e-10 - val_mse: 1.2005e-10\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9810e-11 - mse: 4.9810e-11 - val_loss: 2.0445e-10 - val_mse: 2.0445e-10\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4261e-11 - mse: 1.4261e-11 - val_loss: 1.0768e-10 - val_mse: 1.0768e-10\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1212e-11 - mse: 1.1212e-11 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3625e-11 - mse: 5.3625e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4041e-11 - mse: 2.4041e-11 - val_loss: 8.6584e-11 - val_mse: 8.6584e-11\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1919e-11 - mse: 1.1919e-11 - val_loss: 1.1132e-10 - val_mse: 1.1132e-10\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4248e-11 - mse: 1.4248e-11 - val_loss: 1.0623e-10 - val_mse: 1.0623e-10\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6701e-11 - mse: 1.6701e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1246e-12 - mse: 5.1246e-12 - val_loss: 4.1982e-10 - val_mse: 4.1982e-10\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1156e-11 - mse: 2.1156e-11 - val_loss: 8.8767e-11 - val_mse: 8.8767e-11\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.0351e-12 - mse: 8.0351e-12 - val_loss: 1.9063e-10 - val_mse: 1.9063e-10\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.7050e-10 - mse: 3.7050e-10 - val_loss: 1.1678e-09 - val_mse: 1.1678e-09\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4571e-09 - mse: 2.4571e-09 - val_loss: 7.7853e-11 - val_mse: 7.7853e-11\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1821e-10 - mse: 1.1821e-10 - val_loss: 4.5475e-10 - val_mse: 4.5475e-10\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9680e-10 - mse: 2.9680e-10 - val_loss: 1.1642e-11 - val_mse: 1.1642e-11\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1667e-10 - mse: 5.1667e-10 - val_loss: 1.0623e-10 - val_mse: 1.0623e-10\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2815e-11 - mse: 3.2815e-11 - val_loss: 1.2369e-11 - val_mse: 1.2369e-11\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1289e-10 - mse: 5.1289e-10 - val_loss: 4.7333e-08 - val_mse: 4.7333e-08\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0409e-06 - mse: 1.0409e-06 - val_loss: 2.3448e-04 - val_mse: 2.3448e-04\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0667 - val_mse: 0.0667\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1258 - mse: 0.1258 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 6.8809e-04 - val_mse: 6.8809e-04\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.7553e-07 - val_mse: 1.7553e-07\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4291e-05 - mse: 1.4291e-05 - val_loss: 3.1153e-06 - val_mse: 3.1153e-06\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1275e-06 - mse: 1.1275e-06 - val_loss: 1.2334e-07 - val_mse: 1.2334e-07\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2059e-08 - mse: 4.2059e-08 - val_loss: 1.2832e-07 - val_mse: 1.2832e-07\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.8952e-09 - mse: 9.8952e-09 - val_loss: 2.4235e-08 - val_mse: 2.4235e-08\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3042e-09 - mse: 1.3042e-09 - val_loss: 1.2587e-10 - val_mse: 1.2587e-10\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4603e-11 - mse: 5.4603e-11 - val_loss: 1.8190e-09 - val_mse: 1.8190e-09\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5343e-11 - mse: 9.5343e-11 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0414e-11 - mse: 3.0414e-11 - val_loss: 4.1327e-10 - val_mse: 4.1327e-10\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8879e-10 - mse: 4.8879e-10 - val_loss: 3.8832e-09 - val_mse: 3.8832e-09\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8192e-08 - mse: 1.8192e-08 - val_loss: 3.6817e-07 - val_mse: 3.6817e-07\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2845e-07 - mse: 2.2845e-07 - val_loss: 5.3959e-08 - val_mse: 5.3959e-08\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0497e-07 - mse: 1.0497e-07 - val_loss: 1.1292e-07 - val_mse: 1.1292e-07\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9960e-08 - mse: 2.9960e-08 - val_loss: 4.5598e-09 - val_mse: 4.5598e-09\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8067e-08 - mse: 9.8067e-08 - val_loss: 1.8916e-07 - val_mse: 1.8916e-07\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.8838e-08 - mse: 3.8838e-08 - val_loss: 4.3809e-09 - val_mse: 4.3809e-09\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5759e-08 - mse: 2.5759e-08 - val_loss: 3.1437e-07 - val_mse: 3.1437e-07\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0639e-07 - mse: 1.0639e-07 - val_loss: 2.4497e-08 - val_mse: 2.4497e-08\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0583e-06 - mse: 1.0583e-06 - val_loss: 6.6338e-06 - val_mse: 6.6338e-06\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8890e-07 - mse: 2.8890e-07 - val_loss: 2.4123e-08 - val_mse: 2.4123e-08\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3765e-08 - mse: 3.3765e-08 - val_loss: 9.2405e-11 - val_mse: 9.2405e-11\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0679e-10 - mse: 4.0679e-10 - val_loss: 1.1998e-09 - val_mse: 1.1998e-09\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7010e-08 - mse: 1.7010e-08 - val_loss: 4.0679e-08 - val_mse: 4.0679e-08\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2129e-06 - mse: 3.2129e-06 - val_loss: 1.5716e-04 - val_mse: 1.5716e-04\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.3563 - val_mse: 0.3563\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 2.5647e-04 - val_mse: 2.5647e-04\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1661 - mse: 0.1661 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3182 - mse: 0.3182 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 9.5627e-05 - val_mse: 9.5627e-05\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 5.1971e-04 - val_mse: 5.1971e-04\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6013e-04 - mse: 1.6013e-04 - val_loss: 2.4614e-05 - val_mse: 2.4614e-05\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2149e-05 - mse: 2.2149e-05 - val_loss: 3.8010e-06 - val_mse: 3.8010e-06\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6603e-06 - mse: 1.6603e-06 - val_loss: 2.5045e-06 - val_mse: 2.5045e-06\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4013e-07 - mse: 7.4013e-07 - val_loss: 4.4876e-06 - val_mse: 4.4876e-06\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1466e-06 - mse: 1.1466e-06 - val_loss: 7.0687e-06 - val_mse: 7.0687e-06\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5140e-07 - mse: 9.5140e-07 - val_loss: 1.7033e-06 - val_mse: 1.7033e-06\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0203e-07 - mse: 1.0203e-07 - val_loss: 1.1798e-08 - val_mse: 1.1798e-08\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.7307e-09 - mse: 8.7307e-09 - val_loss: 7.1232e-10 - val_mse: 7.1232e-10\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1482e-11 - mse: 6.1482e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.6928e-12 - mse: 9.6928e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5784e-12 - mse: 5.5784e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.6779e-12 - mse: 2.6779e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8218e-12 - mse: 3.8218e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.5577e-12 - mse: 4.5577e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7506e-12 - mse: 2.7506e-12 - val_loss: 7.3487e-11 - val_mse: 7.3487e-11\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2249e-11 - mse: 1.2249e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.5793e-12 - mse: 8.5793e-12 - val_loss: 8.1491e-11 - val_mse: 8.1491e-11\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1370e-11 - mse: 1.1370e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1139e-11 - mse: 1.1139e-11 - val_loss: 1.1496e-10 - val_mse: 1.1496e-10\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5008e-11 - mse: 3.5008e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8128e-11 - mse: 1.8128e-11 - val_loss: 2.6921e-10 - val_mse: 2.6921e-10\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0839e-10 - mse: 1.0839e-10 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.5020e-12 - mse: 8.5020e-12 - val_loss: 5.2387e-11 - val_mse: 5.2387e-11\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9917e-11 - mse: 4.9917e-11 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0471e-10 - mse: 1.0471e-10 - val_loss: 3.7660e-09 - val_mse: 3.7660e-09\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0706e-09 - mse: 7.0706e-09 - val_loss: 1.8447e-08 - val_mse: 1.8447e-08\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6278e-07 - mse: 1.6278e-07 - val_loss: 3.6076e-07 - val_mse: 3.6076e-07\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.8167e-07 - mse: 7.8167e-07 - val_loss: 3.5644e-05 - val_mse: 3.5644e-05\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0749e-06 - mse: 4.0749e-06 - val_loss: 1.0209e-06 - val_mse: 1.0209e-06\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1344e-07 - mse: 5.1344e-07 - val_loss: 3.9897e-07 - val_mse: 3.9897e-07\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3842e-06 - mse: 4.3842e-06 - val_loss: 3.5443e-07 - val_mse: 3.5443e-07\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0661e-06 - mse: 2.0661e-06 - val_loss: 2.0209e-06 - val_mse: 2.0209e-06\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.2451e-06 - mse: 5.2451e-06 - val_loss: 1.4208e-05 - val_mse: 1.4208e-05\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8357e-05 - mse: 5.8357e-05 - val_loss: 8.8067e-07 - val_mse: 8.8067e-07\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4925e-05 - mse: 3.4925e-05 - val_loss: 6.4775e-04 - val_mse: 6.4775e-04\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3469e-05 - mse: 4.3469e-05 - val_loss: 8.4636e-07 - val_mse: 8.4636e-07\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.9384e-06 - mse: 3.9384e-06 - val_loss: 7.5595e-07 - val_mse: 7.5595e-07\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.6682e-06 - mse: 7.6682e-06 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.1115 - val_mse: 0.1115\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1780 - mse: 0.1780 - val_loss: 0.0070 - val_mse: 0.0070\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.0924e-06 - val_mse: 2.0924e-06\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3245e-04 - mse: 3.3245e-04 - val_loss: 9.2894e-04 - val_mse: 9.2894e-04\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5666e-04 - mse: 3.5666e-04 - val_loss: 0.0468 - val_mse: 0.0468\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7630e-04 - mse: 2.7630e-04 - val_loss: 1.6778e-09 - val_mse: 1.6778e-09\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5211e-06 - mse: 1.5211e-06 - val_loss: 1.4519e-07 - val_mse: 1.4519e-07\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8709e-08 - mse: 2.8709e-08 - val_loss: 2.5274e-08 - val_mse: 2.5274e-08\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2609e-08 - mse: 2.2609e-08 - val_loss: 1.1998e-09 - val_mse: 1.1998e-09\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6367e-10 - mse: 1.6367e-10 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7293e-11 - mse: 1.7293e-11 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.7276e-12 - mse: 7.7276e-12 - val_loss: 2.2555e-11 - val_mse: 2.2555e-11\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4614e-11 - mse: 3.4614e-11 - val_loss: 5.2387e-11 - val_mse: 5.2387e-11\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0240e-10 - mse: 2.0240e-10 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1726e-11 - mse: 1.1726e-11 - val_loss: 7.4942e-11 - val_mse: 7.4942e-11\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.0959e-11 - mse: 3.0959e-11 - val_loss: 1.5061e-10 - val_mse: 1.5061e-10\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2915e-10 - mse: 2.2915e-10 - val_loss: 6.0463e-10 - val_mse: 6.0463e-10\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7959e-10 - mse: 1.7959e-10 - val_loss: 9.3860e-11 - val_mse: 9.3860e-11\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3229e-12 - mse: 8.3229e-12 - val_loss: 8.6584e-11 - val_mse: 8.6584e-11\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9702e-11 - mse: 4.9702e-11 - val_loss: 1.4217e-09 - val_mse: 1.4217e-09\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0505e-09 - mse: 4.0505e-09 - val_loss: 5.6534e-10 - val_mse: 5.6534e-10\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5575e-08 - mse: 1.5575e-08 - val_loss: 2.4441e-07 - val_mse: 2.4441e-07\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9449e-07 - mse: 1.9449e-07 - val_loss: 1.3412e-05 - val_mse: 1.3412e-05\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0712e-06 - mse: 3.0712e-06 - val_loss: 4.6967e-06 - val_mse: 4.6967e-06\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1764e-04 - mse: 1.1764e-04 - val_loss: 0.0186 - val_mse: 0.0186\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2620e-04 - mse: 4.2620e-04 - val_loss: 3.8553e-04 - val_mse: 3.8553e-04\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.5346e-05 - mse: 6.5346e-05 - val_loss: 5.9547e-06 - val_mse: 5.9547e-06\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8345e-05 - mse: 5.8345e-05 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 7.3878e-04 - val_mse: 7.3878e-04\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.8735 - val_mse: 0.8735\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2122 - mse: 0.2122 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0065 - val_mse: 0.0065\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 3.2175e-05 - val_mse: 3.2175e-05\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8880e-04 - mse: 2.8880e-04 - val_loss: 2.9504e-07 - val_mse: 2.9504e-07\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0139e-05 - mse: 7.0139e-05 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 8.5999e-05 - val_mse: 8.5999e-05\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0781e-05 - mse: 1.0781e-05 - val_loss: 3.9525e-07 - val_mse: 3.9525e-07\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1848e-08 - mse: 6.1848e-08 - val_loss: 6.0027e-10 - val_mse: 6.0027e-10\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8755e-10 - mse: 3.8755e-10 - val_loss: 2.8042e-09 - val_mse: 2.8042e-09\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2789e-10 - mse: 1.2789e-10 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7115e-12 - mse: 6.7115e-12 - val_loss: 7.7853e-11 - val_mse: 7.7853e-11\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2302e-11 - mse: 2.2302e-11 - val_loss: 9.0949e-11 - val_mse: 9.0949e-11\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2769e-10 - mse: 1.2769e-10 - val_loss: 5.8040e-09 - val_mse: 5.8040e-09\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8988e-10 - mse: 5.8988e-10 - val_loss: 2.3720e-10 - val_mse: 2.3720e-10\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0779e-10 - mse: 1.0779e-10 - val_loss: 1.9354e-10 - val_mse: 1.9354e-10\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2453e-11 - mse: 5.2453e-11 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2274e-12 - mse: 6.2274e-12 - val_loss: 1.4188e-10 - val_mse: 1.4188e-10\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8159e-11 - mse: 1.8159e-11 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0346e-10 - mse: 1.0346e-10 - val_loss: 6.8394e-11 - val_mse: 6.8394e-11\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.4105e-12 - mse: 5.4105e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9198e-12 - mse: 5.9198e-12 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0873e-09 - mse: 1.0873e-09 - val_loss: 2.4985e-07 - val_mse: 2.4985e-07\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0053e-07 - mse: 1.0053e-07 - val_loss: 1.6683e-05 - val_mse: 1.6683e-05\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6424e-06 - mse: 2.6424e-06 - val_loss: 1.0777e-05 - val_mse: 1.0777e-05\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.8312e-06 - mse: 4.8312e-06 - val_loss: 1.4992e-07 - val_mse: 1.4992e-07\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7184e-05 - mse: 2.7184e-05 - val_loss: 2.2860e-04 - val_mse: 2.2860e-04\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 0.1138 - val_mse: 0.1138\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 2.6144e-05 - val_mse: 2.6144e-05\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0769e-04 - mse: 1.0769e-04 - val_loss: 5.4658e-05 - val_mse: 5.4658e-05\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0984e-05 - mse: 2.0984e-05 - val_loss: 3.1256e-05 - val_mse: 3.1256e-05\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3219e-07 - mse: 7.3219e-07 - val_loss: 1.0446e-06 - val_mse: 1.0446e-06\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3297e-08 - mse: 6.3297e-08 - val_loss: 1.0371e-07 - val_mse: 1.0371e-07\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6094e-08 - mse: 2.6094e-08 - val_loss: 5.8419e-09 - val_mse: 5.8419e-09\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1230e-09 - mse: 1.1230e-09 - val_loss: 8.3310e-10 - val_mse: 8.3310e-10\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.9920e-11 - mse: 5.9920e-11 - val_loss: 1.1132e-10 - val_mse: 1.1132e-10\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3351e-11 - mse: 1.3351e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.7270e-12 - mse: 9.7270e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0416e-12 - mse: 4.0416e-12 - val_loss: 1.2151e-10 - val_mse: 1.2151e-10\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.2785e-11 - mse: 7.2785e-11 - val_loss: 5.8862e-10 - val_mse: 5.8862e-10\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1250e-11 - mse: 6.1250e-11 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7740e-11 - mse: 1.7740e-11 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3471e-11 - mse: 2.3471e-11 - val_loss: 3.9072e-10 - val_mse: 3.9072e-10\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5388e-11 - mse: 8.5388e-11 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0006e-12 - mse: 8.0006e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1027e-11 - mse: 1.1027e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4286e-11 - mse: 1.4286e-11 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1664e-10 - mse: 2.1664e-10 - val_loss: 1.0165e-09 - val_mse: 1.0165e-09\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2587e-09 - mse: 1.2587e-09 - val_loss: 2.4680e-08 - val_mse: 2.4680e-08\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5943e-07 - mse: 3.5943e-07 - val_loss: 3.4226e-07 - val_mse: 3.4226e-07\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.9079e-07 - mse: 9.9079e-07 - val_loss: 4.9064e-08 - val_mse: 4.9064e-08\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7216e-08 - mse: 1.7216e-08 - val_loss: 7.7723e-08 - val_mse: 7.7723e-08\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5567e-08 - mse: 1.5567e-08 - val_loss: 1.6389e-06 - val_mse: 1.6389e-06\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5827e-07 - mse: 2.5827e-07 - val_loss: 1.8813e-08 - val_mse: 1.8813e-08\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9409e-09 - mse: 1.9409e-09 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.4611e-10 - mse: 7.4611e-10 - val_loss: 9.9681e-11 - val_mse: 9.9681e-11\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0823e-10 - mse: 3.0823e-10 - val_loss: 8.7093e-10 - val_mse: 8.7093e-10\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.4118e-10 - mse: 4.4118e-10 - val_loss: 6.4465e-10 - val_mse: 6.4465e-10\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1411e-10 - mse: 1.1411e-10 - val_loss: 4.3146e-10 - val_mse: 4.3146e-10\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0584e-09 - mse: 1.0584e-09 - val_loss: 9.9681e-11 - val_mse: 9.9681e-11\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3920e-08 - mse: 1.3920e-08 - val_loss: 4.7105e-09 - val_mse: 4.7105e-09\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.2742e-05 - mse: 5.2742e-05 - val_loss: 9.4787e-04 - val_mse: 9.4787e-04\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0763 - val_mse: 0.0763\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8333 - mse: 0.8333 - val_loss: 0.3538 - val_mse: 0.3538\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3033e-04 - mse: 2.3033e-04 - val_loss: 1.5223e-05 - val_mse: 1.5223e-05\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1424e-06 - mse: 3.1424e-06 - val_loss: 6.5733e-06 - val_mse: 6.5733e-06\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.6648e-07 - mse: 6.6648e-07 - val_loss: 5.8642e-06 - val_mse: 5.8642e-06\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3584e-06 - mse: 1.3584e-06 - val_loss: 1.5895e-08 - val_mse: 1.5895e-08\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2690e-07 - mse: 3.2690e-07 - val_loss: 2.6776e-08 - val_mse: 2.6776e-08\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9727e-08 - mse: 1.9727e-08 - val_loss: 8.6490e-08 - val_mse: 8.6490e-08\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2290e-08 - mse: 1.2290e-08 - val_loss: 1.3148e-09 - val_mse: 1.3148e-09\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.2312e-10 - mse: 9.2312e-10 - val_loss: 1.0579e-09 - val_mse: 1.0579e-09\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8838e-10 - mse: 2.8838e-10 - val_loss: 1.6516e-10 - val_mse: 1.6516e-10\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6410e-11 - mse: 6.6410e-11 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1904e-11 - mse: 2.1904e-11 - val_loss: 4.5111e-11 - val_mse: 4.5111e-11\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.0528e-12 - mse: 9.0528e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0665e-12 - mse: 7.0665e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.2246e-12 - mse: 7.2246e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0110e-11 - mse: 1.0110e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0240e-12 - mse: 7.0240e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.9388e-12 - mse: 9.9388e-12 - val_loss: 8.2291e-10 - val_mse: 8.2291e-10\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9998e-11 - mse: 2.9998e-11 - val_loss: 1.3242e-10 - val_mse: 1.3242e-10\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5766e-11 - mse: 1.5766e-11 - val_loss: 8.8767e-11 - val_mse: 8.8767e-11\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8801e-11 - mse: 1.8801e-11 - val_loss: 7.1304e-11 - val_mse: 7.1304e-11\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4178e-11 - mse: 1.4178e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5782e-12 - mse: 8.5782e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.9668e-12 - mse: 6.9668e-12 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1132e-11 - mse: 1.1132e-11 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.2036e-12 - mse: 8.2036e-12 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.7439e-12 - mse: 9.7439e-12 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.6302e-11 - mse: 2.6302e-11 - val_loss: 7.7853e-11 - val_mse: 7.7853e-11\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3300e-12 - mse: 8.3300e-12 - val_loss: 6.6211e-11 - val_mse: 6.6211e-11\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1143e-11 - mse: 1.1143e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.5718e-12 - mse: 6.5718e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0753e-11 - mse: 1.0753e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2116e-11 - mse: 1.2116e-11 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1882e-11 - mse: 6.1882e-11 - val_loss: 1.8845e-10 - val_mse: 1.8845e-10\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3223e-10 - mse: 1.3223e-10 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.6910e-12 - mse: 8.6910e-12 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6659e-11 - mse: 1.6659e-11 - val_loss: 1.0987e-10 - val_mse: 1.0987e-10\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0450e-10 - mse: 2.0450e-10 - val_loss: 1.4188e-10 - val_mse: 1.4188e-10\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2191e-10 - mse: 2.2191e-10 - val_loss: 1.1424e-07 - val_mse: 1.1424e-07\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1933e-07 - mse: 1.1933e-07 - val_loss: 2.1091e-06 - val_mse: 2.1091e-06\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6996e-06 - mse: 9.6996e-06 - val_loss: 1.7992e-04 - val_mse: 1.7992e-04\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.7756e-04 - mse: 9.7756e-04 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 2.5258 - val_mse: 2.5258\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4257 - mse: 0.4257 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0187 - val_mse: 0.0187\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 4.8596e-07 - val_mse: 4.8596e-07\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0672e-05 - mse: 4.0672e-05 - val_loss: 6.3693e-05 - val_mse: 6.3693e-05\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.5417e-06 - mse: 8.5417e-06 - val_loss: 4.4421e-06 - val_mse: 4.4421e-06\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0061e-06 - mse: 2.0061e-06 - val_loss: 4.8661e-07 - val_mse: 4.8661e-07\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.5663e-08 - mse: 6.5663e-08 - val_loss: 4.8563e-08 - val_mse: 4.8563e-08\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.4193e-08 - mse: 9.4193e-08 - val_loss: 3.0619e-08 - val_mse: 3.0619e-08\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8364e-09 - mse: 2.8364e-09 - val_loss: 1.0041e-10 - val_mse: 1.0041e-10\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2850e-10 - mse: 1.2850e-10 - val_loss: 1.4406e-10 - val_mse: 1.4406e-10\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.9500e-10 - mse: 1.9500e-10\n",
            "mse :  [1.949956585090007e-10, 1.949956585090007e-10]\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5d96cd710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[101.00002 ]\n",
            " [102.000015]\n",
            " [103.00001 ]\n",
            " [104.000015]\n",
            " [105.00001 ]\n",
            " [106.000015]\n",
            " [107.000015]\n",
            " [108.000015]\n",
            " [109.00002 ]\n",
            " [110.00001 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrkMwdI_O4hl"
      },
      "source": [
        "101에서 110까지의 값을 x로 주고 예측을 시켰을 때의 결과이다.\n",
        "\n",
        "train과 test에서 제공된 데이터가 아닌 전혀 다른 데이터로 predict을 시켰으나 거의 정확하게 예측되었다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWf12j3CP-iR"
      },
      "source": [
        "### 4.2.3. train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "617O_sIRQNI_"
      },
      "source": [
        "지금까지는 데이터를 손으로 잘라서 사용했다. 사이킷런에서 이미 잘 구현된 train_test_split 함수를 제공하니 이것을 사용해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw2mfV_tOwE-"
      },
      "source": [
        "# sklean의 train_test_split 함수 사용\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4, shuffle=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ZRFyuGURmr"
      },
      "source": [
        "x, y에 데이터의 x값과 y값을 넣었다. test_size=0.4는 test_size가 40%라는 의미이다. 이는 train_size=0.6이라고도 할 수 있다. \n",
        "\n",
        "shuffle이라는 파라미터가 추가되었다는 점도 눈여겨 봐야한다. 잘라낸 데이터를 섞을 것이냐는 의미이다. 이때 x와 y의 쌍까지 섞이지는 않는다. \n",
        "\n",
        "---\n",
        "\n",
        "train_test_split는 인잣값으로 x input 데이터와 y output 데이터를 받는다. 옵션값으로는 test_size, train_size, random_state, shuffle등이 있다.\n",
        "\n",
        "*   **test_size** : float로 받으며 0.0~1.0까지 입력한다. 정수를 입력하면 데이터의 절대 수를 의미한다. 옵션값이 지정되지 않았을 경우 train_size에 따라 결정되는데, train_size도 None 이면 0.25로 맞춰진다.\n",
        "\n",
        "*   **train_size** : float 로 받으며 0.0~1.0까지 입력한다. 정수를 입력하면 데이터의 절대 수를 의미한다. 옵션값이 지정되지 않았을 경우 test_size 따라 자동 결정된다.\n",
        "\n",
        "*   **random_state** : 재현가능(for reproducibility)하도록 난수의 초기값을 설정해주는 것이다.\n",
        "\n",
        "*   **shuffle** : 분할하기 전에 데이터를 섞을 것인지를 의미한다. 기본값은 True이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb4FJwaHXK7e",
        "outputId": "57f5c11f-e4cd-4ca8-bd07-c43333936de3"
      },
      "source": [
        "# 1. 데이터 준비 \n",
        "import numpy as np\n",
        "x = np.array(range(1, 101))\n",
        "y = np.array(range(1, 101))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=66, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=66, shuffle=False)\n",
        "## test 데이터의 50%를 validation에 배분하게 되어 train:val:test의 비율이 6:2:2가 된다.\n",
        "\n",
        "\n",
        "# 2. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 3. 훈련\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=300, validation_data=(x_val, y_val))\n",
        "\n",
        "# 4. 평가 예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('mse :', mse)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 1486.2996 - mse: 1486.2996 - val_loss: 3176.3684 - val_mse: 3176.3684\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 593.3036 - mse: 593.3036 - val_loss: 1502.8042 - val_mse: 1502.8042\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 308.2341 - mse: 308.2341 - val_loss: 335.0134 - val_mse: 335.0134\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 47.1245 - mse: 47.1245 - val_loss: 26.1325 - val_mse: 26.1325\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5936 - mse: 2.5936 - val_loss: 1.7608 - val_mse: 1.7608\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3555 - mse: 0.3555 - val_loss: 0.7319 - val_mse: 0.7319\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.7754 - val_mse: 0.7754\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2565 - mse: 0.2565 - val_loss: 0.7483 - val_mse: 0.7483\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3195 - mse: 0.3195 - val_loss: 0.5445 - val_mse: 0.5445\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2890 - mse: 0.2890 - val_loss: 0.6508 - val_mse: 0.6508\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1965 - mse: 0.1965 - val_loss: 0.7769 - val_mse: 0.7769\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2840 - mse: 0.2840 - val_loss: 0.5958 - val_mse: 0.5958\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2491 - mse: 0.2491 - val_loss: 0.5620 - val_mse: 0.5620\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 0.5529 - val_mse: 0.5529\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2176 - mse: 0.2176 - val_loss: 0.5729 - val_mse: 0.5729\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3012 - mse: 0.3012 - val_loss: 0.3266 - val_mse: 0.3266\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2317 - mse: 0.2317 - val_loss: 0.4749 - val_mse: 0.4749\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2527 - mse: 0.2527 - val_loss: 0.5342 - val_mse: 0.5342\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2221 - mse: 0.2221 - val_loss: 0.4252 - val_mse: 0.4252\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.1264 - val_loss: 0.4693 - val_mse: 0.4693\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 0.3869 - val_mse: 0.3869\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1867 - mse: 0.1867 - val_loss: 0.3968 - val_mse: 0.3968\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 0.3571 - val_mse: 0.3571\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1775 - mse: 0.1775 - val_loss: 0.2060 - val_mse: 0.2060\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 0.3641 - val_mse: 0.3641\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1348 - mse: 0.1348 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 0.3694 - val_mse: 0.3694\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1334 - mse: 0.1334 - val_loss: 0.3074 - val_mse: 0.3074\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 0.1825 - val_mse: 0.1825\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.2067 - val_mse: 0.2067\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 0.1452 - val_mse: 0.1452\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.2137 - val_mse: 0.2137\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.2638 - val_mse: 0.2638\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 0.2774 - val_mse: 0.2774\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0984 - val_mse: 0.0984\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.1436 - val_mse: 0.1436\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.2713 - val_mse: 0.2713\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.1733 - val_mse: 0.1733\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.1546 - val_mse: 0.1546\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0723 - val_mse: 0.0723\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.1179 - val_mse: 0.1179\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0967 - val_mse: 0.0967\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0376 - val_mse: 0.0376\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.1030 - val_mse: 0.1030\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0830 - val_mse: 0.0830\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0692 - val_mse: 0.0692\n",
            "Epoch 51/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 52/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 53/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 54/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 55/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0184 - val_mse: 0.0184\n",
            "Epoch 56/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 57/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 58/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0065 - val_mse: 0.0065\n",
            "Epoch 59/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 60/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0186 - val_mse: 0.0186\n",
            "Epoch 61/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 62/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 63/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 64/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 65/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 66/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 67/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.1217e-04 - mse: 9.1217e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 68/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1693e-04 - mse: 7.1693e-04 - val_loss: 8.8296e-04 - val_mse: 8.8296e-04\n",
            "Epoch 69/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4874e-04 - mse: 8.4874e-04 - val_loss: 3.9402e-04 - val_mse: 3.9402e-04\n",
            "Epoch 70/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.6758e-04 - mse: 4.6758e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 71/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4066e-04 - mse: 3.4066e-04 - val_loss: 7.4138e-04 - val_mse: 7.4138e-04\n",
            "Epoch 72/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5330e-04 - mse: 2.5330e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 73/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3838e-04 - mse: 2.3838e-04 - val_loss: 4.3220e-04 - val_mse: 4.3220e-04\n",
            "Epoch 74/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5754e-04 - mse: 1.5754e-04 - val_loss: 1.5648e-04 - val_mse: 1.5648e-04\n",
            "Epoch 75/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2172e-04 - mse: 1.2172e-04 - val_loss: 1.9346e-04 - val_mse: 1.9346e-04\n",
            "Epoch 76/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4641e-05 - mse: 8.4641e-05 - val_loss: 6.9667e-05 - val_mse: 6.9667e-05\n",
            "Epoch 77/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7931e-05 - mse: 6.7931e-05 - val_loss: 2.6043e-05 - val_mse: 2.6043e-05\n",
            "Epoch 78/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9947e-05 - mse: 4.9947e-05 - val_loss: 6.5529e-05 - val_mse: 6.5529e-05\n",
            "Epoch 79/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8549e-05 - mse: 2.8549e-05 - val_loss: 1.0524e-05 - val_mse: 1.0524e-05\n",
            "Epoch 80/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2751e-05 - mse: 2.2751e-05 - val_loss: 4.6399e-05 - val_mse: 4.6399e-05\n",
            "Epoch 81/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8217e-05 - mse: 1.8217e-05 - val_loss: 4.0557e-05 - val_mse: 4.0557e-05\n",
            "Epoch 82/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1709e-05 - mse: 1.1709e-05 - val_loss: 3.3082e-05 - val_mse: 3.3082e-05\n",
            "Epoch 83/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0142e-05 - mse: 1.0142e-05 - val_loss: 1.4013e-05 - val_mse: 1.4013e-05\n",
            "Epoch 84/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3074e-06 - mse: 5.3074e-06 - val_loss: 1.9745e-06 - val_mse: 1.9745e-06\n",
            "Epoch 85/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5147e-06 - mse: 4.5147e-06 - val_loss: 4.6392e-06 - val_mse: 4.6392e-06\n",
            "Epoch 86/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1132e-06 - mse: 2.1132e-06 - val_loss: 1.8061e-06 - val_mse: 1.8061e-06\n",
            "Epoch 87/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2559e-06 - mse: 2.2559e-06 - val_loss: 4.5386e-06 - val_mse: 4.5386e-06\n",
            "Epoch 88/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1593e-06 - mse: 1.1593e-06 - val_loss: 5.8159e-07 - val_mse: 5.8159e-07\n",
            "Epoch 89/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0366e-06 - mse: 1.0366e-06 - val_loss: 1.9156e-06 - val_mse: 1.9156e-06\n",
            "Epoch 90/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2547e-07 - mse: 4.2547e-07 - val_loss: 4.4011e-08 - val_mse: 4.4011e-08\n",
            "Epoch 91/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.7505e-07 - mse: 3.7505e-07 - val_loss: 2.8389e-07 - val_mse: 2.8389e-07\n",
            "Epoch 92/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5967e-07 - mse: 1.5967e-07 - val_loss: 7.1917e-07 - val_mse: 7.1917e-07\n",
            "Epoch 93/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3379e-07 - mse: 1.3379e-07 - val_loss: 2.8951e-07 - val_mse: 2.8951e-07\n",
            "Epoch 94/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7118e-08 - mse: 5.7118e-08 - val_loss: 5.1899e-08 - val_mse: 5.1899e-08\n",
            "Epoch 95/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7795e-08 - mse: 3.7795e-08 - val_loss: 9.6403e-08 - val_mse: 9.6403e-08\n",
            "Epoch 96/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5719e-08 - mse: 2.5719e-08 - val_loss: 1.1513e-07 - val_mse: 1.1513e-07\n",
            "Epoch 97/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5326e-08 - mse: 1.5326e-08 - val_loss: 4.1007e-09 - val_mse: 4.1007e-09\n",
            "Epoch 98/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3466e-08 - mse: 1.3466e-08 - val_loss: 1.2711e-09 - val_mse: 1.2711e-09\n",
            "Epoch 99/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3137e-09 - mse: 5.3137e-09 - val_loss: 2.1002e-08 - val_mse: 2.1002e-08\n",
            "Epoch 100/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4593e-09 - mse: 2.4593e-09 - val_loss: 4.4085e-09 - val_mse: 4.4085e-09\n",
            "Epoch 101/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.7927e-10 - mse: 9.7927e-10 - val_loss: 4.0760e-09 - val_mse: 4.0760e-09\n",
            "Epoch 102/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.5850e-10 - mse: 6.5850e-10 - val_loss: 3.5543e-09 - val_mse: 3.5543e-09\n",
            "Epoch 103/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4748e-10 - mse: 3.4748e-10 - val_loss: 6.2937e-10 - val_mse: 6.2937e-10\n",
            "Epoch 104/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3751e-10 - mse: 1.3751e-10 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
            "Epoch 105/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3851e-10 - mse: 1.3851e-10 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
            "Epoch 106/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2343e-11 - mse: 5.2343e-11 - val_loss: 1.5716e-10 - val_mse: 1.5716e-10\n",
            "Epoch 107/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8769e-11 - mse: 1.8769e-11 - val_loss: 7.5670e-11 - val_mse: 7.5670e-11\n",
            "Epoch 108/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4350e-11 - mse: 1.4350e-11 - val_loss: 7.8580e-11 - val_mse: 7.8580e-11\n",
            "Epoch 109/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.9122e-12 - mse: 7.9122e-12 - val_loss: 7.8580e-11 - val_mse: 7.8580e-11\n",
            "Epoch 110/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.0561e-12 - mse: 9.0561e-12 - val_loss: 7.8580e-11 - val_mse: 7.8580e-11\n",
            "Epoch 111/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0903e-11 - mse: 1.0903e-11 - val_loss: 6.6939e-11 - val_mse: 6.6939e-11\n",
            "Epoch 112/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4224e-12 - mse: 6.4224e-12 - val_loss: 6.6939e-11 - val_mse: 6.6939e-11\n",
            "Epoch 113/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5013e-12 - mse: 5.5013e-12 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
            "Epoch 114/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8010e-12 - mse: 5.8010e-12 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
            "Epoch 115/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9036e-12 - mse: 4.9036e-12 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
            "Epoch 116/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0034e-12 - mse: 6.0034e-12 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
            "Epoch 117/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0729e-12 - mse: 6.0729e-12 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
            "Epoch 118/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3135e-12 - mse: 4.3135e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
            "Epoch 119/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4285e-12 - mse: 7.4285e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 120/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0103e-12 - mse: 4.0103e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
            "Epoch 121/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1895e-12 - mse: 3.1895e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 122/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1452e-12 - mse: 4.1452e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 123/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8255e-12 - mse: 3.8255e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
            "Epoch 124/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8806e-12 - mse: 5.8806e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 125/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2403e-12 - mse: 3.2403e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 126/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.4516e-12 - mse: 4.4516e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 127/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8560e-12 - mse: 3.8560e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 128/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0156e-12 - mse: 4.0156e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
            "Epoch 129/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5645e-12 - mse: 1.5645e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 130/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4475e-12 - mse: 2.4475e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 131/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0655e-12 - mse: 2.0655e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 132/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2061e-12 - mse: 1.2061e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 133/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5612e-12 - mse: 1.5612e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 134/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1906e-12 - mse: 1.1906e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 135/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3173e-12 - mse: 1.3173e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 136/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6833e-12 - mse: 1.6833e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 137/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5644e-13 - mse: 9.5644e-13 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 138/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0993e-12 - mse: 1.0993e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 139/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3327e-12 - mse: 1.3327e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 140/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8191e-12 - mse: 1.8191e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 141/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3572e-12 - mse: 1.3572e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 142/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4427e-13 - mse: 8.4427e-13 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 143/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4300e-12 - mse: 1.4300e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 144/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1923e-12 - mse: 1.1923e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
            "Epoch 145/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.6660e-12 - mse: 3.6660e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
            "Epoch 146/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3874e-11 - mse: 2.3874e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 147/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2241e-12 - mse: 3.2241e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 148/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0747e-12 - mse: 1.0747e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 149/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3936e-12 - mse: 1.3936e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 150/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0887e-12 - mse: 1.0887e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 151/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5949e-13 - mse: 9.5949e-13 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 152/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.6658e-13 - mse: 8.6658e-13 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 153/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1996e-12 - mse: 1.1996e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 154/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3775e-12 - mse: 3.3775e-12 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
            "Epoch 155/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1476e-10 - mse: 3.1476e-10 - val_loss: 7.2068e-09 - val_mse: 7.2068e-09\n",
            "Epoch 156/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.2607e-09 - mse: 8.2607e-09 - val_loss: 2.9482e-06 - val_mse: 2.9482e-06\n",
            "Epoch 157/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1043e-07 - mse: 4.1043e-07 - val_loss: 3.2052e-06 - val_mse: 3.2052e-06\n",
            "Epoch 158/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9780e-06 - mse: 4.9780e-06 - val_loss: 6.6654e-06 - val_mse: 6.6654e-06\n",
            "Epoch 159/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6019e-05 - mse: 1.6019e-05 - val_loss: 3.2373e-05 - val_mse: 3.2373e-05\n",
            "Epoch 160/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 0.4690 - val_mse: 0.4690\n",
            "Epoch 161/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 162/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 1.4500e-05 - val_mse: 1.4500e-05\n",
            "Epoch 163/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1861e-04 - mse: 1.1861e-04 - val_loss: 6.8816e-05 - val_mse: 6.8816e-05\n",
            "Epoch 164/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1176e-06 - mse: 5.1176e-06 - val_loss: 2.6998e-07 - val_mse: 2.6998e-07\n",
            "Epoch 165/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0495e-07 - mse: 3.0495e-07 - val_loss: 3.4984e-07 - val_mse: 3.4984e-07\n",
            "Epoch 166/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.6502e-08 - mse: 3.6502e-08 - val_loss: 1.6716e-08 - val_mse: 1.6716e-08\n",
            "Epoch 167/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3980e-09 - mse: 3.3980e-09 - val_loss: 5.3551e-10 - val_mse: 5.3551e-10\n",
            "Epoch 168/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2220e-09 - mse: 1.2220e-09 - val_loss: 1.2151e-10 - val_mse: 1.2151e-10\n",
            "Epoch 169/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4258e-11 - mse: 3.4258e-11 - val_loss: 4.3947e-10 - val_mse: 4.3947e-10\n",
            "Epoch 170/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3231e-11 - mse: 2.3231e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
            "Epoch 171/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3961e-11 - mse: 1.3961e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
            "Epoch 172/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4988e-12 - mse: 6.4988e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
            "Epoch 173/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3707e-11 - mse: 1.3707e-11 - val_loss: 1.9645e-11 - val_mse: 1.9645e-11\n",
            "Epoch 174/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.1842e-12 - mse: 7.1842e-12 - val_loss: 1.9645e-11 - val_mse: 1.9645e-11\n",
            "Epoch 175/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5788e-12 - mse: 8.5788e-12 - val_loss: 1.9645e-11 - val_mse: 1.9645e-11\n",
            "Epoch 176/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3395e-12 - mse: 7.3395e-12 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
            "Epoch 177/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5693e-11 - mse: 1.5693e-11 - val_loss: 5.8062e-10 - val_mse: 5.8062e-10\n",
            "Epoch 178/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0661e-11 - mse: 3.0661e-11 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
            "Epoch 179/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7643e-12 - mse: 6.7643e-12 - val_loss: 5.9663e-11 - val_mse: 5.9663e-11\n",
            "Epoch 180/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5051e-11 - mse: 2.5051e-11 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
            "Epoch 181/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0097e-09 - mse: 7.0097e-09 - val_loss: 9.3342e-08 - val_mse: 9.3342e-08\n",
            "Epoch 182/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0601e-09 - mse: 4.0601e-09 - val_loss: 2.5696e-08 - val_mse: 2.5696e-08\n",
            "Epoch 183/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8991e-09 - mse: 3.8991e-09 - val_loss: 1.9645e-10 - val_mse: 1.9645e-10\n",
            "Epoch 184/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.4781e-11 - mse: 9.4781e-11 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 185/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.3160e-12 - mse: 9.3160e-12 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
            "Epoch 186/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6255e-11 - mse: 1.6255e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
            "Epoch 187/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3466e-11 - mse: 4.3466e-11 - val_loss: 8.3674e-11 - val_mse: 8.3674e-11\n",
            "Epoch 188/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1467e-11 - mse: 1.1467e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
            "Epoch 189/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2511e-11 - mse: 1.2511e-11 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
            "Epoch 190/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9731e-10 - mse: 1.9731e-10 - val_loss: 5.6680e-10 - val_mse: 5.6680e-10\n",
            "Epoch 191/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8687e-09 - mse: 2.8687e-09 - val_loss: 1.9573e-08 - val_mse: 1.9573e-08\n",
            "Epoch 192/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.1431e-09 - mse: 9.1431e-09 - val_loss: 4.7304e-08 - val_mse: 4.7304e-08\n",
            "Epoch 193/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0039e-06 - mse: 5.0039e-06 - val_loss: 2.4179e-05 - val_mse: 2.4179e-05\n",
            "Epoch 194/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8107e-04 - mse: 1.8107e-04 - val_loss: 4.3719e-04 - val_mse: 4.3719e-04\n",
            "Epoch 195/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2616e-04 - mse: 2.2616e-04 - val_loss: 4.5119e-06 - val_mse: 4.5119e-06\n",
            "Epoch 196/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7107e-04 - mse: 3.7107e-04 - val_loss: 9.6502e-06 - val_mse: 9.6502e-06\n",
            "Epoch 197/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0372 - val_mse: 0.0372\n",
            "Epoch 198/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 199/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0114e-04 - mse: 2.0114e-04 - val_loss: 6.8836e-06 - val_mse: 6.8836e-06\n",
            "Epoch 200/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9895e-05 - mse: 2.9895e-05 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 201/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4386e-04 - mse: 3.4386e-04 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 202/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.9937e-04 - mse: 3.9937e-04 - val_loss: 7.4046e-04 - val_mse: 7.4046e-04\n",
            "Epoch 203/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 8.5224e-04 - val_mse: 8.5224e-04\n",
            "Epoch 204/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4909 - mse: 0.4909 - val_loss: 0.5181 - val_mse: 0.5181\n",
            "Epoch 205/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640 - val_loss: 0.0914 - val_mse: 0.0914\n",
            "Epoch 206/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 207/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7224e-04 - mse: 2.7224e-04 - val_loss: 9.1302e-04 - val_mse: 9.1302e-04\n",
            "Epoch 208/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1922e-05 - mse: 7.1922e-05 - val_loss: 8.0843e-06 - val_mse: 8.0843e-06\n",
            "Epoch 209/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6596e-05 - mse: 1.6596e-05 - val_loss: 4.3643e-07 - val_mse: 4.3643e-07\n",
            "Epoch 210/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3407e-06 - mse: 5.3407e-06 - val_loss: 9.8552e-06 - val_mse: 9.8552e-06\n",
            "Epoch 211/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3098e-06 - mse: 3.3098e-06 - val_loss: 2.2771e-08 - val_mse: 2.2771e-08\n",
            "Epoch 212/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.2330e-07 - mse: 9.2330e-07 - val_loss: 1.0239e-06 - val_mse: 1.0239e-06\n",
            "Epoch 213/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6550e-07 - mse: 7.6550e-07 - val_loss: 2.3741e-09 - val_mse: 2.3741e-09\n",
            "Epoch 214/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.6008e-08 - mse: 4.6008e-08 - val_loss: 1.9504e-07 - val_mse: 1.9504e-07\n",
            "Epoch 215/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4585e-08 - mse: 1.4585e-08 - val_loss: 1.9711e-08 - val_mse: 1.9711e-08\n",
            "Epoch 216/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.1625e-09 - mse: 3.1625e-09 - val_loss: 6.5938e-08 - val_mse: 6.5938e-08\n",
            "Epoch 217/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1934e-08 - mse: 1.1934e-08 - val_loss: 2.6019e-09 - val_mse: 2.6019e-09\n",
            "Epoch 218/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2737e-10 - mse: 4.2737e-10 - val_loss: 8.5129e-11 - val_mse: 8.5129e-11\n",
            "Epoch 219/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4613e-10 - mse: 1.4613e-10 - val_loss: 7.7853e-11 - val_mse: 7.7853e-11\n",
            "Epoch 220/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9554e-11 - mse: 2.9554e-11 - val_loss: 5.7480e-11 - val_mse: 5.7480e-11\n",
            "Epoch 221/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.6492e-12 - mse: 8.6492e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
            "Epoch 222/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8209e-12 - mse: 7.8209e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
            "Epoch 223/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6399e-11 - mse: 1.6399e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 224/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9145e-12 - mse: 5.9145e-12 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 225/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1319e-12 - mse: 6.1319e-12 - val_loss: 2.0082e-10 - val_mse: 2.0082e-10\n",
            "Epoch 226/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4385e-11 - mse: 1.4385e-11 - val_loss: 8.4401e-11 - val_mse: 8.4401e-11\n",
            "Epoch 227/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0446e-12 - mse: 5.0446e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
            "Epoch 228/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5004e-12 - mse: 9.5004e-12 - val_loss: 8.4401e-11 - val_mse: 8.4401e-11\n",
            "Epoch 229/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0896e-12 - mse: 6.0896e-12 - val_loss: 8.4401e-11 - val_mse: 8.4401e-11\n",
            "Epoch 230/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.0677e-12 - mse: 8.0677e-12 - val_loss: 1.5716e-10 - val_mse: 1.5716e-10\n",
            "Epoch 231/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0514e-11 - mse: 1.0514e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 232/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0232e-11 - mse: 1.0232e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 233/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7132e-11 - mse: 1.7132e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
            "Epoch 234/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2073e-11 - mse: 1.2073e-11 - val_loss: 9.3132e-11 - val_mse: 9.3132e-11\n",
            "Epoch 235/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3318e-12 - mse: 6.3318e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
            "Epoch 236/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7179e-11 - mse: 3.7179e-11 - val_loss: 1.5280e-10 - val_mse: 1.5280e-10\n",
            "Epoch 237/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3189e-11 - mse: 1.3189e-11 - val_loss: 2.2919e-10 - val_mse: 2.2919e-10\n",
            "Epoch 238/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.1008e-12 - mse: 7.1008e-12 - val_loss: 1.0987e-10 - val_mse: 1.0987e-10\n",
            "Epoch 239/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7254e-12 - mse: 6.7254e-12 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 240/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.5718e-12 - mse: 5.5718e-12 - val_loss: 5.2387e-11 - val_mse: 5.2387e-11\n",
            "Epoch 241/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1297e-12 - mse: 5.1297e-12 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
            "Epoch 242/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0140e-11 - mse: 2.0140e-11 - val_loss: 2.7285e-10 - val_mse: 2.7285e-10\n",
            "Epoch 243/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2861e-11 - mse: 1.2861e-11 - val_loss: 8.0254e-10 - val_mse: 8.0254e-10\n",
            "Epoch 244/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5572e-11 - mse: 3.5572e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
            "Epoch 245/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0805e-11 - mse: 3.0805e-11 - val_loss: 2.8449e-10 - val_mse: 2.8449e-10\n",
            "Epoch 246/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5872e-11 - mse: 3.5872e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
            "Epoch 247/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.3313e-12 - mse: 8.3313e-12 - val_loss: 1.1059e-10 - val_mse: 1.1059e-10\n",
            "Epoch 248/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5287e-11 - mse: 5.5287e-11 - val_loss: 5.9372e-10 - val_mse: 5.9372e-10\n",
            "Epoch 249/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8169e-09 - mse: 4.8169e-09 - val_loss: 8.4037e-10 - val_mse: 8.4037e-10\n",
            "Epoch 250/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.3372e-10 - mse: 7.3372e-10 - val_loss: 2.7125e-09 - val_mse: 2.7125e-09\n",
            "Epoch 251/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8051e-10 - mse: 2.8051e-10 - val_loss: 1.1787e-10 - val_mse: 1.1787e-10\n",
            "Epoch 252/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2551e-10 - mse: 4.2551e-10 - val_loss: 1.9427e-10 - val_mse: 1.9427e-10\n",
            "Epoch 253/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6153e-11 - mse: 2.6153e-11 - val_loss: 1.1809e-09 - val_mse: 1.1809e-09\n",
            "Epoch 254/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1418e-09 - mse: 1.1418e-09 - val_loss: 1.6176e-08 - val_mse: 1.6176e-08\n",
            "Epoch 255/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2219e-08 - mse: 4.2219e-08 - val_loss: 1.8302e-07 - val_mse: 1.8302e-07\n",
            "Epoch 256/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.6064e-08 - mse: 7.6064e-08 - val_loss: 5.9999e-07 - val_mse: 5.9999e-07\n",
            "Epoch 257/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1529e-07 - mse: 2.1529e-07 - val_loss: 6.3737e-10 - val_mse: 6.3737e-10\n",
            "Epoch 258/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7948e-06 - mse: 2.7948e-06 - val_loss: 4.8604e-07 - val_mse: 4.8604e-07\n",
            "Epoch 259/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2351e-04 - mse: 2.2351e-04 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 260/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.6061 - val_mse: 0.6061\n",
            "Epoch 261/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1979 - mse: 0.1979 - val_loss: 0.0171 - val_mse: 0.0171\n",
            "Epoch 262/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 263/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 2.3467e-05 - val_mse: 2.3467e-05\n",
            "Epoch 264/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.0074e-05 - mse: 8.0074e-05 - val_loss: 1.0339e-05 - val_mse: 1.0339e-05\n",
            "Epoch 265/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2371e-06 - mse: 4.2371e-06 - val_loss: 4.1738e-07 - val_mse: 4.1738e-07\n",
            "Epoch 266/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4952e-07 - mse: 8.4952e-07 - val_loss: 2.9772e-08 - val_mse: 2.9772e-08\n",
            "Epoch 267/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3331e-07 - mse: 2.3331e-07 - val_loss: 2.7501e-08 - val_mse: 2.7501e-08\n",
            "Epoch 268/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4766e-08 - mse: 1.4766e-08 - val_loss: 3.6671e-10 - val_mse: 3.6671e-10\n",
            "Epoch 269/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7059e-09 - mse: 1.7059e-09 - val_loss: 8.4401e-11 - val_mse: 8.4401e-11\n",
            "Epoch 270/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1981e-10 - mse: 1.1981e-10 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
            "Epoch 271/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5243e-11 - mse: 1.5243e-11 - val_loss: 4.6566e-11 - val_mse: 4.6566e-11\n",
            "Epoch 272/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1575e-12 - mse: 3.1575e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 273/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2013e-12 - mse: 4.2013e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
            "Epoch 274/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.9284e-12 - mse: 4.9284e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
            "Epoch 275/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5397e-11 - mse: 1.5397e-11 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
            "Epoch 276/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.2870e-12 - mse: 5.2870e-12 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
            "Epoch 277/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3609e-11 - mse: 3.3609e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
            "Epoch 278/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9104e-11 - mse: 3.9104e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
            "Epoch 279/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8608e-11 - mse: 1.8608e-11 - val_loss: 2.0082e-10 - val_mse: 2.0082e-10\n",
            "Epoch 280/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2972e-09 - mse: 1.2972e-09 - val_loss: 9.6770e-11 - val_mse: 9.6770e-11\n",
            "Epoch 281/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5184e-11 - mse: 5.5184e-11 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
            "Epoch 282/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.7585e-11 - mse: 3.7585e-11 - val_loss: 5.8935e-11 - val_mse: 5.8935e-11\n",
            "Epoch 283/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6944e-10 - mse: 6.6944e-10 - val_loss: 4.9920e-09 - val_mse: 4.9920e-09\n",
            "Epoch 284/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3519e-09 - mse: 2.3519e-09 - val_loss: 4.3679e-08 - val_mse: 4.3679e-08\n",
            "Epoch 285/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5696e-09 - mse: 9.5696e-09 - val_loss: 4.2536e-07 - val_mse: 4.2536e-07\n",
            "Epoch 286/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.0709e-08 - mse: 5.0709e-08 - val_loss: 1.3629e-07 - val_mse: 1.3629e-07\n",
            "Epoch 287/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0868e-08 - mse: 2.0868e-08 - val_loss: 6.2872e-09 - val_mse: 6.2872e-09\n",
            "Epoch 288/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5191e-08 - mse: 9.5191e-08 - val_loss: 1.0785e-08 - val_mse: 1.0785e-08\n",
            "Epoch 289/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4522e-08 - mse: 2.4522e-08 - val_loss: 8.4692e-10 - val_mse: 8.4692e-10\n",
            "Epoch 290/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3946e-10 - mse: 6.3946e-10 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
            "Epoch 291/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0483e-09 - mse: 1.0483e-09 - val_loss: 3.1744e-08 - val_mse: 3.1744e-08\n",
            "Epoch 292/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4108e-09 - mse: 2.4108e-09 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
            "Epoch 293/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7294e-08 - mse: 1.7294e-08 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
            "Epoch 294/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1011e-07 - mse: 5.1011e-07 - val_loss: 6.8288e-06 - val_mse: 6.8288e-06\n",
            "Epoch 295/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3056e-05 - mse: 2.3056e-05 - val_loss: 5.1858e-05 - val_mse: 5.1858e-05\n",
            "Epoch 296/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9935e-06 - mse: 5.9935e-06 - val_loss: 1.3105e-08 - val_mse: 1.3105e-08\n",
            "Epoch 297/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9060e-09 - mse: 4.9060e-09 - val_loss: 1.2442e-10 - val_mse: 1.2442e-10\n",
            "Epoch 298/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8338e-10 - mse: 5.8338e-10 - val_loss: 4.2550e-09 - val_mse: 4.2550e-09\n",
            "Epoch 299/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.0840e-09 - mse: 3.0840e-09 - val_loss: 2.6484e-10 - val_mse: 2.6484e-10\n",
            "Epoch 300/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6545e-09 - mse: 1.6545e-09 - val_loss: 4.4290e-08 - val_mse: 4.4290e-08\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.0012e-08 - mse: 7.0012e-08\n",
            "mse : [7.001217738888954e-08, 7.001217738888954e-08]\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5da002950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[ 81.000244]\n",
            " [ 82.00024 ]\n",
            " [ 83.000244]\n",
            " [ 84.000244]\n",
            " [ 85.00025 ]\n",
            " [ 86.00025 ]\n",
            " [ 87.00025 ]\n",
            " [ 88.00025 ]\n",
            " [ 89.00026 ]\n",
            " [ 90.00027 ]\n",
            " [ 91.00027 ]\n",
            " [ 92.00027 ]\n",
            " [ 93.00027 ]\n",
            " [ 94.000275]\n",
            " [ 95.000275]\n",
            " [ 96.00028 ]\n",
            " [ 97.00028 ]\n",
            " [ 98.00029 ]\n",
            " [ 99.00028 ]\n",
            " [100.00028 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc0uu_FFYvHl",
        "outputId": "e1d7a452-5199-4dd2-d9f9-fd6a809c5996"
      },
      "source": [
        "#RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :  0.00026405311326548856\n",
            "R2 :  0.9999999979030362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P6XdYsgao7l"
      },
      "source": [
        "## 4.3. 함수형 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBbaHIa4bfCP"
      },
      "source": [
        "### 4.3.1. 1:1 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73l_kZrzbjUK"
      },
      "source": [
        "지금까지 모델을 만들 때 model = Sequential()을 이용하여 순차적 모델만을 만들어왔다. 케라스 딥러닝에서는 두 가지 모델을 구성하는 방식이 있다. \n",
        "\n",
        "기존에 배웠던 순차적 모델과 이번에 배울 함수형 모델이다.\n",
        "\n",
        "모델의 간결함은 순차적 모델이 우수하나, 앞으로 모델이 길어지고 앙상블 등의 여러 가지 기법을 사용하고자 하면 함수형 모델은 필수이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgwvzAc3Yutd",
        "outputId": "71876dce-6728-4d7d-d67b-e8f8891073cc"
      },
      "source": [
        "# 1. 데이터 준비 \n",
        "import numpy as np\n",
        "x = np.array(range(1, 101))\n",
        "y = np.array(range(1, 101))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=66, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=66, shuffle=False)\n",
        "## test 데이터의 50%를 validation에 배분하게 되어 train:val:test의 비율이 6:2:2가 된다.\n",
        "\n",
        "\n",
        "# 2. 모델 구성\n",
        "from keras.models import Sequential, Model   ## Model을 추가해준다.\n",
        "from keras.layers import Dense, Input  ## Input 레이어를 추가해준다.\n",
        "\n",
        "input1 = Input(shape=(1,))\n",
        "dense1 = Dense(5, activation='relu')(input1)\n",
        "dense2 = Dense(3)(dense1)\n",
        "dense3 = Dense(4)(dense2)\n",
        "output1 = Dense(1)(dense3)\n",
        "\n",
        "model = Model(inputs = input1, outputs= output1)\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 5)                 10        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 18        \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 4)                 16        \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 49\n",
            "Trainable params: 49\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9t4xGGtc_Bt"
      },
      "source": [
        "-> 총 49개의 파라미터를 사용한 간단한 심층 신경망 모델이 잘 구현되었음을 확인할 수 있다. \n",
        "\n",
        "*   Input(shape=(1,))\n",
        "\n",
        "  : Input레이어를 이용하여 shape을 구성한다. 1개의 컬럼이 들어가므로 shape에 1을 입력한다.\n",
        "\n",
        "*   다음 레이어들부터는 상위층에서 출력된 레이어의 이름을 하위층의 가장 끝부분에 명시해준다.\n",
        "\n",
        "*   마지막으로 Model을 통해 input 레이어와 output 레이어를 엮어준다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nn8NBakc3Nq",
        "outputId": "0ad36747-31e7-471a-be21-25b22c7d52f4"
      },
      "source": [
        "# 3. 훈련\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_val, y_val))\n",
        "\n",
        "# 4. 평가 예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=3)\n",
        "print('mse :', mse)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)\n",
        "\n",
        "#RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 1085.6285 - mse: 1085.6285 - val_loss: 3990.5090 - val_mse: 3990.5090\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 936.7070 - mse: 936.7070 - val_loss: 2741.6665 - val_mse: 2741.6665\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 540.1752 - mse: 540.1752 - val_loss: 1542.9612 - val_mse: 1542.9612\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 294.1379 - mse: 294.1379 - val_loss: 487.9391 - val_mse: 487.9391\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 69.9544 - mse: 69.9544 - val_loss: 86.0607 - val_mse: 86.0607\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.9289 - mse: 7.9289 - val_loss: 9.8115 - val_mse: 9.8115\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4657 - mse: 1.4657 - val_loss: 3.6859 - val_mse: 3.6859\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2360 - mse: 1.2360 - val_loss: 3.2513 - val_mse: 3.2513\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1637 - mse: 1.1637 - val_loss: 2.9146 - val_mse: 2.9146\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9860 - mse: 0.9860 - val_loss: 3.2440 - val_mse: 3.2440\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2623 - mse: 1.2623 - val_loss: 2.7734 - val_mse: 2.7734\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1884 - mse: 1.1884 - val_loss: 3.1221 - val_mse: 3.1221\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9529 - mse: 0.9529 - val_loss: 2.4747 - val_mse: 2.4747\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 3.0478 - val_mse: 3.0478\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9411 - mse: 0.9411 - val_loss: 2.3454 - val_mse: 2.3454\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7569 - mse: 0.7569 - val_loss: 2.0659 - val_mse: 2.0659\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9104 - mse: 0.9104 - val_loss: 2.8520 - val_mse: 2.8520\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8916 - mse: 0.8916 - val_loss: 2.3552 - val_mse: 2.3552\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6959 - mse: 0.6959 - val_loss: 1.7731 - val_mse: 1.7731\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7558 - mse: 0.7558 - val_loss: 1.8572 - val_mse: 1.8572\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7867 - mse: 0.7867 - val_loss: 2.2686 - val_mse: 2.2686\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7009 - mse: 0.7009 - val_loss: 1.2849 - val_mse: 1.2849\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8601 - mse: 0.8601 - val_loss: 1.7006 - val_mse: 1.7006\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4802 - mse: 0.4802 - val_loss: 1.1281 - val_mse: 1.1281\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5773 - mse: 0.5773 - val_loss: 1.6969 - val_mse: 1.6969\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5064 - mse: 0.5064 - val_loss: 0.9160 - val_mse: 0.9160\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5218 - mse: 0.5218 - val_loss: 1.1637 - val_mse: 1.1637\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5533 - mse: 0.5533 - val_loss: 0.9409 - val_mse: 0.9409\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4854 - mse: 0.4854 - val_loss: 1.2669 - val_mse: 1.2669\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 1.0023 - val_mse: 1.0023\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4847 - mse: 0.4847 - val_loss: 0.9281 - val_mse: 0.9281\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3913 - mse: 0.3913 - val_loss: 0.9067 - val_mse: 0.9067\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.6237 - val_mse: 0.6237\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2704 - mse: 0.2704 - val_loss: 0.5503 - val_mse: 0.5503\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2695 - mse: 0.2695 - val_loss: 1.2198 - val_mse: 1.2198\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2609 - mse: 0.2609 - val_loss: 0.6913 - val_mse: 0.6913\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2485 - mse: 0.2485 - val_loss: 0.3636 - val_mse: 0.3636\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2309 - mse: 0.2309 - val_loss: 0.5052 - val_mse: 0.5052\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.3457 - val_mse: 0.3457\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1698 - mse: 0.1698 - val_loss: 0.5303 - val_mse: 0.5303\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.2582 - val_mse: 0.2582\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1301 - mse: 0.1301 - val_loss: 0.3199 - val_mse: 0.3199\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 0.3386 - val_mse: 0.3386\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 0.2585 - val_mse: 0.2585\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.1471 - val_mse: 0.1471\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.1548 - val_mse: 0.1548\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 0.1377 - val_mse: 0.1377\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0877 - val_mse: 0.0877\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0709 - val_mse: 0.0709\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.1131 - val_mse: 0.1131\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0511 - val_mse: 0.0511\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0388 - val_mse: 0.0388\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0433 - val_mse: 0.0433\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.7540e-04 - mse: 8.7540e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5033e-04 - mse: 5.5033e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3958e-04 - mse: 4.3958e-04 - val_loss: 4.8063e-04 - val_mse: 4.8063e-04\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8211e-04 - mse: 3.8211e-04 - val_loss: 3.6194e-04 - val_mse: 3.6194e-04\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0083e-04 - mse: 3.0083e-04 - val_loss: 2.9599e-04 - val_mse: 2.9599e-04\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3125e-04 - mse: 1.3125e-04 - val_loss: 1.1332e-04 - val_mse: 1.1332e-04\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1263e-04 - mse: 1.1263e-04 - val_loss: 4.9747e-04 - val_mse: 4.9747e-04\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.8531e-05 - mse: 8.8531e-05 - val_loss: 2.2092e-05 - val_mse: 2.2092e-05\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.8178e-05 - mse: 8.8178e-05 - val_loss: 2.9603e-04 - val_mse: 2.9603e-04\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.5596e-05 - mse: 5.5596e-05 - val_loss: 1.9641e-05 - val_mse: 1.9641e-05\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5459e-05 - mse: 3.5459e-05 - val_loss: 4.0765e-05 - val_mse: 4.0765e-05\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2213e-05 - mse: 2.2213e-05 - val_loss: 3.8244e-05 - val_mse: 3.8244e-05\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3007e-05 - mse: 1.3007e-05 - val_loss: 4.3787e-05 - val_mse: 4.3787e-05\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.6495e-06 - mse: 9.6495e-06 - val_loss: 2.4346e-05 - val_mse: 2.4346e-05\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.0076e-06 - mse: 7.0076e-06 - val_loss: 1.0792e-05 - val_mse: 1.0792e-05\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8191e-06 - mse: 3.8191e-06 - val_loss: 1.4557e-05 - val_mse: 1.4557e-05\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3268e-06 - mse: 3.3268e-06 - val_loss: 5.1617e-06 - val_mse: 5.1617e-06\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8155e-06 - mse: 1.8155e-06 - val_loss: 2.4768e-06 - val_mse: 2.4768e-06\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6177e-07 - mse: 9.6177e-07 - val_loss: 2.7935e-06 - val_mse: 2.7935e-06\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3515e-07 - mse: 7.3515e-07 - val_loss: 1.1437e-08 - val_mse: 1.1437e-08\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.9643e-07 - mse: 3.9643e-07 - val_loss: 3.7264e-07 - val_mse: 3.7264e-07\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9710e-07 - mse: 2.9710e-07 - val_loss: 1.6230e-07 - val_mse: 1.6230e-07\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5856e-07 - mse: 1.5856e-07 - val_loss: 5.7451e-09 - val_mse: 5.7451e-09\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8223e-08 - mse: 7.8223e-08 - val_loss: 8.3206e-08 - val_mse: 8.3206e-08\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1764e-08 - mse: 4.1764e-08 - val_loss: 1.3578e-08 - val_mse: 1.3578e-08\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7469e-08 - mse: 1.7469e-08 - val_loss: 1.2998e-08 - val_mse: 1.2998e-08\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1483e-08 - mse: 1.1483e-08 - val_loss: 7.3151e-08 - val_mse: 7.3151e-08\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3025e-09 - mse: 8.3025e-09 - val_loss: 6.3686e-09 - val_mse: 6.3686e-09\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2946e-09 - mse: 3.2946e-09 - val_loss: 6.1045e-10 - val_mse: 6.1045e-10\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5297e-09 - mse: 1.5297e-09 - val_loss: 1.0717e-09 - val_mse: 1.0717e-09\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0859e-10 - mse: 6.0859e-10 - val_loss: 3.5870e-10 - val_mse: 3.5870e-10\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7405e-10 - mse: 2.7405e-10 - val_loss: 3.8490e-10 - val_mse: 3.8490e-10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1.0186e-09 - mse: 1.0186e-09\n",
            "mse : [1.0186340659856796e-09, 1.0186340659856796e-09]\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5d9041b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[80.99998]\n",
            " [81.99998]\n",
            " [82.99997]\n",
            " [83.99997]\n",
            " [84.99996]\n",
            " [85.99997]\n",
            " [86.99997]\n",
            " [87.99997]\n",
            " [88.99997]\n",
            " [89.99997]\n",
            " [90.99997]\n",
            " [91.99996]\n",
            " [92.99996]\n",
            " [93.99997]\n",
            " [94.99996]\n",
            " [95.99997]\n",
            " [96.99996]\n",
            " [97.99997]\n",
            " [98.99997]\n",
            " [99.99997]]\n",
            "RMSE :  3.1961608986897905e-05\n",
            "R2 :  0.9999999999692769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBLKC3EVfLHF"
      },
      "source": [
        "-> mse, RMSE, R2 모두 괜찮은 값이 나왔고, 모델도 잘 돌아갔음을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ut50PmJfdtM"
      },
      "source": [
        "### 4.3.2. 다:다 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-9YcNVc4jX1"
      },
      "source": [
        "지금까지는 입력되는 칼럼의 수가 1개였다(input_dim=1 또는 input_shape=(1,)). 이제부터 2개 이상의 컬럼이 입력되는 경우를 살펴보자. \n",
        "\n",
        "x와 y는 1에서 100까지의 정수와 301에서 400까지의 정수를 사용한다. 모델에 입력하기 위해서는 행과 열이 맞아야 한다. \n",
        "\n",
        "DNN의 구조에서는 차원(dimension)이 가장 중요하여, 행은 무시되고 열(컬럼)이 우선된다. \n",
        "\n",
        "그러다 보니 모델에서 입력할 때 input_dim = 1 또는 input_shape=(1,)과 같은 파라미터를 요구하게 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQsWBdbhe8-O",
        "outputId": "5705247f-8f09-43de-98ab-ddfb4146190c"
      },
      "source": [
        "# 1. 데이터 준비 \n",
        "import numpy as np\n",
        "x = np.array([range(100), range(301, 401)])\n",
        "y = np.array([range(100), range(301, 401)])\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 100)\n",
            "(2, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KRD2Y3y6ibH"
      },
      "source": [
        "-> 위의 shape을 통해 본 결과를 확인해보면, 데이터 구조가 2행 100열로 컬럼이 100개이다.\n",
        "\n",
        "우리가 원하는 구조는 100행 2열이므로, 행과 열을 바꿔줘야한다. 이때 필요한 메서드는 transpose()이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9257COC6dfm",
        "outputId": "6297dfda-cb60-4a32-d773-de01d007af41"
      },
      "source": [
        "# 행 열 바꾸기 -> transpose() 이용\n",
        "x = np.transpose(x)\n",
        "y = np.transpose(y)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 2)\n",
            "(100, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouKvGFmc6-dW"
      },
      "source": [
        "이제 우리가 원하는 100행 2열로 바뀌었다. input_dim = 2로 가능하게 데이터의 구조가 변경되었다. \n",
        "\n",
        "이제 데이터를 train, test, val로 분리한 후 모델을 구성해보자. 마찬가지로 6:2:2로 구성해볼 것이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx8o7rYE68C-",
        "outputId": "8e084660-6f1f-4794-dfbe-aa19be57e4d9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66,  test_size=0.4, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, random_state=66, test_size=0.5, shuffle=False)\n",
        "\n",
        "# 2. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(5, input_shape = (2, ), activation='relu'))  ## input_shape = (1, ) > input_shape = (2, )\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(2))\n",
        "\n",
        "# 3. 훈련\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=300, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "# 4. 평가 예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('mse :', mse)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)\n",
        "\n",
        "#RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 55416.9916 - mse: 55416.9916 - val_loss: 56108.6562 - val_mse: 56108.6562\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 39419.7544 - mse: 39419.7544 - val_loss: 24917.3223 - val_mse: 24917.3223\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13861.5386 - mse: 13861.5386 - val_loss: 3551.2949 - val_mse: 3551.2949\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1039.6644 - mse: 1039.6644 - val_loss: 1031.8201 - val_mse: 1031.8201\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 138.4219 - mse: 138.4219 - val_loss: 1109.6838 - val_mse: 1109.6838\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 213.4631 - mse: 213.4631 - val_loss: 786.4839 - val_mse: 786.4839\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 185.9861 - mse: 185.9861 - val_loss: 980.7390 - val_mse: 980.7390\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 207.8160 - mse: 207.8160 - val_loss: 793.0529 - val_mse: 793.0529\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 145.4559 - mse: 145.4559 - val_loss: 963.5262 - val_mse: 963.5262\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 182.9980 - mse: 182.9980 - val_loss: 841.1655 - val_mse: 841.1655\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 183.4193 - mse: 183.4193 - val_loss: 961.7982 - val_mse: 961.7982\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 180.0216 - mse: 180.0216 - val_loss: 649.3042 - val_mse: 649.3042\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 202.1486 - mse: 202.1486 - val_loss: 754.6610 - val_mse: 754.6610\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 167.1251 - mse: 167.1251 - val_loss: 592.9097 - val_mse: 592.9097\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 145.3216 - mse: 145.3216 - val_loss: 1008.5619 - val_mse: 1008.5619\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 157.1998 - mse: 157.1998 - val_loss: 734.6367 - val_mse: 734.6367\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 172.6660 - mse: 172.6660 - val_loss: 543.9840 - val_mse: 543.9840\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 145.6729 - mse: 145.6729 - val_loss: 851.5734 - val_mse: 851.5734\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 134.3592 - mse: 134.3592 - val_loss: 577.1646 - val_mse: 577.1646\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 146.3945 - mse: 146.3945 - val_loss: 592.5502 - val_mse: 592.5502\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 141.1945 - mse: 141.1945 - val_loss: 602.7770 - val_mse: 602.7770\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 111.6570 - mse: 111.6570 - val_loss: 582.1448 - val_mse: 582.1448\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 127.5256 - mse: 127.5256 - val_loss: 677.1163 - val_mse: 677.1163\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 148.0906 - mse: 148.0906 - val_loss: 423.3492 - val_mse: 423.3492\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 122.5959 - mse: 122.5959 - val_loss: 822.3135 - val_mse: 822.3135\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 126.3295 - mse: 126.3295 - val_loss: 514.0316 - val_mse: 514.0316\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 130.3063 - mse: 130.3063 - val_loss: 667.0212 - val_mse: 667.0212\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 135.3893 - mse: 135.3893 - val_loss: 514.2867 - val_mse: 514.2867\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 121.5768 - mse: 121.5768 - val_loss: 545.8560 - val_mse: 545.8560\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 111.3830 - mse: 111.3830 - val_loss: 439.4655 - val_mse: 439.4655\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 121.7891 - mse: 121.7891 - val_loss: 376.5486 - val_mse: 376.5486\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 99.1280 - mse: 99.1280 - val_loss: 747.0215 - val_mse: 747.0215\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 115.0074 - mse: 115.0074 - val_loss: 489.0008 - val_mse: 489.0008\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 86.8840 - mse: 86.8840 - val_loss: 459.7799 - val_mse: 459.7799\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 106.1911 - mse: 106.1911 - val_loss: 452.0817 - val_mse: 452.0817\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 120.1338 - mse: 120.1338 - val_loss: 358.6024 - val_mse: 358.6024\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 77.3317 - mse: 77.3317 - val_loss: 448.5966 - val_mse: 448.5966\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 77.6251 - mse: 77.6251 - val_loss: 474.9228 - val_mse: 474.9228\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 59.7365 - mse: 59.7365 - val_loss: 429.7015 - val_mse: 429.7015\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 69.4117 - mse: 69.4117 - val_loss: 247.4790 - val_mse: 247.4790\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 55.2891 - mse: 55.2891 - val_loss: 380.2458 - val_mse: 380.2458\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 58.1618 - mse: 58.1618 - val_loss: 290.1827 - val_mse: 290.1827\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 70.7640 - mse: 70.7640 - val_loss: 212.3321 - val_mse: 212.3321\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 48.4184 - mse: 48.4184 - val_loss: 198.6631 - val_mse: 198.6631\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 46.9915 - mse: 46.9915 - val_loss: 174.0047 - val_mse: 174.0047\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 39.9529 - mse: 39.9529 - val_loss: 178.4884 - val_mse: 178.4884\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 42.1675 - mse: 42.1675 - val_loss: 194.1059 - val_mse: 194.1059\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 28.2274 - mse: 28.2274 - val_loss: 80.7514 - val_mse: 80.7514\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 31.4339 - mse: 31.4339 - val_loss: 70.4526 - val_mse: 70.4526\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 25.5892 - mse: 25.5892 - val_loss: 49.8306 - val_mse: 49.8306\n",
            "Epoch 51/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 26.4836 - mse: 26.4836 - val_loss: 54.8932 - val_mse: 54.8932\n",
            "Epoch 52/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 14.7737 - mse: 14.7737 - val_loss: 57.1113 - val_mse: 57.1113\n",
            "Epoch 53/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11.6178 - mse: 11.6178 - val_loss: 62.3558 - val_mse: 62.3558\n",
            "Epoch 54/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11.7862 - mse: 11.7862 - val_loss: 36.2797 - val_mse: 36.2797\n",
            "Epoch 55/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2041 - mse: 7.2041 - val_loss: 31.1793 - val_mse: 31.1793\n",
            "Epoch 56/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9237 - mse: 5.9237 - val_loss: 29.2460 - val_mse: 29.2460\n",
            "Epoch 57/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7492 - mse: 4.7492 - val_loss: 15.3049 - val_mse: 15.3049\n",
            "Epoch 58/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8042 - mse: 2.8042 - val_loss: 12.1107 - val_mse: 12.1107\n",
            "Epoch 59/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0373 - mse: 2.0373 - val_loss: 8.1442 - val_mse: 8.1442\n",
            "Epoch 60/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3754 - mse: 1.3754 - val_loss: 8.7108 - val_mse: 8.7108\n",
            "Epoch 61/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9868 - mse: 0.9868 - val_loss: 2.3017 - val_mse: 2.3017\n",
            "Epoch 62/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5938 - mse: 0.5938 - val_loss: 3.5688 - val_mse: 3.5688\n",
            "Epoch 63/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6556 - mse: 0.6556 - val_loss: 1.8301 - val_mse: 1.8301\n",
            "Epoch 64/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 0.7506 - val_mse: 0.7506\n",
            "Epoch 65/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1717 - mse: 0.1717 - val_loss: 0.7479 - val_mse: 0.7479\n",
            "Epoch 66/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 0.7893 - val_mse: 0.7893\n",
            "Epoch 67/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.4745 - val_mse: 0.4745\n",
            "Epoch 68/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0916 - val_mse: 0.0916\n",
            "Epoch 69/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.1160 - val_mse: 0.1160\n",
            "Epoch 70/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1583 - val_mse: 0.1583\n",
            "Epoch 71/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0372 - val_mse: 0.0372\n",
            "Epoch 72/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 73/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 74/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0194 - val_mse: 0.0194\n",
            "Epoch 75/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0058 - val_mse: 0.0058\n",
            "Epoch 76/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 77/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.7054e-04 - mse: 8.7054e-04 - val_loss: 7.3247e-04 - val_mse: 7.3247e-04\n",
            "Epoch 78/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.6565e-04 - mse: 5.6565e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 79/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5547e-04 - mse: 2.5547e-04 - val_loss: 8.9507e-04 - val_mse: 8.9507e-04\n",
            "Epoch 80/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4685e-04 - mse: 1.4685e-04 - val_loss: 1.9655e-04 - val_mse: 1.9655e-04\n",
            "Epoch 81/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6317e-05 - mse: 7.6317e-05 - val_loss: 9.3376e-05 - val_mse: 9.3376e-05\n",
            "Epoch 82/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1910e-05 - mse: 3.1910e-05 - val_loss: 5.0789e-05 - val_mse: 5.0789e-05\n",
            "Epoch 83/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9487e-05 - mse: 2.9487e-05 - val_loss: 1.3663e-05 - val_mse: 1.3663e-05\n",
            "Epoch 84/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3679e-05 - mse: 1.3679e-05 - val_loss: 5.8337e-06 - val_mse: 5.8337e-06\n",
            "Epoch 85/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1001e-06 - mse: 6.1001e-06 - val_loss: 1.3985e-05 - val_mse: 1.3985e-05\n",
            "Epoch 86/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4725e-06 - mse: 3.4725e-06 - val_loss: 1.9583e-05 - val_mse: 1.9583e-05\n",
            "Epoch 87/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6288e-06 - mse: 1.6288e-06 - val_loss: 3.6377e-06 - val_mse: 3.6377e-06\n",
            "Epoch 88/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8741e-07 - mse: 7.8741e-07 - val_loss: 7.9474e-07 - val_mse: 7.9474e-07\n",
            "Epoch 89/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2030e-07 - mse: 2.2030e-07 - val_loss: 6.1930e-07 - val_mse: 6.1930e-07\n",
            "Epoch 90/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0407e-07 - mse: 1.0407e-07 - val_loss: 1.7315e-07 - val_mse: 1.7315e-07\n",
            "Epoch 91/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.0019e-08 - mse: 6.0019e-08 - val_loss: 2.2092e-07 - val_mse: 2.2092e-07\n",
            "Epoch 92/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4692e-08 - mse: 6.4692e-08 - val_loss: 1.1300e-07 - val_mse: 1.1300e-07\n",
            "Epoch 93/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8494e-08 - mse: 1.8494e-08 - val_loss: 4.3568e-08 - val_mse: 4.3568e-08\n",
            "Epoch 94/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.4213e-09 - mse: 8.4213e-09 - val_loss: 3.3324e-08 - val_mse: 3.3324e-08\n",
            "Epoch 95/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0260e-09 - mse: 8.0260e-09 - val_loss: 3.0890e-08 - val_mse: 3.0890e-08\n",
            "Epoch 96/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1909e-09 - mse: 5.1909e-09 - val_loss: 2.1947e-08 - val_mse: 2.1947e-08\n",
            "Epoch 97/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2536e-09 - mse: 4.2536e-09 - val_loss: 1.3745e-08 - val_mse: 1.3745e-08\n",
            "Epoch 98/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3828e-09 - mse: 2.3828e-09 - val_loss: 1.7311e-08 - val_mse: 1.7311e-08\n",
            "Epoch 99/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1140e-09 - mse: 3.1140e-09 - val_loss: 1.1317e-08 - val_mse: 1.1317e-08\n",
            "Epoch 100/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2568e-09 - mse: 2.2568e-09 - val_loss: 9.7654e-09 - val_mse: 9.7654e-09\n",
            "Epoch 101/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7861e-09 - mse: 1.7861e-09 - val_loss: 2.6157e-09 - val_mse: 2.6157e-09\n",
            "Epoch 102/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3253e-09 - mse: 1.3253e-09 - val_loss: 5.6836e-09 - val_mse: 5.6836e-09\n",
            "Epoch 103/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2757e-09 - mse: 1.2757e-09 - val_loss: 2.6092e-09 - val_mse: 2.6092e-09\n",
            "Epoch 104/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3158e-09 - mse: 1.3158e-09 - val_loss: 4.6566e-09 - val_mse: 4.6566e-09\n",
            "Epoch 105/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0526e-09 - mse: 1.0526e-09 - val_loss: 3.6802e-09 - val_mse: 3.6802e-09\n",
            "Epoch 106/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.3970e-10 - mse: 9.3970e-10 - val_loss: 1.9445e-09 - val_mse: 1.9445e-09\n",
            "Epoch 107/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.8915e-10 - mse: 8.8915e-10 - val_loss: 1.7884e-09 - val_mse: 1.7884e-09\n",
            "Epoch 108/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6341e-10 - mse: 7.6341e-10 - val_loss: 7.6543e-10 - val_mse: 7.6543e-10\n",
            "Epoch 109/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5561e-10 - mse: 9.5561e-10 - val_loss: 1.1241e-09 - val_mse: 1.1241e-09\n",
            "Epoch 110/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.5546e-10 - mse: 7.5546e-10 - val_loss: 8.2837e-10 - val_mse: 8.2837e-10\n",
            "Epoch 111/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3085e-10 - mse: 6.3085e-10 - val_loss: 2.1853e-09 - val_mse: 2.1853e-09\n",
            "Epoch 112/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3399e-10 - mse: 8.3399e-10 - val_loss: 1.3824e-09 - val_mse: 1.3824e-09\n",
            "Epoch 113/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.6606e-10 - mse: 6.6606e-10 - val_loss: 6.5229e-10 - val_mse: 6.5229e-10\n",
            "Epoch 114/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.2862e-10 - mse: 7.2862e-10 - val_loss: 1.3508e-09 - val_mse: 1.3508e-09\n",
            "Epoch 115/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3820e-10 - mse: 5.3820e-10 - val_loss: 1.6043e-09 - val_mse: 1.6043e-09\n",
            "Epoch 116/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.7704e-10 - mse: 7.7704e-10 - val_loss: 6.4356e-10 - val_mse: 6.4356e-10\n",
            "Epoch 117/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.8246e-10 - mse: 6.8246e-10 - val_loss: 4.8640e-10 - val_mse: 4.8640e-10\n",
            "Epoch 118/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8113e-10 - mse: 3.8113e-10 - val_loss: 3.1650e-10 - val_mse: 3.1650e-10\n",
            "Epoch 119/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.3478e-10 - mse: 5.3478e-10 - val_loss: 5.5734e-10 - val_mse: 5.5734e-10\n",
            "Epoch 120/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0919e-10 - mse: 4.0919e-10 - val_loss: 9.9244e-10 - val_mse: 9.9244e-10\n",
            "Epoch 121/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4448e-10 - mse: 5.4448e-10 - val_loss: 7.6179e-10 - val_mse: 7.6179e-10\n",
            "Epoch 122/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0608e-10 - mse: 5.0608e-10 - val_loss: 4.3401e-10 - val_mse: 4.3401e-10\n",
            "Epoch 123/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.3799e-10 - mse: 5.3799e-10 - val_loss: 1.0805e-09 - val_mse: 1.0805e-09\n",
            "Epoch 124/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7404e-10 - mse: 5.7404e-10 - val_loss: 4.2746e-10 - val_mse: 4.2746e-10\n",
            "Epoch 125/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4141e-10 - mse: 6.4141e-10 - val_loss: 5.8571e-10 - val_mse: 5.8571e-10\n",
            "Epoch 126/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.3536e-10 - mse: 5.3536e-10 - val_loss: 5.3806e-10 - val_mse: 5.3806e-10\n",
            "Epoch 127/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.8901e-10 - mse: 3.8901e-10 - val_loss: 6.2282e-10 - val_mse: 6.2282e-10\n",
            "Epoch 128/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4330e-10 - mse: 5.4330e-10 - val_loss: 3.9872e-10 - val_mse: 3.9872e-10\n",
            "Epoch 129/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4144e-10 - mse: 3.4144e-10 - val_loss: 6.2319e-10 - val_mse: 6.2319e-10\n",
            "Epoch 130/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.8609e-10 - mse: 3.8609e-10 - val_loss: 5.2569e-10 - val_mse: 5.2569e-10\n",
            "Epoch 131/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2251e-10 - mse: 4.2251e-10 - val_loss: 7.0031e-10 - val_mse: 7.0031e-10\n",
            "Epoch 132/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5813e-10 - mse: 3.5813e-10 - val_loss: 4.8531e-10 - val_mse: 4.8531e-10\n",
            "Epoch 133/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5608e-10 - mse: 4.5608e-10 - val_loss: 7.4833e-10 - val_mse: 7.4833e-10\n",
            "Epoch 134/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7927e-10 - mse: 4.7927e-10 - val_loss: 3.5870e-10 - val_mse: 3.5870e-10\n",
            "Epoch 135/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.0532e-10 - mse: 6.0532e-10 - val_loss: 1.2780e-09 - val_mse: 1.2780e-09\n",
            "Epoch 136/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2961e-10 - mse: 5.2961e-10 - val_loss: 4.6202e-10 - val_mse: 4.6202e-10\n",
            "Epoch 137/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4614e-10 - mse: 5.4614e-10 - val_loss: 7.7162e-10 - val_mse: 7.7162e-10\n",
            "Epoch 138/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.4354e-10 - mse: 4.4354e-10 - val_loss: 6.0681e-10 - val_mse: 6.0681e-10\n",
            "Epoch 139/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.4016e-10 - mse: 5.4016e-10 - val_loss: 5.2751e-10 - val_mse: 5.2751e-10\n",
            "Epoch 140/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8921e-10 - mse: 5.8921e-10 - val_loss: 4.2237e-10 - val_mse: 4.2237e-10\n",
            "Epoch 141/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7720e-10 - mse: 7.7720e-10 - val_loss: 1.1372e-09 - val_mse: 1.1372e-09\n",
            "Epoch 142/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3637e-10 - mse: 6.3637e-10 - val_loss: 1.8194e-09 - val_mse: 1.8194e-09\n",
            "Epoch 143/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.1679e-10 - mse: 4.1679e-10 - val_loss: 3.9181e-10 - val_mse: 3.9181e-10\n",
            "Epoch 144/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.2024e-10 - mse: 6.2024e-10 - val_loss: 9.6770e-10 - val_mse: 9.6770e-10\n",
            "Epoch 145/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.1339e-10 - mse: 8.1339e-10 - val_loss: 9.0840e-10 - val_mse: 9.0840e-10\n",
            "Epoch 146/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.3368e-10 - mse: 8.3368e-10 - val_loss: 7.9744e-10 - val_mse: 7.9744e-10\n",
            "Epoch 147/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.1612e-10 - mse: 8.1612e-10 - val_loss: 8.1382e-10 - val_mse: 8.1382e-10\n",
            "Epoch 148/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.2667e-10 - mse: 5.2667e-10 - val_loss: 3.7544e-10 - val_mse: 3.7544e-10\n",
            "Epoch 149/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7612e-10 - mse: 4.7612e-10 - val_loss: 8.9556e-09 - val_mse: 8.9556e-09\n",
            "Epoch 150/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4303e-09 - mse: 3.4303e-09 - val_loss: 7.0140e-10 - val_mse: 7.0140e-10\n",
            "Epoch 151/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.6217e-10 - mse: 4.6217e-10 - val_loss: 3.7471e-10 - val_mse: 3.7471e-10\n",
            "Epoch 152/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6668e-10 - mse: 6.6668e-10 - val_loss: 1.4406e-09 - val_mse: 1.4406e-09\n",
            "Epoch 153/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1563e-09 - mse: 2.1563e-09 - val_loss: 6.0609e-10 - val_mse: 6.0609e-10\n",
            "Epoch 154/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3747e-09 - mse: 1.3747e-09 - val_loss: 1.4138e-08 - val_mse: 1.4138e-08\n",
            "Epoch 155/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5377e-09 - mse: 3.5377e-09 - val_loss: 1.7149e-09 - val_mse: 1.7149e-09\n",
            "Epoch 156/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1215e-09 - mse: 2.1215e-09 - val_loss: 9.6188e-10 - val_mse: 9.6188e-10\n",
            "Epoch 157/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4883e-09 - mse: 1.4883e-09 - val_loss: 1.4596e-09 - val_mse: 1.4596e-09\n",
            "Epoch 158/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0584e-09 - mse: 1.0584e-09 - val_loss: 9.7571e-10 - val_mse: 9.7571e-10\n",
            "Epoch 159/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.9533e-10 - mse: 6.9533e-10 - val_loss: 9.7425e-10 - val_mse: 9.7425e-10\n",
            "Epoch 160/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.5454e-10 - mse: 7.5454e-10 - val_loss: 8.3746e-10 - val_mse: 8.3746e-10\n",
            "Epoch 161/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5615e-09 - mse: 1.5615e-09 - val_loss: 8.8068e-09 - val_mse: 8.8068e-09\n",
            "Epoch 162/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.7617e-09 - mse: 7.7617e-09 - val_loss: 8.4157e-09 - val_mse: 8.4157e-09\n",
            "Epoch 163/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.8341e-09 - mse: 8.8341e-09 - val_loss: 4.3863e-09 - val_mse: 4.3863e-09\n",
            "Epoch 164/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1557e-08 - mse: 2.1557e-08 - val_loss: 9.6294e-09 - val_mse: 9.6294e-09\n",
            "Epoch 165/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5157e-09 - mse: 4.5157e-09 - val_loss: 1.2324e-08 - val_mse: 1.2324e-08\n",
            "Epoch 166/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.5418e-09 - mse: 8.5418e-09 - val_loss: 7.4251e-10 - val_mse: 7.4251e-10\n",
            "Epoch 167/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0357e-09 - mse: 3.0357e-09 - val_loss: 7.0202e-09 - val_mse: 7.0202e-09\n",
            "Epoch 168/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3643e-08 - mse: 1.3643e-08 - val_loss: 2.6471e-08 - val_mse: 2.6471e-08\n",
            "Epoch 169/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.5520e-09 - mse: 9.5520e-09 - val_loss: 2.5779e-08 - val_mse: 2.5779e-08\n",
            "Epoch 170/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2377e-08 - mse: 2.2377e-08 - val_loss: 2.2108e-09 - val_mse: 2.2108e-09\n",
            "Epoch 171/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.7689e-09 - mse: 9.7689e-09 - val_loss: 1.4523e-09 - val_mse: 1.4523e-09\n",
            "Epoch 172/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3007e-09 - mse: 2.3007e-09 - val_loss: 2.2013e-09 - val_mse: 2.2013e-09\n",
            "Epoch 173/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3143e-09 - mse: 2.3143e-09 - val_loss: 4.4686e-08 - val_mse: 4.4686e-08\n",
            "Epoch 174/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.4222e-09 - mse: 7.4222e-09 - val_loss: 3.0197e-08 - val_mse: 3.0197e-08\n",
            "Epoch 175/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8753e-08 - mse: 1.8753e-08 - val_loss: 1.3745e-08 - val_mse: 1.3745e-08\n",
            "Epoch 176/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3342e-08 - mse: 1.3342e-08 - val_loss: 4.0040e-09 - val_mse: 4.0040e-09\n",
            "Epoch 177/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8499e-08 - mse: 1.8499e-08 - val_loss: 2.5117e-07 - val_mse: 2.5117e-07\n",
            "Epoch 178/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.7220e-08 - mse: 5.7220e-08 - val_loss: 1.6410e-07 - val_mse: 1.6410e-07\n",
            "Epoch 179/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3891e-07 - mse: 1.3891e-07 - val_loss: 4.8698e-08 - val_mse: 4.8698e-08\n",
            "Epoch 180/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1907e-08 - mse: 3.1907e-08 - val_loss: 2.3065e-08 - val_mse: 2.3065e-08\n",
            "Epoch 181/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4822e-08 - mse: 2.4822e-08 - val_loss: 3.9618e-09 - val_mse: 3.9618e-09\n",
            "Epoch 182/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2103e-08 - mse: 1.2103e-08 - val_loss: 3.9237e-08 - val_mse: 3.9237e-08\n",
            "Epoch 183/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.2786e-08 - mse: 8.2786e-08 - val_loss: 2.2460e-06 - val_mse: 2.2460e-06\n",
            "Epoch 184/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8287e-05 - mse: 1.8287e-05 - val_loss: 8.2082e-06 - val_mse: 8.2082e-06\n",
            "Epoch 185/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3063e-05 - mse: 3.3063e-05 - val_loss: 1.3005e-05 - val_mse: 1.3005e-05\n",
            "Epoch 186/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 187/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.1216 - val_mse: 0.1216\n",
            "Epoch 188/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 7.3390e-04 - val_mse: 7.3390e-04\n",
            "Epoch 189/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 190/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1956 - mse: 0.1956 - val_loss: 1.1370 - val_mse: 1.1370\n",
            "Epoch 191/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4200 - mse: 0.4200 - val_loss: 0.0390 - val_mse: 0.0390\n",
            "Epoch 192/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 1.9266e-05 - val_mse: 1.9266e-05\n",
            "Epoch 193/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1884e-04 - mse: 1.1884e-04 - val_loss: 1.0039e-05 - val_mse: 1.0039e-05\n",
            "Epoch 194/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5557e-06 - mse: 1.5557e-06 - val_loss: 4.2128e-07 - val_mse: 4.2128e-07\n",
            "Epoch 195/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9237e-08 - mse: 2.9237e-08 - val_loss: 1.6858e-09 - val_mse: 1.6858e-09\n",
            "Epoch 196/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0235e-08 - mse: 1.0235e-08 - val_loss: 1.1261e-08 - val_mse: 1.1261e-08\n",
            "Epoch 197/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8116e-09 - mse: 9.8116e-09 - val_loss: 1.4523e-09 - val_mse: 1.4523e-09\n",
            "Epoch 198/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2268e-09 - mse: 3.2268e-09 - val_loss: 2.5935e-09 - val_mse: 2.5935e-09\n",
            "Epoch 199/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5070e-08 - mse: 1.5070e-08 - val_loss: 7.5772e-08 - val_mse: 7.5772e-08\n",
            "Epoch 200/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3101e-08 - mse: 1.3101e-08 - val_loss: 3.8792e-09 - val_mse: 3.8792e-09\n",
            "Epoch 201/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4974e-09 - mse: 6.4974e-09 - val_loss: 3.6876e-08 - val_mse: 3.6876e-08\n",
            "Epoch 202/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0353e-08 - mse: 2.0353e-08 - val_loss: 1.9482e-07 - val_mse: 1.9482e-07\n",
            "Epoch 203/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0947e-07 - mse: 1.0947e-07 - val_loss: 3.0449e-06 - val_mse: 3.0449e-06\n",
            "Epoch 204/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8080e-06 - mse: 1.8080e-06 - val_loss: 7.9831e-06 - val_mse: 7.9831e-06\n",
            "Epoch 205/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9311e-05 - mse: 2.9311e-05 - val_loss: 4.5523e-06 - val_mse: 4.5523e-06\n",
            "Epoch 206/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6907e-05 - mse: 6.6907e-05 - val_loss: 5.9049e-05 - val_mse: 5.9049e-05\n",
            "Epoch 207/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9733e-05 - mse: 1.9733e-05 - val_loss: 1.4712e-07 - val_mse: 1.4712e-07\n",
            "Epoch 208/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1246e-06 - mse: 3.1246e-06 - val_loss: 4.2332e-06 - val_mse: 4.2332e-06\n",
            "Epoch 209/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.4131e-06 - mse: 6.4131e-06 - val_loss: 1.9333e-06 - val_mse: 1.9333e-06\n",
            "Epoch 210/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6118e-06 - mse: 7.6118e-06 - val_loss: 8.4344e-06 - val_mse: 8.4344e-06\n",
            "Epoch 211/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0514e-05 - mse: 1.0514e-05 - val_loss: 7.2035e-05 - val_mse: 7.2035e-05\n",
            "Epoch 212/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.1277e-06 - mse: 7.1277e-06 - val_loss: 9.7200e-07 - val_mse: 9.7200e-07\n",
            "Epoch 213/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7423e-06 - mse: 1.7423e-06 - val_loss: 5.0353e-07 - val_mse: 5.0353e-07\n",
            "Epoch 214/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3079e-06 - mse: 1.3079e-06 - val_loss: 8.7515e-07 - val_mse: 8.7515e-07\n",
            "Epoch 215/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4628e-07 - mse: 6.4628e-07 - val_loss: 6.4753e-05 - val_mse: 6.4753e-05\n",
            "Epoch 216/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1778e-05 - mse: 3.1778e-05 - val_loss: 8.0974e-05 - val_mse: 8.0974e-05\n",
            "Epoch 217/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.9212e-04 - mse: 6.9212e-04 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 218/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 219/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6160 - mse: 0.6160 - val_loss: 3.2164e-04 - val_mse: 3.2164e-04\n",
            "Epoch 220/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 221/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 4.0877e-04 - val_mse: 4.0877e-04\n",
            "Epoch 222/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8450e-04 - mse: 1.8450e-04 - val_loss: 4.0930e-06 - val_mse: 4.0930e-06\n",
            "Epoch 223/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2123e-04 - mse: 1.2123e-04 - val_loss: 3.7128e-05 - val_mse: 3.7128e-05\n",
            "Epoch 224/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1049e-04 - mse: 2.1049e-04 - val_loss: 1.7596e-04 - val_mse: 1.7596e-04\n",
            "Epoch 225/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.2136e-05 - mse: 9.2136e-05 - val_loss: 3.0788e-04 - val_mse: 3.0788e-04\n",
            "Epoch 226/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2454e-04 - mse: 4.2454e-04 - val_loss: 3.7610e-06 - val_mse: 3.7610e-06\n",
            "Epoch 227/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1224e-05 - mse: 1.1224e-05 - val_loss: 3.4342e-06 - val_mse: 3.4342e-06\n",
            "Epoch 228/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8059e-06 - mse: 1.8059e-06 - val_loss: 2.7495e-07 - val_mse: 2.7495e-07\n",
            "Epoch 229/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.0832e-06 - mse: 9.0832e-06 - val_loss: 4.3838e-05 - val_mse: 4.3838e-05\n",
            "Epoch 230/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0082e-04 - mse: 1.0082e-04 - val_loss: 4.4409e-04 - val_mse: 4.4409e-04\n",
            "Epoch 231/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0991e-04 - mse: 2.0991e-04 - val_loss: 4.1552e-05 - val_mse: 4.1552e-05\n",
            "Epoch 232/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4175e-04 - mse: 1.4175e-04 - val_loss: 1.0480e-05 - val_mse: 1.0480e-05\n",
            "Epoch 233/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.7925e-06 - mse: 6.7925e-06 - val_loss: 5.5870e-05 - val_mse: 5.5870e-05\n",
            "Epoch 234/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3339e-05 - mse: 2.3339e-05 - val_loss: 2.5284e-06 - val_mse: 2.5284e-06\n",
            "Epoch 235/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5556e-06 - mse: 2.5556e-06 - val_loss: 1.4719e-07 - val_mse: 1.4719e-07\n",
            "Epoch 236/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9963e-07 - mse: 2.9963e-07 - val_loss: 7.2539e-08 - val_mse: 7.2539e-08\n",
            "Epoch 237/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3884e-08 - mse: 4.3884e-08 - val_loss: 3.0244e-07 - val_mse: 3.0244e-07\n",
            "Epoch 238/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.4782e-07 - mse: 7.4782e-07 - val_loss: 1.3794e-05 - val_mse: 1.3794e-05\n",
            "Epoch 239/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5087e-05 - mse: 1.5087e-05 - val_loss: 5.7383e-06 - val_mse: 5.7383e-06\n",
            "Epoch 240/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.6474e-04 - mse: 3.6474e-04 - val_loss: 0.0501 - val_mse: 0.0501\n",
            "Epoch 241/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.3825 - val_mse: 0.3825\n",
            "Epoch 242/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3088 - mse: 0.3088 - val_loss: 0.4372 - val_mse: 0.4372\n",
            "Epoch 243/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7138 - mse: 0.7138 - val_loss: 0.3794 - val_mse: 0.3794\n",
            "Epoch 244/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 245/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 3.6929e-07 - val_mse: 3.6929e-07\n",
            "Epoch 246/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4986e-05 - mse: 1.4986e-05 - val_loss: 2.1261e-06 - val_mse: 2.1261e-06\n",
            "Epoch 247/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.9875e-07 - mse: 6.9875e-07 - val_loss: 5.0659e-08 - val_mse: 5.0659e-08\n",
            "Epoch 248/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3201e-08 - mse: 1.3201e-08 - val_loss: 5.0980e-08 - val_mse: 5.0980e-08\n",
            "Epoch 249/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5610e-08 - mse: 1.5610e-08 - val_loss: 1.7328e-08 - val_mse: 1.7328e-08\n",
            "Epoch 250/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8860e-08 - mse: 1.8860e-08 - val_loss: 3.0709e-08 - val_mse: 3.0709e-08\n",
            "Epoch 251/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3580e-08 - mse: 2.3580e-08 - val_loss: 1.0554e-09 - val_mse: 1.0554e-09\n",
            "Epoch 252/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.7436e-09 - mse: 4.7436e-09 - val_loss: 2.1940e-08 - val_mse: 2.1940e-08\n",
            "Epoch 253/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4995e-08 - mse: 1.4995e-08 - val_loss: 1.0135e-08 - val_mse: 1.0135e-08\n",
            "Epoch 254/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1547e-08 - mse: 1.1547e-08 - val_loss: 8.6668e-09 - val_mse: 8.6668e-09\n",
            "Epoch 255/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6800e-09 - mse: 7.6800e-09 - val_loss: 6.5303e-08 - val_mse: 6.5303e-08\n",
            "Epoch 256/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0385e-08 - mse: 1.0385e-08 - val_loss: 1.5461e-08 - val_mse: 1.5461e-08\n",
            "Epoch 257/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3232e-08 - mse: 3.3232e-08 - val_loss: 1.2190e-08 - val_mse: 1.2190e-08\n",
            "Epoch 258/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.6536e-09 - mse: 7.6536e-09 - val_loss: 5.3180e-09 - val_mse: 5.3180e-09\n",
            "Epoch 259/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.2672e-09 - mse: 5.2672e-09 - val_loss: 6.4141e-09 - val_mse: 6.4141e-09\n",
            "Epoch 260/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.7712e-09 - mse: 6.7712e-09 - val_loss: 4.5714e-08 - val_mse: 4.5714e-08\n",
            "Epoch 261/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1004e-08 - mse: 1.1004e-08 - val_loss: 1.3901e-08 - val_mse: 1.3901e-08\n",
            "Epoch 262/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.9600e-08 - mse: 5.9600e-08 - val_loss: 6.8181e-08 - val_mse: 6.8181e-08\n",
            "Epoch 263/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7564e-07 - mse: 2.7564e-07 - val_loss: 2.2407e-06 - val_mse: 2.2407e-06\n",
            "Epoch 264/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.1035e-06 - mse: 4.1035e-06 - val_loss: 3.9668e-07 - val_mse: 3.9668e-07\n",
            "Epoch 265/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8702e-07 - mse: 1.8702e-07 - val_loss: 3.4088e-06 - val_mse: 3.4088e-06\n",
            "Epoch 266/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4030e-06 - mse: 1.4030e-06 - val_loss: 6.1176e-07 - val_mse: 6.1176e-07\n",
            "Epoch 267/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0609e-07 - mse: 6.0609e-07 - val_loss: 9.4069e-07 - val_mse: 9.4069e-07\n",
            "Epoch 268/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2130e-07 - mse: 4.2130e-07 - val_loss: 5.9646e-06 - val_mse: 5.9646e-06\n",
            "Epoch 269/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.4331e-06 - mse: 9.4331e-06 - val_loss: 3.8754e-05 - val_mse: 3.8754e-05\n",
            "Epoch 270/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3425e-05 - mse: 1.3425e-05 - val_loss: 7.1554e-05 - val_mse: 7.1554e-05\n",
            "Epoch 271/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4059e-05 - mse: 2.4059e-05 - val_loss: 2.3710e-04 - val_mse: 2.3710e-04\n",
            "Epoch 272/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5203e-04 - mse: 2.5203e-04 - val_loss: 2.8459e-04 - val_mse: 2.8459e-04\n",
            "Epoch 273/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 274/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 275/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1078 - mse: 0.1078 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 276/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 277/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3227e-04 - mse: 1.3227e-04 - val_loss: 2.7666e-06 - val_mse: 2.7666e-06\n",
            "Epoch 278/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.8828e-07 - mse: 5.8828e-07 - val_loss: 1.0513e-06 - val_mse: 1.0513e-06\n",
            "Epoch 279/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1319e-07 - mse: 1.1319e-07 - val_loss: 1.0220e-08 - val_mse: 1.0220e-08\n",
            "Epoch 280/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.6677e-09 - mse: 8.6677e-09 - val_loss: 3.4555e-08 - val_mse: 3.4555e-08\n",
            "Epoch 281/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.3313e-09 - mse: 9.3313e-09 - val_loss: 9.2117e-09 - val_mse: 9.2117e-09\n",
            "Epoch 282/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0349e-08 - mse: 4.0349e-08 - val_loss: 3.3516e-08 - val_mse: 3.3516e-08\n",
            "Epoch 283/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8185e-08 - mse: 2.8185e-08 - val_loss: 1.7895e-09 - val_mse: 1.7895e-09\n",
            "Epoch 284/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0331e-08 - mse: 1.0331e-08 - val_loss: 8.3586e-09 - val_mse: 8.3586e-09\n",
            "Epoch 285/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.9201e-08 - mse: 7.9201e-08 - val_loss: 1.2104e-08 - val_mse: 1.2104e-08\n",
            "Epoch 286/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0220e-07 - mse: 7.0220e-07 - val_loss: 8.8674e-06 - val_mse: 8.8674e-06\n",
            "Epoch 287/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.6263e-05 - mse: 9.6263e-05 - val_loss: 7.5908e-05 - val_mse: 7.5908e-05\n",
            "Epoch 288/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 5.3091e-04 - val_mse: 5.3091e-04\n",
            "Epoch 289/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 290/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0193 - val_mse: 0.0193\n",
            "Epoch 291/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0482 - val_mse: 0.0482\n",
            "Epoch 292/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 293/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 294/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0660 - val_mse: 0.0660\n",
            "Epoch 295/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 2.3015e-06 - val_mse: 2.3015e-06\n",
            "Epoch 296/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1023e-04 - mse: 1.1023e-04 - val_loss: 1.0015e-04 - val_mse: 1.0015e-04\n",
            "Epoch 297/300\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4992e-04 - mse: 6.4992e-04 - val_loss: 6.1461e-05 - val_mse: 6.1461e-05\n",
            "Epoch 298/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2909e-04 - mse: 2.2909e-04 - val_loss: 7.7029e-04 - val_mse: 7.7029e-04\n",
            "Epoch 299/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.5461 - val_mse: 0.5461\n",
            "Epoch 300/300\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3136 - mse: 0.3136 - val_loss: 0.3812 - val_mse: 0.3812\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2848 - mse: 0.2848\n",
            "mse : [0.2847990095615387, 0.2847990095615387]\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6400dcdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[ 80.3075   380.2504  ]\n",
            " [ 81.305664 381.256   ]\n",
            " [ 82.30383  382.26172 ]\n",
            " [ 83.302    383.26733 ]\n",
            " [ 84.30016  384.27298 ]\n",
            " [ 85.298325 385.27866 ]\n",
            " [ 86.29649  386.2843  ]\n",
            " [ 87.29466  387.28995 ]\n",
            " [ 88.292816 388.29562 ]\n",
            " [ 89.29099  389.30127 ]\n",
            " [ 90.28914  390.30695 ]\n",
            " [ 91.28731  391.3126  ]\n",
            " [ 92.28548  392.31824 ]\n",
            " [ 93.28364  393.32388 ]\n",
            " [ 94.28181  394.3295  ]\n",
            " [ 95.27996  395.3352  ]\n",
            " [ 96.27813  396.34082 ]\n",
            " [ 97.276306 397.34647 ]\n",
            " [ 98.27445  398.35217 ]\n",
            " [ 99.272606 399.3578  ]]\n",
            "RMSE :  0.5336661759413628\n",
            "R2 :  0.9914345988768758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ck4_VUG8nJW"
      },
      "source": [
        "### 4.3.3. 다:1 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bFijtdr8sA5"
      },
      "source": [
        "다:1 모델은 다:다 모델에서 아웃풋만 1개인 경우를 말한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps-7d3SH9f_G"
      },
      "source": [
        "100개의 데이터씩 2개의 컬럼이 입력되어, 100개의 데이터 1개가 출력되는 구조이다. 위의 코드와 동일하지만, 최종 아웃풋 레이어만 1로 변경했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfbBxlo7-79I",
        "outputId": "3108e0ae-9842-412c-a630-efee53c7e310"
      },
      "source": [
        "#1. 데이터 준비\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([range(100), range(301,401)])\n",
        "y = np.array(range(201,301))\n",
        "x = np.transpose(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, random_state=66, test_size=0.5, shuffle=False\n",
        "                                                )\n",
        "#2. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape = (2, ), activation ='relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))  ## 최종 아웃풋 레이어 : 2 > 1로 변경\n",
        "\n",
        "#3. 훈련\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "#4. 평가 예측\n",
        "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print(\"mse : \", mse)\n",
        "y_predict = model.predict(x_test)\n",
        "\n",
        "# RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 57491.3963 - mse: 57491.3963 - val_loss: 39268.9570 - val_mse: 39268.9570\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 27237.0625 - mse: 27237.0625 - val_loss: 12515.5176 - val_mse: 12515.5176\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6714.7126 - mse: 6714.7126 - val_loss: 621.5402 - val_mse: 621.5402\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 260.0728 - mse: 260.0728 - val_loss: 2.3995 - val_mse: 2.3995\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3677 - mse: 0.3677 - val_loss: 4.9123 - val_mse: 4.9123\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 4.7279 - val_mse: 4.7279\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1459 - mse: 0.1459 - val_loss: 4.3020 - val_mse: 4.3020\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 4.8431 - val_mse: 4.8431\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 4.2072 - val_mse: 4.2072\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 4.0322 - val_mse: 4.0322\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 3.9928 - val_mse: 3.9928\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 3.6719 - val_mse: 3.6719\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 3.8304 - val_mse: 3.8304\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 3.4355 - val_mse: 3.4355\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 3.1643 - val_mse: 3.1643\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 3.0786 - val_mse: 3.0786\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 2.9695 - val_mse: 2.9695\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 2.8654 - val_mse: 2.8654\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 2.8837 - val_mse: 2.8837\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 2.7594 - val_mse: 2.7594\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 2.5442 - val_mse: 2.5442\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 2.4805 - val_mse: 2.4805\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 2.4899 - val_mse: 2.4899\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 2.4741 - val_mse: 2.4741\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.4014 - val_mse: 2.4014\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.3211 - val_mse: 2.3211\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.3392 - val_mse: 2.3392\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.3538 - val_mse: 2.3538\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3875e-04 - mse: 6.3875e-04 - val_loss: 2.3291 - val_mse: 2.3291\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5953e-04 - mse: 4.5953e-04 - val_loss: 2.2766 - val_mse: 2.2766\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3672e-04 - mse: 3.3672e-04 - val_loss: 2.2639 - val_mse: 2.2639\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2608e-04 - mse: 2.2608e-04 - val_loss: 2.2535 - val_mse: 2.2535\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6726e-04 - mse: 1.6726e-04 - val_loss: 2.2353 - val_mse: 2.2353\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5096e-05 - mse: 9.5096e-05 - val_loss: 2.2230 - val_mse: 2.2230\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7869e-05 - mse: 5.7869e-05 - val_loss: 2.2121 - val_mse: 2.2121\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3065e-05 - mse: 3.3065e-05 - val_loss: 2.2068 - val_mse: 2.2068\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4438e-05 - mse: 2.4438e-05 - val_loss: 2.2066 - val_mse: 2.2066\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3670e-05 - mse: 1.3670e-05 - val_loss: 2.2011 - val_mse: 2.2011\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.3465e-06 - mse: 8.3465e-06 - val_loss: 2.1962 - val_mse: 2.1962\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9774e-06 - mse: 4.9774e-06 - val_loss: 2.1930 - val_mse: 2.1930\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8634e-06 - mse: 2.8634e-06 - val_loss: 2.1912 - val_mse: 2.1912\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4826e-06 - mse: 1.4826e-06 - val_loss: 2.1908 - val_mse: 2.1908\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.6562e-07 - mse: 6.6562e-07 - val_loss: 2.1896 - val_mse: 2.1896\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1162e-07 - mse: 5.1162e-07 - val_loss: 2.1888 - val_mse: 2.1888\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.0604e-07 - mse: 3.0604e-07 - val_loss: 2.1877 - val_mse: 2.1877\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0049e-07 - mse: 2.0049e-07 - val_loss: 2.1876 - val_mse: 2.1876\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2922e-07 - mse: 1.2922e-07 - val_loss: 2.1874 - val_mse: 2.1874\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8396e-08 - mse: 9.8396e-08 - val_loss: 2.1873 - val_mse: 2.1873\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.7854e-08 - mse: 6.7854e-08 - val_loss: 2.1869 - val_mse: 2.1869\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5823e-08 - mse: 4.5823e-08 - val_loss: 2.1867 - val_mse: 2.1867\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4869e-08 - mse: 3.4869e-08 - val_loss: 2.1866 - val_mse: 2.1866\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5671e-08 - mse: 3.5671e-08 - val_loss: 2.1865 - val_mse: 2.1865\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0935e-08 - mse: 2.0935e-08 - val_loss: 2.1864 - val_mse: 2.1864\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9861e-08 - mse: 1.9861e-08 - val_loss: 2.1864 - val_mse: 2.1864\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0420e-08 - mse: 2.0420e-08 - val_loss: 2.1862 - val_mse: 2.1862\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1606e-08 - mse: 1.1606e-08 - val_loss: 2.1862 - val_mse: 2.1862\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0899e-08 - mse: 1.0899e-08 - val_loss: 2.1860 - val_mse: 2.1860\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0283e-09 - mse: 6.0283e-09 - val_loss: 2.1860 - val_mse: 2.1860\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1367e-09 - mse: 5.1367e-09 - val_loss: 2.1860 - val_mse: 2.1860\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.4037e-09 - mse: 4.4037e-09 - val_loss: 2.1860 - val_mse: 2.1860\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5010e-09 - mse: 4.5010e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0613e-09 - mse: 4.0613e-09 - val_loss: 2.1860 - val_mse: 2.1860\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4462e-09 - mse: 3.4462e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5329e-09 - mse: 2.5329e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2834e-09 - mse: 3.2834e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5010e-09 - mse: 2.5010e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4133e-09 - mse: 2.4133e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4551e-09 - mse: 2.4551e-09 - val_loss: 2.1859 - val_mse: 2.1859\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0619e-09 - mse: 2.0619e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5849e-09 - mse: 1.5849e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4765e-09 - mse: 1.4765e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7628e-09 - mse: 1.7628e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8720e-09 - mse: 1.8720e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2052e-09 - mse: 1.2052e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1197e-09 - mse: 1.1197e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2666e-09 - mse: 1.2666e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0092e-09 - mse: 1.0092e-09 - val_loss: 2.1858 - val_mse: 2.1858\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.9238e-10 - mse: 8.9238e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0219e-09 - mse: 1.0219e-09 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1058e-09 - mse: 1.1058e-09 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.6410e-10 - mse: 7.6410e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.6022e-10 - mse: 5.6022e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0829e-10 - mse: 4.0829e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1900e-10 - mse: 5.1900e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.4121e-10 - mse: 4.4121e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.0002e-10 - mse: 4.0002e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5697e-10 - mse: 4.5697e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.1850e-10 - mse: 5.1850e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.1538e-10 - mse: 6.1538e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1921e-10 - mse: 3.1921e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.0428e-10 - mse: 4.0428e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8775e-10 - mse: 2.8775e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3927e-10 - mse: 2.3927e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8348e-10 - mse: 2.8348e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2158e-10 - mse: 3.2158e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2808e-10 - mse: 2.2808e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9134e-10 - mse: 1.9134e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6678e-10 - mse: 1.6678e-10 - val_loss: 2.1857 - val_mse: 2.1857\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2666e-10 - mse: 3.2666e-10 - val_loss: 2.1856 - val_mse: 2.1856\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4519e-10 - mse: 3.4519e-10 - val_loss: 2.1856 - val_mse: 2.1856\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 18.3757 - mse: 18.3757\n",
            "mse :  [18.375680923461914, 18.375680923461914]\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5d91edc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "RMSE :  4.286685419365853\n",
            "R2 :  0.4473482139968783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZEYMjLM-cb3"
      },
      "source": [
        "### 4.3.4. 1:다 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y0xbY-U-Y0b",
        "outputId": "b2d9087c-3037-4fda-d260-e6a29bffceed"
      },
      "source": [
        "#1. 데이터 준비하기\n",
        "import numpy as np\n",
        "x = np.array([range(100)])  \n",
        "y = np.array([range(201,301), range(301,401)])   \n",
        "x = np.transpose(x)\n",
        "y = np.transpose(y)\n",
        "\n",
        "print(x.shape)   ##  x는 (100,1)의 shape을 가지고 있는 데이터\n",
        "print(y.shape)   ##  y는 (100,2)의 shape을 가지고 있는 데이터\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, random_state=66, test_size=0.5, shuffle=False)\n",
        "\n",
        "print(x_test.shape)\n",
        "\n",
        "#2. 모델 구성\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape = (1, ), activation ='relu'))   ## 입력 모델의 input_shape이 1로 바뀜.\n",
        "model.add(Dense(3))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(2))    ## 마지막 출력의 Dense 층의 아웃풋을 2로 변경\n",
        "\n",
        "#3. 훈련\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=1, validation_data=(x_val, y_val))\n",
        "\n",
        "#4. 평가 예측\n",
        "loss, mse = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print(\"mse : \", mse)\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict)\n",
        "\n",
        "#RMSE 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\n",
        "\n",
        "# R2 구하기\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(y_test, y_predict)\n",
        "print(\"R2 : \", r2_y_predict)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1)\n",
            "(100, 2)\n",
            "(20, 1)\n",
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 83915.6570 - mse: 83915.6570 - val_loss: 93482.6875 - val_mse: 93482.6875\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 76254.4452 - mse: 76254.4452 - val_loss: 77054.6094 - val_mse: 77054.6094\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 67867.0191 - mse: 67867.0191 - val_loss: 55395.3867 - val_mse: 55395.3867\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 57627.4787 - mse: 57627.4787 - val_loss: 27212.3184 - val_mse: 27212.3184\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 42418.8048 - mse: 42418.8048 - val_loss: 4654.7690 - val_mse: 4654.7690\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 31484.6177 - mse: 31484.6177 - val_loss: 5403.5854 - val_mse: 5403.5854\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 21294.3988 - mse: 21294.3988 - val_loss: 20962.6406 - val_mse: 20962.6406\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 15981.4925 - mse: 15981.4925 - val_loss: 31050.3438 - val_mse: 31050.3438\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16441.7303 - mse: 16441.7303 - val_loss: 33634.6641 - val_mse: 33634.6641\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13570.0774 - mse: 13570.0774 - val_loss: 38105.4688 - val_mse: 38105.4688\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16705.5171 - mse: 16705.5171 - val_loss: 35113.0859 - val_mse: 35113.0859\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14234.3180 - mse: 14234.3180 - val_loss: 36470.8516 - val_mse: 36470.8516\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 15337.4361 - mse: 15337.4361 - val_loss: 33969.2500 - val_mse: 33969.2500\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 15405.2502 - mse: 15405.2502 - val_loss: 37434.7109 - val_mse: 37434.7109\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12175.6477 - mse: 12175.6477 - val_loss: 35309.1953 - val_mse: 35309.1953\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14620.3175 - mse: 14620.3175 - val_loss: 35776.6641 - val_mse: 35776.6641\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11339.2147 - mse: 11339.2147 - val_loss: 35712.5859 - val_mse: 35712.5859\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16718.5206 - mse: 16718.5206 - val_loss: 36725.8711 - val_mse: 36725.8711\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 17271.5842 - mse: 17271.5842 - val_loss: 35501.2266 - val_mse: 35501.2266\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13564.4408 - mse: 13564.4408 - val_loss: 36847.0703 - val_mse: 36847.0703\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16923.7151 - mse: 16923.7151 - val_loss: 34891.1562 - val_mse: 34891.1562\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13972.6713 - mse: 13972.6713 - val_loss: 34513.8828 - val_mse: 34513.8828\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14914.5978 - mse: 14914.5978 - val_loss: 40002.0977 - val_mse: 40002.0977\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13255.1290 - mse: 13255.1290 - val_loss: 36615.5391 - val_mse: 36615.5391\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14390.7632 - mse: 14390.7632 - val_loss: 33775.5000 - val_mse: 33775.5000\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13398.8629 - mse: 13398.8629 - val_loss: 35630.4023 - val_mse: 35630.4023\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14865.0336 - mse: 14865.0336 - val_loss: 36240.5547 - val_mse: 36240.5547\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14324.2483 - mse: 14324.2483 - val_loss: 36451.4141 - val_mse: 36451.4141\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14285.2934 - mse: 14285.2934 - val_loss: 34684.2969 - val_mse: 34684.2969\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13290.8105 - mse: 13290.8105 - val_loss: 37256.0703 - val_mse: 37256.0703\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16356.2563 - mse: 16356.2563 - val_loss: 36317.9453 - val_mse: 36317.9453\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 18956.0874 - mse: 18956.0874 - val_loss: 36745.0391 - val_mse: 36745.0391\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12458.9875 - mse: 12458.9875 - val_loss: 36016.1484 - val_mse: 36016.1484\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12482.8839 - mse: 12482.8839 - val_loss: 33570.5703 - val_mse: 33570.5703\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13562.3989 - mse: 13562.3989 - val_loss: 34855.1484 - val_mse: 34855.1484\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14540.2789 - mse: 14540.2789 - val_loss: 32992.3359 - val_mse: 32992.3359\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13540.9259 - mse: 13540.9259 - val_loss: 34775.1484 - val_mse: 34775.1484\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14088.9400 - mse: 14088.9400 - val_loss: 34142.4336 - val_mse: 34142.4336\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12422.2152 - mse: 12422.2152 - val_loss: 35411.3516 - val_mse: 35411.3516\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11448.9067 - mse: 11448.9067 - val_loss: 33094.9766 - val_mse: 33094.9766\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12864.9238 - mse: 12864.9238 - val_loss: 32989.0430 - val_mse: 32989.0430\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 15817.7455 - mse: 15817.7455 - val_loss: 34551.5117 - val_mse: 34551.5117\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10759.9791 - mse: 10759.9791 - val_loss: 32836.5391 - val_mse: 32836.5391\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 14388.9048 - mse: 14388.9048 - val_loss: 34573.1211 - val_mse: 34573.1211\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 13861.6544 - mse: 13861.6544 - val_loss: 31500.8281 - val_mse: 31500.8281\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13793.8226 - mse: 13793.8226 - val_loss: 31269.3906 - val_mse: 31269.3906\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13306.6112 - mse: 13306.6112 - val_loss: 30810.3906 - val_mse: 30810.3906\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10572.1693 - mse: 10572.1693 - val_loss: 33544.1953 - val_mse: 33544.1953\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10285.2940 - mse: 10285.2940 - val_loss: 33030.5234 - val_mse: 33030.5234\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11534.1685 - mse: 11534.1685 - val_loss: 32212.7383 - val_mse: 32212.7383\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9985.5244 - mse: 9985.5244 - val_loss: 33408.9141 - val_mse: 33408.9141\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10055.7979 - mse: 10055.7979 - val_loss: 32384.2285 - val_mse: 32384.2285\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14440.5534 - mse: 14440.5534 - val_loss: 31452.5820 - val_mse: 31452.5820\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10845.5043 - mse: 10845.5043 - val_loss: 31855.3477 - val_mse: 31855.3477\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11562.2106 - mse: 11562.2106 - val_loss: 30698.3945 - val_mse: 30698.3945\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12291.5252 - mse: 12291.5252 - val_loss: 29155.1504 - val_mse: 29155.1504\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9589.8476 - mse: 9589.8476 - val_loss: 31766.0586 - val_mse: 31766.0586\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 14992.0411 - mse: 14992.0411 - val_loss: 29239.3945 - val_mse: 29239.3945\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12230.8799 - mse: 12230.8799 - val_loss: 31804.2246 - val_mse: 31804.2246\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9574.2107 - mse: 9574.2107 - val_loss: 29070.7129 - val_mse: 29070.7129\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11687.2614 - mse: 11687.2614 - val_loss: 31272.8691 - val_mse: 31272.8691\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12406.4710 - mse: 12406.4710 - val_loss: 29668.7910 - val_mse: 29668.7910\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 13409.7934 - mse: 13409.7934 - val_loss: 32267.3633 - val_mse: 32267.3633\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10850.2085 - mse: 10850.2085 - val_loss: 27150.2246 - val_mse: 27150.2246\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12945.4450 - mse: 12945.4450 - val_loss: 29239.9023 - val_mse: 29239.9023\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11586.7349 - mse: 11586.7349 - val_loss: 29335.6465 - val_mse: 29335.6465\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 10184.2329 - mse: 10184.2329 - val_loss: 28080.9570 - val_mse: 28080.9570\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11555.3820 - mse: 11555.3820 - val_loss: 29666.8965 - val_mse: 29666.8965\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11320.6937 - mse: 11320.6937 - val_loss: 29347.7539 - val_mse: 29347.7539\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10230.4403 - mse: 10230.4403 - val_loss: 27409.6504 - val_mse: 27409.6504\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 11214.4095 - mse: 11214.4095 - val_loss: 30135.9902 - val_mse: 30135.9902\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 12126.8704 - mse: 12126.8704 - val_loss: 26414.9102 - val_mse: 26414.9102\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9792.1073 - mse: 9792.1073 - val_loss: 26548.6758 - val_mse: 26548.6758\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12793.3856 - mse: 12793.3856 - val_loss: 26267.3711 - val_mse: 26267.3711\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 12011.8223 - mse: 12011.8223 - val_loss: 26557.4473 - val_mse: 26557.4473\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9234.1582 - mse: 9234.1582 - val_loss: 23474.4805 - val_mse: 23474.4805\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9708.1531 - mse: 9708.1531 - val_loss: 25014.3301 - val_mse: 25014.3301\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 10851.1628 - mse: 10851.1628 - val_loss: 24794.5723 - val_mse: 24794.5723\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11632.9834 - mse: 11632.9834 - val_loss: 25946.7637 - val_mse: 25946.7637\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10405.9033 - mse: 10405.9033 - val_loss: 25541.3535 - val_mse: 25541.3535\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 10220.6947 - mse: 10220.6947 - val_loss: 24139.6875 - val_mse: 24139.6875\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7737.4530 - mse: 7737.4530 - val_loss: 24665.6523 - val_mse: 24665.6523\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11054.0395 - mse: 11054.0395 - val_loss: 24079.6113 - val_mse: 24079.6113\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 11077.7517 - mse: 11077.7517 - val_loss: 22330.6406 - val_mse: 22330.6406\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8421.6183 - mse: 8421.6183 - val_loss: 21694.5527 - val_mse: 21694.5527\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8918.8529 - mse: 8918.8529 - val_loss: 23568.4082 - val_mse: 23568.4082\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8955.1486 - mse: 8955.1486 - val_loss: 23231.4316 - val_mse: 23231.4316\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6396.4429 - mse: 6396.4429 - val_loss: 22384.4297 - val_mse: 22384.4297\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8553.4217 - mse: 8553.4217 - val_loss: 22246.5430 - val_mse: 22246.5430\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6423.5390 - mse: 6423.5390 - val_loss: 22813.9941 - val_mse: 22813.9941\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8407.5445 - mse: 8407.5445 - val_loss: 18508.9023 - val_mse: 18508.9023\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6626.2379 - mse: 6626.2379 - val_loss: 21396.0918 - val_mse: 21396.0918\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6962.2116 - mse: 6962.2116 - val_loss: 18233.2012 - val_mse: 18233.2012\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5994.1347 - mse: 5994.1347 - val_loss: 19885.7090 - val_mse: 19885.7090\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7710.7051 - mse: 7710.7051 - val_loss: 17874.4355 - val_mse: 17874.4355\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5750.2340 - mse: 5750.2340 - val_loss: 17514.8145 - val_mse: 17514.8145\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5871.9783 - mse: 5871.9783 - val_loss: 19869.4023 - val_mse: 19869.4023\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6618.2720 - mse: 6618.2720 - val_loss: 17015.1582 - val_mse: 17015.1582\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6959.7057 - mse: 6959.7057 - val_loss: 18172.4199 - val_mse: 18172.4199\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6103.5474 - mse: 6103.5474 - val_loss: 15520.3877 - val_mse: 15520.3877\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 41110.0156 - mse: 41110.0156\n",
            "mse :  41110.015625\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5db959d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[407.72693 575.1667 ]\n",
            " [411.75635 580.85944]\n",
            " [415.78574 586.5522 ]\n",
            " [419.81512 592.2448 ]\n",
            " [423.84454 597.93756]\n",
            " [427.874   603.6304 ]\n",
            " [431.90335 609.32306]\n",
            " [435.9328  615.0158 ]\n",
            " [439.96222 620.70856]\n",
            " [443.99167 626.4013 ]\n",
            " [448.02106 632.09406]\n",
            " [452.0504  637.7867 ]\n",
            " [456.07986 643.47943]\n",
            " [460.10928 649.17224]\n",
            " [464.1387  654.865  ]\n",
            " [468.1681  660.5577 ]\n",
            " [472.19754 666.2504 ]\n",
            " [476.22696 671.9432 ]\n",
            " [480.25635 677.63586]\n",
            " [484.2857  683.32855]]\n",
            "RMSE :  202.75604426776525\n",
            "R2 :  -1235.3913830710371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH7H4anbBJGa"
      },
      "source": [
        "predict한 부분의 값이 엉망이다. 우리가 원하는 값이 나오지 않았다. RMSE도 높은 수치이고, R2는 아예 음수이다. \n",
        "\n",
        "결과값이 좋지는 않지만 이런 모델까지도 만들 수 있다는 것만 이해하면 된다!"
      ]
    }
  ]
}